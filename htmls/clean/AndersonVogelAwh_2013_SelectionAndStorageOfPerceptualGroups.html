<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    
    <head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        <!-- AppResources meta begin -->
        <script type="text/javascript">var ncbi_startTime = new Date();</script>
        <!-- AppResources meta end -->
        
        <!-- TemplateResources meta begin -->
        <meta name="paf_template" content="" />

        <!-- TemplateResources meta end -->
        
        <!-- Logger begin -->
        <meta name="ncbi_db" content="pmc" /><meta name="ncbi_pdid" content="article" /><meta name="ncbi_acc" content="" /><meta name="ncbi_domain" content="nihpa" /><meta name="ncbi_report" content="record" /><meta name="ncbi_type" content="fulltext" /><meta name="ncbi_objectid" content="" /><meta name="ncbi_pcid" content="/articles/PMC4068940/" /><meta name="ncbi_app" content="pmc" />
        <!-- Logger end -->
        
        <title>Selection and Storage of Perceptual Groups Is Constrained by a Discrete Resource in Working Memory</title>
        
        <!-- AppResources external_resources begin -->
        <link rel="stylesheet" href="/core/jig/1.14.8/css/jig.min.css" /><script type="text/javascript" src="/core/jig/1.14.8/js/jig.min.js"></script>

        <!-- AppResources external_resources end -->
        
        <!-- Page meta begin -->
        <meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE" /><link rel="canonical" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4068940/" /><link rel="schema.DC" href="http://purl.org/DC/elements/1.0/" /><meta name="citation_journal_title" content="Journal of experimental psychology. Human perception and performance" /><meta name="citation_title" content="Selection and Storage of Perceptual Groups Is Constrained by a Discrete Resource in Working Memory" /><meta name="citation_authors" content="David E. Anderson, Edward K. Vogel, Edward Awh" /><meta name="citation_date" content="June 2013" /><meta name="citation_issue" content="3" /><meta name="citation_volume" content="39" /><meta name="citation_firstpage" content="824" /><meta name="citation_doi" content="10.1037/a0030094" /><meta name="citation_abstract_html_url" content="/pmc/articles/PMC4068940/?report=abstract" /><meta name="citation_pmid" content="23067117" /><meta name="DC.Title" content="Selection and Storage of Perceptual Groups Is Constrained by a Discrete Resource in Working Memory" /><meta name="DC.Type" content="Text" /><meta name="DC.Publisher" content="NIH Public Access" /><meta name="DC.Contributor" content="David E. Anderson" /><meta name="DC.Contributor" content="Edward K. Vogel" /><meta name="DC.Contributor" content="Edward Awh" /><meta name="DC.Date" content="2013 Jun" /><meta name="DC.Identifier" content="10.1037/a0030094" /><meta name="DC.Language" content="en" /><meta property="og:title" content="Selection and Storage of Perceptual Groups Is Constrained by a Discrete Resource in Working Memory" /><meta property="og:type" content="article" /><meta property="og:description" content="Perceptual grouping can lead observers to perceive a multielement scene as a smaller number of hierarchical units. Past work has shown that grouping enables more elements to be stored in visual working memory (WM). Although this may appear to contradict ..." /><meta property="og:url" content="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4068940/" /><meta property="og:site_name" content="PubMed Central (PMC)" /><meta property="og:image" content="https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-logo-share.png" /><meta name="twitter:card" content="summary" /><meta name="twitter:site" content="@ncbi" /><link rel="stylesheet" href="/corehtml/pmc/css/3.14.1/pmc.min.css" type="text/css" /><link rel="stylesheet" href="/corehtml/pmc/css/3.14.1/pmc_extras_prnt.min.css" type="text/css" media="print" /><script type="text/javascript" src="/corehtml/pmc/js/common.min.js">//</script><script type="text/javascript" src="/corehtml/pmc/js/NcbiTagServer.min.js">//</script><meta name="citationexporter" content="backend:'https://api.ncbi.nlm.nih.gov/lit/ctxp/v1/pmc/'" /><script type="text/javascript" src="https://www.ncbi.nlm.nih.gov/corehtml/pmc/ctxp/jquery.citationexporter.min.js">//</script><link rel="stylesheet" href="https://www.ncbi.nlm.nih.gov/corehtml/pmc/ctxp/citationexporter.css" type="text/css" /><script type="text/javascript" src="/core/mathjax/2.6.1/MathJax.js?config=/corehtml/pmc/js/mathjax-config-classic.3.4.js"></script><script type="text/javascript">window.name="mainwindow";</script><style type="text/css">.pmc-wm {background:transparent repeat-y top left;background-image:url(/corehtml/pmc/pmcgifs/wm-hhspa.gif),url(/corehtml/pmc/pmcgifs/wm-retraction-pink.png);background-size: auto, contain}</style><style type="text/css">.print-view{display:block}</style><style type="text/css">
        div.pmc_para_cit li.highlight,
        div.pmc_para_cit li.highlight .one_line_source
        { background: #E0E0E0; }
        a.bibr.highlight { background: #E0E0E0; } 
      </style><meta name="cited_in_systematic_reviews" content="" />

        <!-- Page meta end -->
    <link rel="shortcut icon" href="//www.ncbi.nlm.nih.gov/favicon.ico" /><meta name="ncbi_phid" content="CE8BBFEFCD118FF100000000007D0057.m_8" />
<meta name='referrer' content='origin-when-cross-origin'/><link type="text/css" rel="stylesheet" href="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/css/3852956/3985586/3808861/4121862/3974050/3917732/251717/4048120/3846471/14534/45193/4113719/3849091/3984811/3751656/4033350/3840896/3577051/3852958/3881636/3579733/4062871/12930/3964959/3855473/4047625/3854974/3854955/4076335/4128070/9685/3549676/3609192/3609193/3609213/3395586/4143404.css" /><link type="text/css" rel="stylesheet" href="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/css/3411343/3882866/4157116.css" media="print" /></head>
    <body class="article">
        <div class="grid">
            <div class="col twelve_col nomargin shadow">
                <!-- System messages like service outage or JS required; this is handled by the TemplateResources portlet -->
                <div class="sysmessages">
                    <noscript>
	<p class="nojs">
	<strong>Warning:</strong>
	The NCBI web site requires JavaScript to function. 
	<a href="/guide/browsers/#enablejs" title="Learn how to enable JavaScript" target="_blank">more...</a>
	</p>
	</noscript>
                </div>
                <!--/.sysmessage-->
                <div class="wrap">
                    <div class="page">
                        <div class="top">
                            <div class="universal_header" id="universal_header"><ul class="inline_list jig-ncbimenu ui-ncbimenu resources_list" id="navcontent"><li class="ui-ncbimenu-item-leaf ui-ncbimenu-item-first ui-helper-reset ui-ncbimenu-item-no-hlt"><a class="ui-ncbimenu-link-first" href="/" role="banner" title="NCBI Home" id="ncbihome" accesskey="1"><span class="offscreen_noflow">NCBI</span><img src="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/img/28977" class="ncbi_logo" title="NCBI" alt="NCBI Logo" /></a></li><li class="offscreen_noflow ui-ncbimenu-item-skip access"><a href="#maincontent" title="Skip to the content" tabindex="0" accesskey="3">Skip to main
                        content</a></li><li class="offscreen_noflow ui-ncbimenu-item-skip access"><a href="#navcontent" title="Skip to the navigation" tabindex="0" accesskey="4">Skip to
                        navigation</a></li><li id="resource-menu" class="topmenu ui-helper-reset ui-ncbimenu-item-first ui-helper-reset"><a class="ui-ncbimenu-first-link-has-submenu ui-ncbimenu-link-first topanchor expandDown" href="/static/header_footer_ajax/submenu/#resources">Resources</a></li><li id="all-howtos-menu" class="topmenu ui-helper-reset ui-ncbimenu-item-first"><a class="ui-ncbimenu-first-link-has-submenu ui-ncbimenu-link-first topanchor expandDown" href="/static/header_footer_ajax/submenu/#howto">How To</a></li><li class="offscreen_noflow ui-ncbimenu-item-skip access"><a href="/guide/browsers/#accesskeys" title="About My NCBI Accesskeys" tabindex="0" accesskey="0">About NCBI Accesskeys</a></li></ul><div class="myncbi"><span id="myncbiusername" style="display:none"><a href="/account/settings/" id="mnu" title="Edit account settings"></a></span><a accesskey="2" href="/myncbi/" id="myncbi" style="display:none">My NCBI</a><a href="/account/" id="sign_in">Sign in to NCBI</a><a href="/account/signout/" id="sign_out" style="display:none">Sign Out</a></div></div>
                            <div class="header">
    <div class="res_logo">
  <h1 class="img_logo"><a href="/pmc/" class="pmc_logo offscreen">PMC</a></h1>
  <div class="NLMLogo">
    <a href="https://www.nlm.nih.gov/" title="US National Library of Medicine">US National Library of Medicine</a>
    <br />
    <a href="https://www.nih.gov/" title="National Institutes of Health">National Institutes of Health</a>
  </div>
</div>
    <div class="search"><form method="get" action="/pmc/"><div class="search_form"><label for="database" class="offscreen_noflow">Search database</label><select id="database"><optgroup label="Recent"><option value="pmc" selected="selected" data-ac_dict="pmc-search-autocomplete">PMC</option><option value="books">Books</option><option value="pubmed" class="last">PubMed</option></optgroup><optgroup label="All"><option value="gquery">All Databases</option><option value="assembly">Assembly</option><option value="biocollections">Biocollections</option><option value="bioproject">BioProject</option><option value="biosample">BioSample</option><option value="biosystems">BioSystems</option><option value="books">Books</option><option value="clinvar">ClinVar</option><option value="clone">Clone</option><option value="cdd">Conserved Domains</option><option value="gap">dbGaP</option><option value="dbvar">dbVar</option><option value="nucest">EST</option><option value="gene">Gene</option><option value="genome">Genome</option><option value="gds">GEO DataSets</option><option value="geoprofiles">GEO Profiles</option><option value="nucgss">GSS</option><option value="gtr">GTR</option><option value="homologene">HomoloGene</option><option value="ipg">Identical Protein Groups</option><option value="medgen">MedGen</option><option value="mesh">MeSH</option><option value="ncbisearch">NCBI Web Site</option><option value="nlmcatalog">NLM Catalog</option><option value="nuccore">Nucleotide</option><option value="omim">OMIM</option><option value="pmc" data-ac_dict="pmc-search-autocomplete">PMC</option><option value="popset">PopSet</option><option value="probe">Probe</option><option value="protein">Protein</option><option value="proteinclusters">Protein Clusters</option><option value="pcassay">PubChem BioAssay</option><option value="pccompound">PubChem Compound</option><option value="pcsubstance">PubChem Substance</option><option value="pubmed">PubMed</option><option value="snp">SNP</option><option value="sparcle">Sparcle</option><option value="sra">SRA</option><option value="structure">Structure</option><option value="taxonomy">Taxonomy</option><option value="toolkit">ToolKit</option><option value="toolkitall">ToolKitAll</option><option value="toolkitbookgh">ToolKitBookgh</option><option value="unigene">UniGene</option></optgroup></select><div class="nowrap"><label for="term" class="offscreen_noflow" accesskey="/">Search term</label><div class="nowrap"><input type="text" name="term" id="term" title="Search PMC. Use up and down arrows to choose an item from the autocomplete." value="" class="jig-ncbiclearbutton jig-ncbiautocomplete" data-jigconfig="dictionary:'pmc-search-autocomplete',disableUrl:'NcbiSearchBarAutoComplCtrl'" autocomplete="off" data-sbconfig="ds:'no',pjs:'no',afs:'yes'" /></div><button id="search" type="submit" class="button_search nowrap" cmd="go">Search</button></div></div></form><ul class="searchlinks inline_list"><li>
                        <a href="/pmc/advanced/">Advanced</a>
                    </li><li>
                        <a href="/pmc/journals/">Journal list</a>
                    </li><li class="help">
                        <a target="_blank" href="/books/NBK3825/">Help</a>
                    </li></ul></div>
</div>

                            
                            
                        <!--<component id="Page" label="headcontent"/>-->
                            
                        </div>
                        <div class="content">
                            <!-- site messages -->
                            <div class="container">
    <div id="maincontent" class="content eight_col col">
        <div class="navlink-box">
            <ul class="page-breadcrumbs inline_list small"><li class="journal-list"><a href="/pmc/journals/" class="navlink">Journal List</a></li><li class="article-entrez-filter"><a href="/pmc/?term=hhs%20author%20manuscript[filter]" class="navlink">HHS Author Manuscripts</a></li><li class="accid">PMC4068940</li></ul>
        </div>

        <!-- Journal banner -->
        <div class="pmc-page-banner whole_rhythm"><div><img src="/corehtml/pmc/pmcgifs/logo-hhspa.png" alt="Logo of nihpa" usemap="#logo-imagemap" /><map id="logo-imagemap" name="logo-imagemap"><area shape="rect" coords="0,57,255,75" alt="About Author manuscripts" title="About Author manuscripts" href="https://www.ncbi.nlm.nih.gov/pmc/about/authorms.html" ref="https://www.ncbi.nlm.nih.gov/pmc/about/authorms.html" /><area shape="rect" coords="256,57,500,75" alt="Submit a manuscript" title="Submit a manuscript" href="https://www.nihms.nih.gov/" ref="reftype=publisher&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CBanner&amp;TO=Publisher%7COther%7CN/A" target="pmc_ext" /><area shape="rect" coords="0,0,499,74" alt="HHS Public Access; Author Manuscript; Accepted for publication in peer reviewed journal;" title="HHS Public Access; Author Manuscript; Accepted for publication in peer reviewed journal;" href="https://www.ncbi.nlm.nih.gov/pmc/about/public-access/" ref="reftype=publisher&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CBanner&amp;TO=Publisher%7COther%7CN/A" target="pmc_ext" /></map></div> </div>
        
        <!--component id='MainPortlet' label='search-reference'/-->
        
        <!-- Book content -->
        <div class="">
            
        
            
            <div class="hide-overflow article lit-style content pmc-wm slang-all page-box"><!--main-content--><div class="jig-ncbiinpagenav" data-jigconfig="smoothScroll: false, allHeadingLevels: ['h2'], headingExclude: ':hidden'"><div class="fm-sec half_rhythm no_top_margin"><div class="fm-citation half_rhythm no_top_margin clearfix"><div class="inline_block eight_col va_top"><div><span id="pmcmata">J Exp Psychol Hum Percept Perform</span>. Author manuscript; available in PMC 2014 Jun 24.</div><div></div><div>Published in final edited form as:</div><div style="margin-left:1em"><div class="fm-vol-iss-date"><a href="/entrez/eutils/elink.fcgi?dbfrom=pubmed&amp;retmode=ref&amp;cmd=prlinks&amp;id=23067117" target="pmc_ext" ref="reftype=publisher&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CFront%20Matter&amp;TO=Content%20Provider%7CArticle%7CRestricted%20Access"><span class="cit">J Exp Psychol Hum Percept Perform. 2013 Jun; 39(3): 824–835. </span></a></div><span class="fm-vol-iss-date">Published online 2012 Oct 15. </span> <span class="doi">doi: <a href="//dx.doi.org/10.1037%2Fa0030094" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CFront%20Matter&amp;TO=Content%20Provider%7CCrosslink%7CDOI">10.1037/a0030094</a></span></div></div><div class="inline_block four_col va_top show-overflow align_right"><div class="fm-citation-ids"><div class="fm-citation-pmcid"><span class="fm-citation-ids-label">PMCID: </span><span>PMC4068940</span></div><div class="fm-citation-manuscriptid"><span class="fm-citation-ids-label">NIHMSID: </span><span>NIHMS589839</span></div><div class="fm-citation-pmid">PMID: <a href="/pubmed/23067117">23067117</a></div></div></div></div><p class="pmc-alert-box retraction-alert"><span class="alert-mark"></span><span class="notice">This article has been retracted. </span>Retraction in: <a href="/pmc/articles/PMC4603561/"><related-article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:pmc="http://www.pubmedcentral.gov/pmc" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" related-article-type="retraction-forward" ext-link-type="pmcaccid" xlink:href="PMC4603561" id="DLidm139702400116912"><?link_pmcaccid_DLidm139702400116912 PMC4603561?>J Exp Psychol Hum Percept Perform. 2015 August 17; 41(5): 1189</related-article></a>    See also: <a href="/pmc/about/guidelines/#retract">PMC Retraction Policy</a></p><h1 class="content-title">Selection and Storage of Perceptual Groups Is Constrained by a Discrete Resource in Working Memory</h1><div class="half_rhythm"><div class="contrib-group fm-author"><a href="/pubmed/?term=Anderson%20DE%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=23067117">David E. Anderson</a>, <a href="/pubmed/?term=Vogel%20EK%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=23067117">Edward K. Vogel</a>, and  <a href="/pubmed/?term=Awh%20E%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=23067117">Edward Awh</a></div><div style="display:none" class="contrib-group aff-tip"></div></div><div class="fm-panel half_rhythm"><div class="togglers"><a href="#" class="pmctoggle" rid="idm139702380275600_ai">Author information</a> <a href="#" class="pmctoggle" rid="idm139702380275600_cpl">Copyright and License information</a> <a href="/pmc/about/disclaimer/">Disclaimer</a></div><div class="fm-authors-info fm-panel hide half_rhythm" id="idm139702380275600_ai" style="display:none"><div class="fm-affl" lang="en" id="A1">University of Oregon</div><div id="FN1">Correspondence concerning this article should be addressed to: Edward Awh, Department of Psychology, 1227 University of Oregon, Eugene, OR 97403. <a href="mailto:dev@null" data-email="ude.nogerou@hwa" class="oemail">ude.nogerou@hwa</a></div><div id="FN2">David E. Anderson, Edward K. Vogel, and Edward Awh, Department of Psychology, University of Oregon.</div></div><div class="fm-article-notes fm-panel half_rhythm"></div><div class="permissions fm-panel half_rhythm hide" id="idm139702380275600_cpl" style="display:none"><div class="fm-copyright half_rhythm"><a href="/pmc/about/copyright/">Copyright notice</a> </div></div></div><div id="pmclinksbox" class="links-box whole_rhythm"><div class="fm-panel"><div>The publisher's final edited version of this article is available  at <a href="/entrez/eutils/elink.fcgi?dbfrom=pubmed&amp;retmode=ref&amp;cmd=prlinks&amp;id=23067117" target="pmc_ext" ref="reftype=publisher&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CFront%20Matter&amp;TO=Content%20Provider%7CArticle%7CRestricted%20Access">J Exp Psychol Hum Percept Perform</a></div><div><strong>This article has been retracted. </strong>See <a href="/pmc/articles/PMC4603561/">J Exp Psychol Hum Percept Perform. 2015 August 17; 41(5): 1189</a>.</div><div>See commentary "<a href="/pmc/articles/PMC4555989/">Findings of research misconduct.</a>" in <em>NIH Guide Grants Contracts</em>, NOT-OD-15-141.</div><div>See commentary "<a href="/pmc/articles/PMC5019524/">Findings of Research Misconduct</a>" in <em>Fed Regist</em>, volume 80 on page 45661.</div><div style="border-top: 1px solid rgb(102, 102, 153); margin: 5px 10% 3px;"></div><div>See other articles in PMC that <a href="/pmc/articles/PMC4068940/citedby/">cite</a> the published article.</div></div></div></div><div class="sec"></div><div id="idm139702371153200" lang="en" class="tsec sec"><h2 class="head no_bottom_margin" id="idm139702371153200title">Abstract</h2><!--article-meta--><div><p id="P1" class="p p-first-last">Perceptual grouping can lead observers to perceive a multielement scene as a smaller number of hierarchical units. Past work has shown that grouping enables more elements to be stored in visual working memory (WM). Although this may appear to contradict so-called discrete resource models that argue for fixed item limits in WM storage, it is also possible that grouping reduces the effective number of &#x0201c;items&#x0201d; in the display. To test this hypothesis, we examined how mnemonic resolution declined as the number of items to be stored increased. Discrete resource models predict that precision will reach a stable plateau at relatively early set sizes, because no further items can be stored once putative item limits are exceeded. Thus, we examined whether the precision by set size function was bilinear when storage was enhanced via perceptual grouping. In line with the hypothesis that each perceptual group counted as a single &#x0201c;item,&#x0201d; precision still reached a clear plateau at a set size determined by the number of stored groups. Moreover, the maximum number of elements stored was doubled, and electrophysiological measures showed that selection and storage-related neural responses were the same for a single element and a multielement perceptual group. Thus, perceptual grouping allows more elements to be held in working memory while storage is still constrained by a discrete item limit.</p></div><div class="sec"><strong class="kwd-title">Keywords: </strong><span class="kwd-text">working memory, individual differences, perceptual organization, ERP</span></div></div><div id="idm139702368734144" class="tsec sec headless whole_rhythm"><p id="P2" class="p p-first">Working memory (WM) is an online memory system whose capacity predicts a broad range of intellectual abilities, including fluid intelligence and academic achievement (Engle et al., 2001; <a href="#R14" rid="R14" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880831">Cowan et al., 2005</a>; <a href="#R21" rid="R21" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880793">Fukuda, Vogel, Mayr, &#x00026; Awh, 2010</a>). Thus, there has been strong interest in characterizing the nature of this capacity limit. Discrete resource models assert a so-called &#x0201c;item limit&#x0201d; within working memory, such that once a small number of items have been stored, no further information can be stored from additional items (<a href="#R2" rid="R2" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880792">Awh, Barton, &#x00026; Vogel, 2007</a>; <a href="#R12" rid="R12" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880810">Cowan, 2001</a>; <a href="#R27" rid="R27" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865124">Rouder et al., 2008</a>; <a href="#R38" rid="R38" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880827">Zhang &#x00026; Luck, 2008</a>). Alternatively, flexible resource models assert that it is possible to distribute WM resources across an unlimited number of items, although the proportion of resources devoted to each item is inversely related to the number of stored items (<a href="#R5" rid="R5" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880805">Bays &#x00026; Husain, 2008</a>; <a href="#R33" rid="R33" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880789">Wilken &#x00026; Ma, 2004</a>). In line with this prediction, multiple studies have demonstrated an inverse relationship between mnemonic precision and the number of stored items (<a href="#R1" rid="R1" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865133">Anderson, Vogel, &#x00026; Awh, 2011</a>; <a href="#R3" rid="R3" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880828">Barton, Ester, &#x00026; Awh, 2009</a>; <a href="#R5" rid="R5" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880808">Bays &#x00026; Husain, 2008</a>; <a href="#R38" rid="R38" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880812">Zhang &#x00026; Luck, 2008</a>). Although this finding is naturally explained by flexible resource models, it can also be reconciled with discrete resource models. For example, <a href="#R3" rid="R3" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880806">Barton et al. (2009)</a> proposed a hybrid model in which a discrete set of &#x0201c;slots&#x0201d; constrains the allocation of a separate resource that determines mnemonic precision. Critically, this hybrid model predicts that declines in mnemonic resolution will halt at relatively early set sizes, because no further information is encoded into memory once putative item limits are exceeded. In line with this, <a href="#R38" rid="R38" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880815">Zhang and Luck (2008)</a> observed equivalent precision for set sizes of three and six items. In addition, <a href="#R1" rid="R1" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865130">Anderson et al. (2011)</a> used a fine-grained manipulation of set size to show that the set size at which mnemonic resolution reached its plateau was strongly predicted by the item limit for each observer. Thus, the shape of the resolution by set size function supports the claim that WM storage is constrained by a discrete item limit.</p><p id="P3">These studies, however, did not directly address the fundamental question of how an &#x0201c;item&#x0201d; should be defined. When <a href="#R24" rid="R24" class=" bibr popnode">Marr (1982)</a> famously asked &#x0201c;What &#x02026; is an object?&#x0201d; (p. 270), he was referencing the complexity of this question. There is a hierarchical organization to natural scenes that depends on the structure of the scene and the goals of the observer (<a href="#R24" rid="R24" class=" bibr popnode">Marr, 1982</a>). From this perspective, it is clear that even if WM storage is constrained by a discrete item limit, variations in scene structure could have a powerful effect on how this resource is allocated across scene elements. For example, <a href="#R34" rid="R34" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880803">Woodman, Vecera, and Luck (2003)</a> showed that Gestalt grouping principles determine which items are encoded into visual WM from supraspan displays. Using a spatial precuing paradigm adopted from <a href="#R16" rid="R16" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880825">Egly, Driver, and Rafal (1994)</a>, <a href="#R34" rid="R34" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880817">Woodman et al. (2003)</a> found that objects that were grouped with the precued object were more likely to be stored in working memory than objects belonging to a different group. In one experiment, they used proximity as a cue to group six items into two columns of three objects each. When one corner was cued, the farthest item within the cued column was more likely to be stored in memory than the equidistant item in the uncued column. Thus, <a href="#R34" rid="R34" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880830">Woodman, Vecera, and Luck (2003)</a> demonstrated that Gestalt grouping principles influence which objects are encoded into memory from supraspan displays. There is also evidence that scene structure influences how many elements can be stored. <a href="#R35" rid="R35" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880826">Xu (2006)</a> found that when a colored circle and oriented stem were connected, performance was better than when these single feature objects were unconnected and separated. Additionally, <a href="#R32" rid="R32" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880799">Walker and Davies (2003)</a> found that visual WM performance was enhanced when eight individual objects were perceptually grouped into four units by way of amodal completion behind an occluder. Likewise, <a href="#R36" rid="R36" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880818">Xu (2008)</a> and <a href="#R37" rid="R37" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865127">Xu and Chun (2007)</a> have shown that storage-related activity in the inferior intraparietal sulcus is reduced when objects are grouped by connectedness (<a href="#R36" rid="R36" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880821">Xu, 2008</a>) or common surface (<a href="#R37" rid="R37" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865123">Xu and Chun, 2007</a>). Thus, perceptual grouping can influence both which items are stored and the maximum number of elements that can be stored in visual WM.</p><p id="P4" class="p">At first glance, such findings might seem to contradict the notion of a fixed item limit&#x02014;a central tenet of discrete resource models&#x02014;given that the number of elements stored increases under grouped conditions. However, these data can be reconciled with a theoretical item limit if each &#x0201c;item&#x0201d; consists of multiple elements that are linked by perceptual grouping cues. In the present work, we tested this hypothesis by examining whether there would be clear evidence of discrete item limits when strong perceptual grouping cues allowed grouping of pairs of items. Here we examined three specific predictions that emerge from the view that each pair of grouped elements occupies a single discrete &#x0201c;slot.&#x0201d; First, we expected to replicate the basic empirical pattern discovered by <a href="#R38" rid="R38" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880785">Zhang and Luck (2008)</a>, in which observers have nonzero information about a subset of items, while retaining no information about additional items. This result favors discrete over flexible resource models, given that flexible resource models predict the storage of nonzero information for all items in the display. Second, we expected to replicate the observations from <a href="#R1" rid="R1" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865125">Anderson et al. (2011)</a> that mnemonic precision would reach a stable asymptote at a set size predicted by each individual&#x02019;s item limit. This correlation is clearly predicted by discrete resource models, because set sizes that exceed the putative item limit do not lead to the storage of additional items. Finally, this approach provided an opportunity to observe whether grouping of pairs of items via collinearity cues would lead to a doubling of the number of elements stored, as well as a doubling of the set size at which mnemonic precision reached a plateau. This result would suggest that resources are allocated in a discrete fashion (as indicated by the plateau in precision), with each perceptual group counting as a single item. Thus, perceptual grouping can increase the number of elements stored while the allocation of mnemonic resources remains constrained by a discrete item limit.</p></div><div id="S1" class="tsec sec"><h2 class="head no_bottom_margin" id="S1title">Experiment 1</h2><div id="S2" class="sec sec-first"><h3 id="S2title">Experiment 1a</h3><p id="P5" class="p p-first">The purpose of this experiment was to determine whether perceptual grouping cues increase the number of elements stored in WM by causing grouped pairs to be stored as a single discrete &#x0201c;item.&#x0201d; Within the &#x0201c;grouped&#x0201d; condition, pairs of elements were grouped via strong collinearity cues (see <a href="/pmc/articles/PMC4068940/figure/F1/" target="figure" class="fig-table-link figpopup" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1</span></a>); thus, we predicted a doubling in both the set size at which precision asymptotes, as well a doubling of capacity estimates in the grouped condition. By contrast, if the number of &#x0201c;items&#x0201d; is not reduced by perceptual grouping, then the asymptote in the precision by set size function should be similar between the grouped and ungrouped conditions.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="F1" co-legend-rid="lgnd_F1"><a href="/pmc/articles/PMC4068940/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139702437900928" class="figure"><a class="inline_block ts_canvas" href="/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=4068940_nihms589839f1.jpg" target="tileshopwindow"><div class="ts_bar small" title="Click on image to zoom"></div><img alt="An external file that holds a picture, illustration, etc.&#10;Object name is nihms589839f1.jpg" title="Click on image to zoom" class="tileshop" src="/pmc/articles/PMC4068940/bin/nihms589839f1.jpg" /></a></div><div id="largeobj_idm139702437900928" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC4068940/figure/F1/?report=objectonly">Open in a separate window</a></div></a><div class="icnblk_cntnt" id="lgnd_F1"><div><a class="figpopup" href="/pmc/articles/PMC4068940/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1">Figure 1</a></div><!--caption a7--><div class="caption"><p id="__p3">Working memory task. Participants maintained fixation and were instructed to remember the orientation of all objects presented on the display. Set sizes used were 2, 4, 6, and 8. After a short delay period, participants were presented with a probe ring that determined which item was to be recalled. Participants used a mouse to indicate the orientation of the probed item.</p></div></div></div><div id="S3" class="sec"><p></p><h4 id="S3title" class="inline">Methods </h4><div id="S4" class="sec sec-first"><p></p><h5 id="S4title" class="inline">Subjects </h5><p id="P6" class="p p-first-last">A total of 25 undergraduates at the University of Oregon completed the experiment for course credit. All had normal or corrected-to-normal visual acuity and gave informed consent according to procedures approved by the University of Oregon institutional review board.</p></div><div id="S5" class="sec"><p></p><h5 id="S5title" class="inline">Stimulus displays </h5><p id="P7" class="p p-first">Stimuli were generated in MATLab using the Psychophysics Toolbox extension (<a href="#R9" rid="R9" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880800">Brainard, 1997</a>; <a href="#R26" rid="R26" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880822">Pelli, 1997</a>) and presented on a 17-inch flat CRT computer screen (refresh rate of 120 Hz). Viewing distances were approximately 77 cm.</p><p id="P8">Our tasks required participants to remember the orientation of solid disks (radius = .93&#x000b0; of visual angle) that contained a rectangular gap, which was randomly positioned at an angle varying across the full 360 degrees of space (see <a href="/pmc/articles/PMC4068940/figure/F1/" target="figure" class="fig-table-link figpopup" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1</span></a>).</p><p id="P9" class="p p-last">In Experiment 1, objects were presented within a square region subtending 10.7&#x000b0; &#x000d7; 10.7&#x000b0; of visual angle, and subjects fixated on a central fixation point that subtended .37&#x000b0; &#x000d7; .37&#x000b0;. Objects were presented in pairs so that two objects within a pair were separated by a center-to-center distance of 3.16&#x000b0; of visual angle. Pairs of objects were positioned randomly, with respect to both position and orientation, with the constraint that no two pairs could fall within 1.43&#x000b0; of one another, resulting in a between-object separation of at least two thirds of an object. At the end of each trial, subjects were cued to recall the orientation of a single item. A specific object was probed by outlining its position with a thick, black ring with a radius of .93&#x000b0; and rim thickness of .37&#x000b0; (see <a href="/pmc/articles/PMC4068940/figure/F1/" target="figure" class="fig-table-link figpopup" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1</span></a>).</p></div><div id="S6" class="sec"><p></p><h5 id="S6title" class="inline">Procedures </h5><p id="P10" class="p p-first-last">Experiment 1 took approximately 1.5 hours to complete and was composed of 15 blocks of 64 trials each. Grouping conditions and set sizes were randomly intermixed within each block. The events in a single trial of Experiment 1 went as follows. First, subjects saw a central fixation point, followed by the presentation of 2, 4, 6, or 8 disks with oriented gaps for 200 ms. In the ungrouped condition, all orientations were random with respect to each other; in the grouped condition, the orientations of different pairs of objects were offset by 180&#x000b0; so that the gaps were facing each other, forming an illusory rectangle (see <a href="/pmc/articles/PMC4068940/figure/F1/" target="figure" class="fig-table-link figpopup" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1</span></a>). A 1000 ms delay period followed the offset of the disks. Following the delay, a probe ring appeared in a randomly selected position. Subjects clicked on the perimeter of this ring in an unspeeded response to indicate the orientation of the sample item that had appeared in the same position. Each response was followed by a 750-ms blank intertrial interval.</p></div><div id="S7" class="sec sec-last"><p></p><h5 id="S7title" class="inline">Modeling response error distributions </h5><p id="P11" class="p p-first-last">Offset values were defined by the difference between the subjects&#x02019; response and the angle of the probed sample stimulus (ranging from &#x02212;180 to 180 degrees). Frequency histograms of response offsets for each set size and stimulus configuration were created to assess memory performance. Memory performance was quantified using a mixture model (<a href="#R38" rid="R38" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880829">Zhang &#x00026; Luck, 2008</a>) that describes the error histogram in terms of a weighted sum of two distinct distributions: 1) a uniform distribution, which reflects random responses with respect to the angle of the probed stimulus, and 2) a von Mises distribution, which reflects target-related responses centered around the angle of the probed stimulus. Maximum likelihood estimation was used to fit the mixture model to the distribution of response offsets. Three parameters were estimated: &#x003bc;, the mean of the von Mises distribution corresponding to trials in which the subject had selected the target location; <em>SD</em>, the width of the same von Mises distribution (used to operationalize mnemonic precision), and <em>p</em>(failure), denoted P<sub>f</sub>. This latter parameter corresponds to the height of a uniform distribution, corresponding to trials in which subjects failed to store the probed item. P<sub>mem</sub> refers simply to the probability that the critical item was stored (1 minus P<sub>f</sub>). Our measure of WM capacity was derived from the P<sub>mem</sub> parameter.</p></div></div><div id="S8" class="sec sec-last"><p></p><h4 id="S8title" class="inline">Results and Discussion </h4><p id="P12" class="p p-first">The individual subject parameter estimates (P<sub>mem</sub> and <em>SD</em>) were extracted separately for each set size for each subject. An analysis of variance (ANOVA) with the factors set size (2, 4, 6, or 8) and grouping condition (grouped vs. ungrouped) was run separately for each parameter. There was a significant main effect for grouping in both our precision, <em>F</em>(1, 24) = 197.76, <em>p</em> &#x0003c; .001 and P<sub>mem</sub> estimates, <em>F</em>(1, 24) = 102.81, <em>p</em> &#x0003c; .001; the probability of storage for the set size 8 grouped condition (<em>M</em> = .68) was approximately twice that of the set size 8 ungrouped condition (<em>M</em> = .32), suggesting that individuals could store twice as many elements in the grouped condition compared to the ungrouped condition. We further examined this relationship by plotting P<sub>mem</sub> for set size 8 ungrouped as a function of P<sub>mem</sub> for set size 8 grouped (<a href="/pmc/articles/PMC4068940/figure/F2/" target="figure" class="fig-table-link figpopup" rid-figpopup="F2" rid-ob="ob-F2" co-legend-rid="lgnd_F2"><span>Figure 2A</span></a>). If we presume that set size 8 is supracapacity for all observers, a doubling of storage capacity in the grouped condition should yield a slope of 0.5. Confirming this prediction, a linear regression model (solid black line, <em>R</em><sup>2</sup> = .38, <em>p</em> &#x0003c; .01) revealed a slope and <em>y</em>-intercept of .53 and &#x02212;.03, respectively. This strengthens the case that individuals are storing twice as many elements in grouped relative to ungrouped conditions. We then fitted these data with hypothetical models (<a href="/pmc/articles/PMC4068940/figure/F2/" target="figure" class="fig-table-link figpopup" rid-figpopup="F2" rid-ob="ob-F2" co-legend-rid="lgnd_F2"><span>Figure 2B</span></a>) that assume a perceptual group is stored as either two individual elements (dotted gray line, in which a slope of 1 is predicted) or a single unit (dotted black line, in which a slope of .5 is predicted). The model which assumes the storage of individuated elements differed significantly from the observed data (<em>p</em> &#x0003c; .0001), while no significant difference was found between the model that assumed the storage of a single group (<em>p</em> = .66). The latter result suggests that these collinearity cues were strong enough to produce virtually perfect grouping, resulting in a doubling of the number of element stored. Thus, we demonstrate that storage estimates for the grouped condition was doubled relative to the ungrouped condition, suggesting that perceptual groups are stored as single units in WM.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="F2" co-legend-rid="lgnd_F2"><a href="/pmc/articles/PMC4068940/figure/F2/" target="figure" rid-figpopup="F2" rid-ob="ob-F2"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139702436731680" class="figure"><a class="inline_block ts_canvas" href="/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=4068940_nihms589839f2.jpg" target="tileshopwindow"><div class="ts_bar small" title="Click on image to zoom"></div><img alt="An external file that holds a picture, illustration, etc.&#10;Object name is nihms589839f2.jpg" title="Click on image to zoom" class="tileshop" src="/pmc/articles/PMC4068940/bin/nihms589839f2.jpg" /></a></div><div id="largeobj_idm139702436731680" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC4068940/figure/F2/?report=objectonly">Open in a separate window</a></div></a><div class="icnblk_cntnt" id="lgnd_F2"><div><a class="figpopup" href="/pmc/articles/PMC4068940/figure/F2/" target="figure" rid-figpopup="F2" rid-ob="ob-F2">Figure 2</a></div><!--caption a7--><div class="caption"><p id="__p4">Testing models that assume the storage of image elements or perceptual groups. (A) Capacity estimates for storing eight individual, ungrouped items (Pmem<sub>SS8u</sub>) was plotted as a function of capacity estimates for storing eight elements organized into four perceptual groups (Pmem<sub>SS8g</sub>). The regression function fitted to these data (solid black line) were statistically indistinguishable from a model assuming the storage of perceptual groups as a single unit (dotted black line; <em>p</em> = .66), whereas a model assuming the storage of individual elements was significantly different (dotted gray line; <em>p</em> &#x0003c; .0001). (B) Capacity estimates for storing four individual, ungrouped items (Pmem<sub>SS4u</sub>) was plotted as a function of capacity estimates for storing eight elements organized into four perceptual groups (Pmem<sub>SS8g</sub>). The regression function fitted to these data (solid black line) were statistically indistinguishable from a model assuming the storage of perceptual groups as a single unit (dotted black line; <em>p</em> = .34), whereas a model assuming the storage of individual elements was significantly different (dotted gray line; <em>p</em> &#x0003c; .0001).</p></div></div></div><p id="P13">If our assumption that the elements of a perceptual group are stored as a single unit in WM is correct, then we should observe similar profiles of storage requirements across different set sizes when the number of perceptual units is identical. Consistent with this prediction, we found equivalent capacity estimates for the set size 4 ungrouped (<em>M</em> = .70) and set size 8 grouped (<em>M</em> = .68) conditions that involved the storage of four pairs of elements, <em>t</em>(24) = .972, <em>p</em> = .348. This suggests that observers store the same number of &#x0201c;items&#x0201d; in both conditions. We further examined the possibility that these two conditions require the same storage demands by plotting P<sub>mem</sub> for set size 4 ungrouped as a function of P<sub>mem</sub> for set size 8 grouped (<a href="/pmc/articles/PMC4068940/figure/F2/" target="figure" class="fig-table-link figpopup" rid-figpopup="F2" rid-ob="ob-F2" co-legend-rid="lgnd_F2"><span>Figure 2B</span></a>). We fitted these data with a linear regression model (solid black line), which provided reliable fit (<em>R</em><sup>2</sup> = .51, <em>p</em> &#x0003c; .01), and regression coefficients revealed a slope and <em>y</em>-intercept of .63 and .28, respectively. We again fitted these data with hypothetical models that assume a perceptual group is stored as either two individual elements (dotted gray line, in which a slope of .5 is predicted) or a single unit (dotted black line, in which a slope of 1 is predicted). The model, which assumes the storage of individuated elements, differed significantly from the observed data (<em>p</em> &#x0003c; .0001), while no significant difference was found between the model that assumed the storage of a single group. We note, however, that although &#x0201c;single unit&#x0201d; model had a superior fit to the observed data, the precise slope of the observed data was numerically closer to that of the &#x0201c;individuated elements&#x0201d; model. In the absence of a clear explanation for the positive <em>y</em>-intercept for the observed data (when a zero intercept was predicted by the better fitting model), the results of this analysis alone should be not be taken as strong evidence in favor of the &#x0201c;single unit&#x0201d; hypothesis.</p><p id="P14">When comparing precision estimates across conditions that require the same storage demands, we found that <em>SD</em> (our operational measure of precision) was lower for the set size 8 grouped condition (<em>M</em> = 15.17) than the set size 4 ungrouped condition, <em>M</em> = 19.41; <em>t</em>(24) = 5.94, <em>p</em> &#x0003c; .001. This indicates that when perceived set size was equal, more precise representations were maintained in the grouped condition. We speculate that the longer aspect ratio for the illusory rectangle in the grouped condition (relative to the single notch in the ungrouped condition) provided more salient orientation information (<a href="#R28" rid="R28" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865120">Sompolinsky &#x00026; Shapley, 1997</a>). One fortunate consequence of this observation is that it rules out the possibility that observers simply ignored one of the elements within each pair of disks (and later extrapolated the ignored value if it was probed) as opposed to simultaneously encoding both elements of the group within a discrete &#x0201c;slot.&#x0201d; Enhanced precision in the grouped condition suggests that both elements of each group were attended and encoded as a single &#x0201c;item&#x0201d; that provided more precise orientation information than that provided by a single ungrouped element.</p><p id="P15">The next analysis focused on the precision by set size functions in the grouped and ungrouped conditions (<a href="/pmc/articles/PMC4068940/figure/F3/" target="figure" class="fig-table-link figpopup" rid-figpopup="F3" rid-ob="ob-F3" co-legend-rid="lgnd_F3"><span>Figure 3A</span></a>). The un-grouped condition is a replication (although with a coarser manipulation of set sizes) of <a href="#R1" rid="R1" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865134">Anderson, Vogel, and Awh (2011)</a>. The discrete resource model predicts an asymptote early in precision by set size functions because resources are distributed only to those items stored in memory. This predicts that an asymptote in the precision by set size function should be observed at a relatively small set size. Indeed, we found a decline in precision from set size 2 (<em>M</em> = 14.1) to set size 4, <em>M</em> = 19.4; <em>t</em>(24) = &#x02212;8.5, <em>p</em> &#x0003c; .001, after which we observed an apparent asymptote, set size 4 to set size 6 (<em>M</em> = 19.6; <em>t</em>(24) = &#x02212;.15, <em>p</em> = .88; set size 6 to set size 8 (<em>M</em> = 19.4; <em>t</em>(24) = .2, <em>p</em> = .84). By fitting a bilinear function to these data (<em>R</em><sup>2</sup> = .9993, <em>p</em> &#x0003c; .0001), we observed an inflection in precision at 4.03 items. This estimate is larger than that found in <a href="#R1" rid="R1" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865121">Anderson, Vogel, and Awh (2011)</a>, but the omission of odd-numbered set sizes may have reduced the precision of inflection estimates in this experiment. The bilinear function is predicted by discrete resource models, because they presume that no further items are stored once relatively small item limits are exceeded; thus, because the number of items stored stays constant when item limits are exceeded, the precision of the items that were stored also remains constant.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="F3" co-legend-rid="lgnd_F3"><a href="/pmc/articles/PMC4068940/figure/F3/" target="figure" rid-figpopup="F3" rid-ob="ob-F3"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139702437464000" class="figure"><a class="inline_block ts_canvas" href="/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=4068940_nihms589839f3.jpg" target="tileshopwindow"><div class="ts_bar small" title="Click on image to zoom"></div><img alt="An external file that holds a picture, illustration, etc.&#10;Object name is nihms589839f3.jpg" title="Click on image to zoom" class="tileshop" src="/pmc/articles/PMC4068940/bin/nihms589839f3.jpg" /></a></div><div id="largeobj_idm139702437464000" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC4068940/figure/F3/?report=objectonly">Open in a separate window</a></div></a><div class="icnblk_cntnt" id="lgnd_F3"><div><a class="figpopup" href="/pmc/articles/PMC4068940/figure/F3/" target="figure" rid-figpopup="F3" rid-ob="ob-F3">Figure 3</a></div><!--caption a7--><div class="caption"><p id="__p5">Bilinear fits and individual differences analyses. (A) The precision by set size functions were fitted with a bilinear function for both the ungrouped (black line) and grouped (gray line) conditions. (B) Inflections in precision occurred at a later set size for both low (black) and high (white) WM capacity individuals (<em>p</em> &#x0003c; .001). Correlation (<em>p</em> &#x0003c; .001) between individual item limits and inflections in precision for ungrouped (C) and grouped (D) conditions, and the correlation (<em>p</em> &#x0003c; .01) between inflections in grouped and inflections in ungrouped conditions. Error bars represent the 95% confidence interval.</p></div></div></div><p id="P16">Given that observers were able to store two collinear objects as a single item, we predicted a doubling of the inflection point in the resolution by set size function, because twice as many elements could be accommodated within the putative item limit if each perceptual group counted as a single item. Indeed, we find that precision decreases monotonically in the grouped condition, set size 2 (<em>M</em> = 10.4) to set size 4 (<em>M</em> = 12.3; <em>t</em>(24) = &#x02212;6.3, <em>p</em> &#x0003c; .001); set size 4 to set size 6 (<em>M</em> = 13.7; <em>t</em>(24) = &#x02212;4.0, <em>p</em> &#x0003c; .001); set size 6 to set size 8 (<em>M</em> = 15.2; <em>t</em>(24) = &#x02212;1.9, <em>p</em> = .066), and, when fitted with a bilinear function (<em>R</em><sup>2</sup> = .995, <em>p</em> &#x0003c; .001), found calculated point of inflection at 7.62 objects. Thus, the asymptote in the grouped condition occurs at a set size that is nearly double the size as the asymptote found in the ungrouped condition (4.03), confirming the prediction that the precision by set size function is sensitive to the number of perceived items stored in working memory.</p><p id="P17">One problem with this empirical pattern is that the inflection point of the precision by set size function in the grouped condition was close to the largest set size tested; this may have compromised the inflection estimate because the flat portion of the putative bilinear function was almost completely cut off. To address this problem, we ran another experiment (Experiment 1b) in which we replicated the findings in the grouped condition, while extending the range of set sizes up to 12 items. As we will discuss below, this procedure allowed a clear demonstration of the predicted plateau from set size 8 to 12. That said, we also gained some traction on this issue by examining the individual subject data from Experiment 1a. Because many individuals had capacity estimates well below four items, the predicted inflection point in their precision by set size function was well below 8 in the grouped condition. To illustrate this point, the data from the low-capacity subjects (as defined by a median-split based on P<sub>mem</sub>) revealed that precision reached a plateau at about set size 5 in the grouped condition (<a href="/pmc/articles/PMC4068940/figure/F3/" target="figure" class="fig-table-link figpopup" rid-figpopup="F3" rid-ob="ob-F3" co-legend-rid="lgnd_F3"><span>Figure 3B</span></a>), approximately twice the observed inflection in the ungrouped condition for those subjects. Thus, even though inflection estimates were well below ceiling in the low-capacity group, the inflection estimates from this subset of subjects corroborated the doubling of the inflection point that was observed in the overall data.</p><p id="P18">Finally, we examined whether the individual subject data from Experiment 1a replicated our prior observation that precision in WM reaches a plateau at a set size that is correlated with each observer&#x02019;s item limit. This correlation is clearly predicted by discrete resource models, because they assert that the plateau in precision results from observer&#x02019;s inability to encode more items into WM. Thus, we examined the correlation between individual item limits and the observed inflection point in the precision by set size function. One potential problem for this analysis is that dependencies between <em>SD</em> and P<sub>mem</sub> can elicit a spurious correlation when those parameters are estimated from the same set of data (<a href="#R6" rid="R6" class=" bibr popnode">Brady, Fougnie, &#x00026; Alvarez, 2011</a>). Thus, we used P<sub>mem</sub> estimates from one experimental condition to predict the inflection point in the precision by set size function in the other condition (i.e., P<sub>mem</sub> from the ungrouped condition was correlated with precision inflections in grouped condition, and vice versa.). Replicating our previous work (<a href="#R1" rid="R1" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865132">Anderson et al., 2011</a>) we observed a strong correlation between storage estimates and inflections in precision in both the ungrouped and grouped conditions (<em>R</em><sup>2</sup> = .39, <em>p</em> &#x0003c; .01, and <em>R</em><sup>2</sup> = .30, <em>p</em> &#x0003c; .01, respectively). Thus, the observed plateau in precision is well explained by the hypothesis that no further items can be encoded once individual item limits are exceeded.</p><p id="P19">We considered the possibility that P<sub>mem</sub> was correlated with the inflection point in the precision function simply because both are measures of &#x0201c;performance,&#x0201d; rather than because of a specific relationship between item limits and the set size at which precision reaches a plateau. Actually, we see this as a reformulation of our initial prediction, to the extent that both measures were argued to reflect the number of items that could be stored in WM. It should be noted, however, that this correlation cannot be explained by continuous resource models that eschew item limits, because that class of models can only account for the apparent guessing rate (P<sub>f</sub>) by appealing to possibilities such as target mislocalization (<a href="#R4" rid="R4" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880784">Bays, Catalao, &#x00026; Husain, 2009</a>) or very low-resolution representations (<a href="#R29" rid="R29" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865126">van den Berg et al., 2012</a>). Not only are both of those alternative explanations inconsistent with the observed plateau in precision, neither explanation predicts any correlation between P<sub>mem</sub> and the set size at which precision reaches a plateau. Moreover, we high-light the fact that P<sub>mem</sub> was not correlated with other measures of &#x0201c;performance,&#x0201d; such as mnemonic precision; <em>SD</em> was not correlated with P<sub>mem</sub> at any set size or condition (<em>p</em> &#x0003e; .17), nor was the asymptotic value of the precision by set size functions correlated with P<sub>mem</sub> (<em>p</em> = .61). These findings establish the divergent validity of the item-limit measure, and replicate past findings indicating that number and precision reflect distinct aspects of memory ability (Fukuda, Vogel, Mayr, &#x00026; Awh, 2009). Thus, the correlation between individual item limits and the inflection point in the precision by set size function cannot be explained by a broad dependency between all measures of competence in this task. Instead, the correlation falls in line with a specific account of how precision should stabilize when putative item limits are exceeded.</p><p id="P20" class="p p-last">Another possible criticism of the evidence we have presented is that P<sub>mem</sub> explained about 35% of the variance in the set size at which precision reached a plateau, rather than exhibiting a perfect correlation. In other words, given that both measures were argued to reflect a common item limit in memory, why wasn&#x02019;t the correlation between these scores closer to the reliability of the measures themselves? We believe this is a flawed criticism, because it presumes that each measure is &#x0201c;process pure&#x0201d; such that no other ability or influence has any effect on the observed score; it has long been acknowledged that no task is pure in this way (e.g., <a href="#R22" rid="R22" class=" bibr popnode">Jacoby, 1991</a>). For instance, although we are relying on P<sub>mem</sub> as an operational definition of the number of items stored in working memory, this score is surely influenced by multiple other aspects of ability (e.g., extemporaneous grouping of angles, retrieval of traces from long term episodic memory, momentary lapses of attention, etc.). Likewise, our measure of the inflection point in the precision by set size function required us to fit a bilinear function to the observed precision by set size functions at the individual subject level. Not surprisingly, these bilinear fits were not perfect (mean <em>r</em><sup>2</sup> fit = .78 and .9 in the ungrouped and grouped conditions, respectively), and this logically precludes a perfect correlation between the inflection point of the fitted bilinear function and P<sub>mem</sub>. In addition, there are surely other sources of noise in our measure of precision (e.g., occasional use of categorical codes, errors in wielding the mouse to indicate the stored angle, etc.) that would further diminish the strength of the predicted correlation. These factors notwithstanding, the observed r values for the grouped and ungrouped conditions (.62 and .54, respectively) are viewed by convention as &#x0201c;large&#x0201d; effects (<a href="#R11" rid="R11" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880798">Cohen, 1992</a>). Finally, we reiterate the point that regardless of the absolute strength of the effect, discrete resource models directly predict this correlation while continuous resource models are at a loss to explain it. Thus, there is strong inferential value in documenting these &#x0201c;large&#x0201d; correlations, because they distinguish between competing theoretical accounts.</p></div></div><div id="S9" class="sec"><h3 id="S9title">Experiment 1b</h3><p id="P21" class="p p-first">Experiment 1b replicated the findings from the grouped condition in Experiment 1a, but here we used a larger range of set sizes (2&#x02013;12) that allowed a direct observation of the predicted plateau in precision between 8 and 12 elements.</p><div id="S10" class="sec sec-last"><p></p><h4 id="S10title" class="inline">Results and Discussion </h4><p id="P22" class="p p-first-last">We observed an initial decline in precision as a function of set size: set size 2 (<em>M</em> = 10.56) to set size 4 (<em>M</em> = 13.23; <em>t</em>(17) = &#x02212;7.39, <em>p</em> &#x0003c; .001); set size 4 to set size 6 (<em>M</em> = 14.82; <em>t</em>(17) = &#x02212;3.87, <em>p</em> &#x0003c; .001); set size 6 to set size 8 (<em>M</em> = 16.34; <em>t</em>(17) = &#x02212;2.47, <em>p</em> &#x0003c; .05), followed by a statistical asymptote at larger set sizes: set size 8 to set size 10 (<em>M</em> = 16.46; <em>t</em>(17) = &#x02212;.47, <em>p</em> = .66); set size 10 to set size 12 (<em>M</em> = 16.21; <em>t</em>(17) = &#x02212;.41, <em>p</em> = .69). When fitted with a bilinear function (<a href="/pmc/articles/PMC4068940/figure/F4/" target="figure" class="fig-table-link figpopup" rid-figpopup="F4" rid-ob="ob-F4" co-legend-rid="lgnd_F4"><span>Figure 4A</span></a>; <em>R</em><sup>2</sup> = .992, <em>p</em> &#x0003c; .001), we observed a calculated point of inflection at 7.25 objects, which was similar to the mean inflection of 7.73 observed across individual subjects (black dotted line in <a href="/pmc/articles/PMC4068940/figure/F4/" target="figure" class="fig-table-link figpopup" rid-figpopup="F4" rid-ob="ob-F4" co-legend-rid="lgnd_F4"><span>Figure 4A</span></a>; average <em>R</em><sup>2</sup> of bilinear fits = .77). Consistent with our predictions, the inflection point in the grouped condition occurred at a set size that was approximately double the size as the inflection point observed in the ungrouped condition in Experiment 1a (4.03). These results corroborated the findings of Experiment 1a by demonstrating a clear plateau between set sizes 8 and 12 in the grouped condition, without being troubled by potential ceiling effects in the inflection point of the precision by set size function.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="F4" co-legend-rid="lgnd_F4"><a href="/pmc/articles/PMC4068940/figure/F4/" target="figure" rid-figpopup="F4" rid-ob="ob-F4"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139702353872576" class="figure"><a class="inline_block ts_canvas" href="/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=4068940_nihms589839f4.jpg" target="tileshopwindow"><div class="ts_bar small" title="Click on image to zoom"></div><img alt="An external file that holds a picture, illustration, etc.&#10;Object name is nihms589839f4.jpg" title="Click on image to zoom" class="tileshop" src="/pmc/articles/PMC4068940/bin/nihms589839f4.jpg" /></a></div><div id="largeobj_idm139702353872576" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC4068940/figure/F4/?report=objectonly">Open in a separate window</a></div></a><div class="icnblk_cntnt" id="lgnd_F4"><div><a class="figpopup" href="/pmc/articles/PMC4068940/figure/F4/" target="figure" rid-figpopup="F4" rid-ob="ob-F4">Figure 4</a></div><!--caption a7--><div class="caption"><p id="__p6">Stimulus displays and parameter estimates from Experiments 1b and c. (A) Precision by set size function and bilinear fit from Experiment 1b, which examined only grouped displays and extended the maximum set size to 12 items. The precision by set size function was fitted with a bilinear function (gray line), and the inflection point of the aggregate data was similar to the average inflection point obtained across observers (dotted black line). (B) Stimulus displays from Experiment 1c. Displays consisted of six elements each, with five elements that were radially arranged around a central element. For each of the five outer items, there were three possible orientation values, such that each possible orientation pointed directly towards the one of the nearest neighbors of that element. The central item could face any of the five peripheral items (C,D) Model parameters from Experiment 1c. A significant effect of grouping was observed for both <em>SD</em> (<em>p</em> &#x0003c; .05) and Pmem (<em>p</em> &#x0003c; .01) measures. Error bars represent the 95% confidence interval.</p></div></div></div></div></div><div id="S11" class="sec sec-last"><h3 id="S11title">Experiment 1c</h3><p id="P23" class="p p-first">We argue that the precision and storage effects observed in the grouped condition reflect the storage of perceptual groups as single, discrete items in WM. One alternative explanation is that observers simply remembered the locations of each element in the grouped condition rather than the orientations of disks. This is a plausible hypothesis because the orientation of each item within a pair (in the grouped condition) always pointed directly toward the other element in the pair; thus, observers may have simply reported the orientation value that pointed toward the probed element&#x02019;s &#x0201c;partner&#x0201d; within the same group. This hypothesis will be strongly challenged by the electrophysiological data from Experiment 2, because we find that each pair elicits selection- and storage-related neural activity commensurate with that of a single item, rather than that of two items as this location-based strategy predicts. Nevertheless, Experiment 1c was intended to provide a behavioral test of whether grouping benefits could be observed when the grouped and ungrouped conditions were equally constrained with respect to possible orientation values. To this end, we created displays in which each item always pointed toward the centroid of an adjacent item in both the grouped and ungrouped displays (see <a href="/pmc/articles/PMC4068940/figure/F4/" target="figure" class="fig-table-link figpopup" rid-figpopup="F4" rid-ob="ob-F4" co-legend-rid="lgnd_F4"><span>Figure 4B</span></a>).</p><p id="P24" class="p">The sample displays in Experiment 1c consisted of six elements each, with five elements that were radially arranged around a central element. For each of the five outer items, there were three possible orientation values, such that each possible orientation pointed directly toward the one of the nearest neighbors of that element. The interitem distances were identical to those in Experiment 1a. The central item could face any of the five peripheral items. With this design, the possible orientation values were equally constrained in the grouped and ungrouped conditions. In this case, a reliable advantage for memory performance in the grouped condition could not be explained by more rigid constraints on the possible positions in the grouped condition.</p><div id="S12" class="sec sec-last"><p></p><h4 id="S12title" class="inline">Results and Discussion </h4><p id="P25" class="p p-first-last">The results from this control experiment (<a href="/pmc/articles/PMC4068940/figure/F4/" target="figure" class="fig-table-link figpopup" rid-figpopup="F4" rid-ob="ob-F4" co-legend-rid="lgnd_F4"><span>Figure 4C, D</span></a>) once again showed that both P<sub>mem</sub>, <em>t</em>(5) = 3.39, <em>p</em> &#x0003c; .05; <a href="/pmc/articles/PMC4068940/figure/F4/" target="figure" class="fig-table-link figpopup" rid-figpopup="F4" rid-ob="ob-F4" co-legend-rid="lgnd_F4"><span>Figure 4D</span></a> and precision, <em>t</em>(5) = 5.97, <em>p</em> &#x0003c; .01; <a href="/pmc/articles/PMC4068940/figure/F4/" target="figure" class="fig-table-link figpopup" rid-figpopup="F4" rid-ob="ob-F4" co-legend-rid="lgnd_F4"><span>Figure 4C</span></a> were superior in the grouped condition. Since the memoranda in both conditions were constrained to the same number of possible sample orientations, and each stimulus always pointed toward an adjacent neighbor, grouping benefits cannot be explained solely by the opportunity to extrapolate the sample orientation based on knowledge of the spatial positions of nearby display elements.</p></div></div></div><div id="S13" class="tsec sec"><h2 class="head no_bottom_margin" id="S13title">Experiment 2</h2><p id="P26" class="p p-first">Experiments 1a, b, and c demonstrated that perceptual grouping increased the number of elements that could be stored, as well as the set size at which mnemonic resolution reached a plateau. The precise size of these effects was predicted by a discrete resource model in which each perceptual group occupied one of a fixed number of &#x0201c;slots.&#x0201d; In Experiment 2, we corroborated these findings with neural measures that have been shown to index the number of discrete items that are encoded and stored in visual WM. The key question was whether perceptual grouping of pairs of element would lead to a halving of set size-dependent neural responses, in line with the claim that each perceptual group counts as a single &#x0201c;item.&#x0201d; To measure the number of discrete units encoded into working memory, we relied on the N2pc component, a phasic electrophysiological response that occurs approximately 200 ms following the onset of a stimulus that summons visual attention (<a href="#R23" rid="R23" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880795">Luck &#x00026; Hillyard, 1994</a>). Past studies have shown that N2pc amplitude increases monotonically with set size during the presentation of items during a dynamic tracking task (<a href="#R15" rid="R15" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880823">Drew &#x00026; Vogel, 2008</a>), during the encoding of items to be stored in WM (<a href="#R1" rid="R1" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865128">Anderson et al., 2011</a>), and during rapid enumeration (<a href="#R20" rid="R20" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880791">Ester, Drew, Klee, Vogel, and Awh, 2012</a>). Importantly, the observed rise in amplitude between set sizes predicts behavioral success in these tasks, suggesting that the N2pc provides a valid measure of the number of &#x0201c;items&#x0201d; processed within a display. For example, <a href="#R1" rid="R1" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865119">Anderson et al. (2011)</a> found that N2pc amplitude followed a bilinear function with rising set size, with the inflection point of this function predicting the number of items that each observer could store. Thus, N2pc amplitude tracks individual differences in the number of items than can be selected. By contrast, the contralateral delay activity (CDA) is a later sustained negative wave whose amplitude rises as set size increases and plateaus at a set size that predicts WM capacity (<a href="#R25" rid="R25" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880820">McCollough et al., 2007</a>; <a href="#R31" rid="R31" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880833">Vogel &#x00026; Machizawa, 2004</a>). Thus, we used these event-related potential (ERP) components to measure whether perceptual grouping of pairs of items would lead to a halving of selection and storage-related electrophysiological responses. This would complement the conclusions of Experiment 1 in three important ways. First, these neural measures provide a qualitatively different way to measure the number of discrete &#x0201c;units&#x0201d; that are selected and stored; thus, this approach can provide strong converging evidence with the behavioral data. For instance, if observers were employing the location-based strategy that motivated Experiment 1c, then we should find no decrease in storage related neural activity in the grouped condition because there would have been no reduction in the number of stored items. Second, while the behavioral measures in Experiment 1 suggested that online storage was enhanced by perceptual grouping, it is also possible that perceptual grouping affected the availability of information stored in long term memory. If subjects had superior episodic memories for perceptual groups, then behavioral capacity estimates could reflect a combination of information maintained in online memory and information retrieved from long term memory when the test item was cued. While this alternative interpretation is difficult to rule out with behavioral data alone, the neural measure of storage provided by the CDA is unambiguously attributable to &#x0201c;online&#x0201d; memory storage rather than more passive modes of storage. Thus, corroborating the behavioral data using these measures would solidify the conclusion that perceptual grouping modifies the number of &#x0201c;units&#x0201d; stored in working memory per se. Finally, the N2pc component provided more fine-grained information about the earliest stages of processing that are affected by perceptual grouping, because this neural response occurs only 200 ms following the onset of the sample array. To anticipate the findings, both storage and earlier stages of visual selection were determined by the number of perceived groups, such that each perceptual group evoked a response commensurate with the response to a single ungrouped element.</p><div id="S14" class="sec"><h3 id="S14title">Methods</h3><div id="S15" class="sec sec-first"><p></p><h4 id="S15title" class="inline">Subjects </h4><p id="P27" class="p p-first-last">A total of 35 undergraduates at the University of Oregon completed the experiment for monetary compensation. All had normal or corrected-to-normal visual acuity and gave informed consent according to procedures approved by the University of Oregon institutional review board.</p></div><div id="S16" class="sec"><p></p><h4 id="S16title" class="inline">Stimulus displays </h4><p id="P28" class="p p-first-last">Stimulus displays were identical to Experiment 1, with the following exceptions; 1) viewing distances were approximately 100 cm; 2) objects had radii of .43&#x000b0; of visual angle; 3) objects were presented within two imaginary rectangles subtending 3.86&#x000b0; &#x000d7; 4.30&#x000b0; of visual angle, each centered 2.86&#x000b0; to the left and right of a central diamond fixation of .57&#x000b0; &#x000d7; .57 &#x000b0; visual angle.</p></div><div id="S17" class="sec"><p></p><h4 id="S17title" class="inline">Procedures </h4><p id="P29" class="p p-first-last">Experiment 2 took approximately 2.5 hours to complete and was composed of 16 blocks of 64 trials each. The events in a single trial of Experiment 2 went as follows. Prior to the onset of the memoranda, the black central fixation briefly changed to a cue, which was blue on one side and yellow on the other, for 500 ms. Subjects were instructed to pay attention only to the side of the screen indicated by one of the two fixation colors (counterbalanced across subjects). This cue was followed by the presentation of two or four memoranda for 200 ms. On the unattended side, an irrelevant display of the same number items appeared (to match visual stimulation across the two hemifields). The constraints of grouped and ungrouped conditions were identical to Experiment 1. A 1000-ms delay period followed the offset of the disks. Following the delay, a probe ring appeared in the position of one item that had been randomly selected from the cued hemifield. Subjects clicked on the perimeter of this ring in an unspeeded response to indicate the orientation of the sample item that had appeared in the same position. Each response was followed by a 750-ms blank intertrial interval.</p></div><div id="S18" class="sec"><p></p><h4 id="S18title" class="inline">Modeling response error distributions </h4><p id="P30" class="p p-first-last">Modeling procedures were identical to those used in Experiment 1.</p></div><div id="S19" class="sec sec-last"><p></p><h4 id="S19title" class="inline">Electrophysiological recording and analysis </h4><p id="P31" class="p p-first">ERPs were recorded using our standard recording and analysis procedures, including rejection of trials contaminated by blocking, blinks, or large (&#x0003e;1&#x000b0;) eye movements (<a href="#R30" rid="R30" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880801">Vogel et al., 1998</a>; <a href="#R25" rid="R25" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880787">McCollough et al., 2007</a>). We recorded from 22 tin electrodes mounted in an elastic cap (Electrocap International, Eaton, OH) using the International 10/20 System. 10/20 sites F3, FZ, F4, T3, C3, CZ, C4, T4, P3, PZ, P4, T5, T6, O1, and O2 were used along with five nonstandard sites: OL midway between T5 and O1; OR midway between T6 and O2; PO3 midway between P3 and OL; PO4 midway between P4 and OR; and POz midway between PO3 and PO4. All sites were recoded with a left-mastoid reference, and the data were rereferenced off-line to the algebraic average of the left and right mastoids. Horizontal electrooculogram (EOG) was recorded from electrodes placed ~1 cm to the left and right of the external canthi of each eye to measure horizontal eye movements. To detect blinks, vertical EOG was recorded from an electrode mounted beneath the left eye and referenced to the left mastoid. Any trials containing either a blink or eye movement were excluded from further analysis. Subjects with trial rejection rates &#x0003e;20% were excluded from the sample.</p><p id="P32" class="p p-last">Contralateral waveforms were computed by averaging the activity recorded over the right hemisphere when subjects attended items in the array at the left side of screen and the left hemisphere when subjects attended items in the array at the right side of the screen. Contralateral working memory activity was measured at posterior parietal, lateral occipital, posterior temporal, parietal, and occipital electrode sites as the difference in mean amplitude between the ipsilateral and contralateral waveforms. We used two measurement windows: 225&#x02013;300 ms after the onset of the memory display for the N2pc analyses and 400&#x02013;1000 ms for the CDA analyses. The EEG and EOG were amplified with an SA Instrumentation (San Diego, CA) amplifier with a bandpass of 0.01&#x02013;80 Hz and were digitized at 250 Hz in LabView 6.1 running on a PC.</p></div></div><div id="S20" class="sec"><h3 id="S20title">Results and Discussion</h3><p id="P33" class="p p-first-last">Separate repeated-measures ANOVAs were carried out on the parameter estimates (P<sub>mem</sub> and <em>SD</em>) from each observer&#x02019;s response error histogram, with set size (2 or 4) and grouping condition (grouped vs. ungrouped) as factors. Replicating the findings from Experiment 1, there was a significant effect of set size, <em>F</em>(1, 34) = 289.82, <em>p</em> 3&#x0003c; .001 and grouping, <em>F</em>(1, 34) = 84.06, <em>p</em> &#x0003c; .001 on P<sub>mem</sub> (<a href="/pmc/articles/PMC4068940/figure/F5/" target="figure" class="fig-table-link figpopup" rid-figpopup="F5" rid-ob="ob-F5" co-legend-rid="lgnd_F5"><span>Figure 5B</span></a>). The effect of perceptual grouping on P<sub>mem</sub> was larger in the set size 4 condition (presumably because even without grouping observers tended to be successful in the set size 2 condition), leading to a significant interaction between set size and grouping, <em>F</em>(1, 34) = 63.74, <em>p</em> &#x0003c; .001. Thus, just as in Experiment 1, perceptual grouping enhanced the probability that each element would be stored relative to an ungrouped condition. Also replicating Experiment 1, we observed significant effects of set size, <em>F</em>(1, 34) = 36.45, <em>p</em> &#x0003c; .001 and grouping, <em>F</em>(1, 34) = 111.86, <em>p</em> &#x0003c; .001 on mnemonic precision (<em>SD</em>; <a href="/pmc/articles/PMC4068940/figure/F5/" target="figure" class="fig-table-link figpopup" rid-figpopup="F5" rid-ob="ob-F5" co-legend-rid="lgnd_F5"><span>Figure 5A</span></a>). The interaction between set size and grouping was not significant (<em>p</em> &#x0003e; .23). As in Experiment 1, precision in the set size 2 ungrouped condition was worse than when four elements were grouped into two items, set size 4 grouped; <em>t</em>(34) = 6.08, <em>p</em> &#x0003c; .001, and precision was better for set size 2 than for set size 4, <em>t</em>(34) = 3.96, <em>p</em> &#x0003c; .001. Again, we speculate that the precision advantage in the grouped condition was driven by the larger aspect ratio observed in the perceptual groups compared to single elements, which may facilitate the initial encoding of orientations.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="F5" co-legend-rid="lgnd_F5"><a href="/pmc/articles/PMC4068940/figure/F5/" target="figure" rid-figpopup="F5" rid-ob="ob-F5"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139702433216512" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.&#10;Object name is nihms589839f5.jpg" title="An external file that holds a picture, illustration, etc.&#10;Object name is nihms589839f5.jpg" src="/pmc/articles/PMC4068940/bin/nihms589839f5.jpg" /></div><div id="largeobj_idm139702433216512" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC4068940/figure/F5/?report=objectonly">Open in a separate window</a></div></a><div class="icnblk_cntnt" id="lgnd_F5"><div><a class="figpopup" href="/pmc/articles/PMC4068940/figure/F5/" target="figure" rid-figpopup="F5" rid-ob="ob-F5">Figure 5</a></div><!--caption a7--><div class="caption"><p id="__p7">Precision and capacity estimates from Experiment 2. (A) The decline in precision across set size was significant for both grouped (dotted line) and ungrouped (solid line) conditions (<em>p</em> &#x0003c; .001), and the effect of grouping on precision was significant (<em>p</em> &#x0003c; .001). (B) The decline in the probability of storage across set size was significant for both grouped (dotted line) and ungrouped (solid line) conditions (<em>p</em> &#x0003c; .001), and the effect of grouping on the probability of storage was significant (<em>p</em> &#x0003c; .001). Error bars represent the 95% confidence interval.</p></div></div></div></div><div id="S21" class="sec sec-last"><h3 id="S21title">Electrophysiological Data</h3><p id="P34" class="p p-first">We examined the N2pc, which measures the number of items that can be simultaneously selected, and the CDA, which indexes online storage load. Both ERP components were apparent at electrodes P3/P4, PO3/PO4, and OL/OR. We plotted difference waves (ipsilateral activity subtracted from contralateral activity across the three electrode pairs; see <a href="/pmc/articles/PMC4068940/figure/F6/" target="figure" class="fig-table-link figpopup" rid-figpopup="F6" rid-ob="ob-F6" co-legend-rid="lgnd_F6"><span>Figures 6A</span></a> and <a href="/pmc/articles/PMC4068940/figure/F7/" target="figure" class="fig-table-link figpopup" rid-figpopup="F7" rid-ob="ob-F7" co-legend-rid="lgnd_F7"><span style="position: relative;text-decoration:none;">&#x200B;<span class="figpopup-sensitive-area" style="left: -1.5em;">and7A</span></span><span>7A</span></a> for average difference waves) for each condition. We first took the mean amplitude across the N2pc (first shaded gray region in <a href="/pmc/articles/PMC4068940/figure/F6/" target="figure" class="fig-table-link figpopup" rid-figpopup="F6" rid-ob="ob-F6" co-legend-rid="lgnd_F6"><span>Figure 6A</span></a>) time window for each condition to examine the effects of set size and grouping on the amplitude of the N2pc (<a href="/pmc/articles/PMC4068940/figure/F6/" target="figure" class="fig-table-link figpopup" rid-figpopup="F6" rid-ob="ob-F6" co-legend-rid="lgnd_F6"><span>Figure 6B</span></a>). This procedure revealed a main effect of set size, <em>F</em>(1, 34) = 12.80, <em>p</em> &#x0003c; .001 and grouping, <em>F</em>(1, 34) = 11.65, <em>p</em> &#x0003c; .01 on N2pc amplitude. It is critical that whereas N2pc amplitude was statistically larger when four ungrouped elements (set size 4 ungrouped) were encoded, as compared with when four elements were grouped into two pairs (set size 4 grouped), <em>t</em>(34) = 2.10, <em>p</em> &#x0003c; .05, N2pc amplitude was statistically equivalent when two ungrouped elements were encoded (set size 2 ungrouped), as compared with when 4 elements were grouped into two pairs, set size 4 grouped; <a href="/pmc/articles/PMC4068940/figure/F7/" target="figure" class="fig-table-link figpopup" rid-figpopup="F7" rid-ob="ob-F7" co-legend-rid="lgnd_F7"><span>Figure 7B</span></a>; <em>t</em>(34) = .86, <em>p</em> &#x0003e; .40. This result suggests that early stages of visual selection are altered by perceptual grouping, such that grouped pairs of elements evoke the same neural response as a single ungrouped element. We also observed a significant correlation between WM capacity and the difference in N2pc amplitude between set size 2 and set size 4 (<a href="/pmc/articles/PMC4068940/figure/F6/" target="figure" class="fig-table-link figpopup" rid-figpopup="F6" rid-ob="ob-F6" co-legend-rid="lgnd_F6"><span>Figure 6C</span></a>; <em>R</em><sup>2</sup> = .27, <em>p</em> &#x0003c; .01), consistent with past work (<a href="#R1" rid="R1" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865118">Anderson, Vogel, &#x00026; Awh, 2011</a>; <a href="#R15" rid="R15" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880790">Drew &#x00026; Vogel, 2008</a>). Thus, we find that individuals who can store more items in WM have the capacity to individuate more items during selection.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="F6" co-legend-rid="lgnd_F6"><a href="/pmc/articles/PMC4068940/figure/F6/" target="figure" rid-figpopup="F6" rid-ob="ob-F6"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139702436272688" class="figure"><a class="inline_block ts_canvas" href="/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=4068940_nihms589839f6.jpg" target="tileshopwindow"><div class="ts_bar small" title="Click on image to zoom"></div><img alt="An external file that holds a picture, illustration, etc.&#10;Object name is nihms589839f6.jpg" title="Click on image to zoom" class="tileshop" src="/pmc/articles/PMC4068940/bin/nihms589839f6.jpg" /></a></div><div id="largeobj_idm139702436272688" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC4068940/figure/F6/?report=objectonly">Open in a separate window</a></div></a><div class="icnblk_cntnt" id="lgnd_F6"><div><a class="figpopup" href="/pmc/articles/PMC4068940/figure/F6/" target="figure" rid-figpopup="F6" rid-ob="ob-F6">Figure 6</a></div><!--caption a7--><div class="caption"><p id="__p8">(A) Grand averaged difference waves from P3/P4, PO3/PO4, and OL/OR electrodes. The gray bars indicate the temporal windows used to measure N2pc and CDA amplitudes. (B) N2pc amplitude as a function of set size and grouping condition. The increase in amplitude with set size (<em>p</em> &#x0003c; .001) and the decrease in amplitude in the grouped condition (red) relative to the ungrouped condition (blue) were significant (<em>p</em> &#x0003c; .01). (C) Correlation (<em>p</em> &#x0003c; .01) between the rise in N2pc amplitude with increasing set size as a function of capacity estimates (<em>p</em> &#x0003c; .01). (D) CDA amplitude as a function of set size and grouping condition. The increase in amplitude with set size (<em>p</em> &#x0003c; .01) and the decrease in amplitude in the grouped condition (red) relative to the ungrouped condition (blue) were significant (<em>p</em> &#x0003c; .001). (E) Correlation (<em>p</em> &#x0003c;) between the rise in CDA amplitude with increasing set size as a function of capacity estimates (<em>p</em> &#x0003c; .01). Error bars represent the 95% confidence interval.</p></div></div></div><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm clearfix" id="F7" co-legend-rid="lgnd_F7"><a href="/pmc/articles/PMC4068940/figure/F7/" target="figure" rid-figpopup="F7" rid-ob="ob-F7"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139702438438880" class="figure"><img class="fig-image" alt="An external file that holds a picture, illustration, etc.&#10;Object name is nihms589839f7.jpg" title="An external file that holds a picture, illustration, etc.&#10;Object name is nihms589839f7.jpg" src="/pmc/articles/PMC4068940/bin/nihms589839f7.jpg" /></div><div id="largeobj_idm139702438438880" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC4068940/figure/F7/?report=objectonly">Open in a separate window</a></div></a><div class="icnblk_cntnt" id="lgnd_F7"><div><a class="figpopup" href="/pmc/articles/PMC4068940/figure/F7/" target="figure" rid-figpopup="F7" rid-ob="ob-F7">Figure 7</a></div><!--caption a7--><div class="caption"><p id="__p9">(A) Grand averaged difference waves for critical conditions containing two perceived items (two ungrouped items and two grouped pairs of items). The gray bars indicate the temporal windows used to measure N2pc and CDA amplitudes. (B) N2pc amplitude and (C) CDA amplitude was equivalent between displays containing either two ungrouped items or two grouped pairs of items. Error bars represent the 95% confidence interval.</p></div></div></div><p id="P35">We then took the mean amplitude across the CDA (second shaded gray region in <a href="/pmc/articles/PMC4068940/figure/F6/" target="figure" class="fig-table-link figpopup" rid-figpopup="F6" rid-ob="ob-F6" co-legend-rid="lgnd_F6"><span>Figure 6A</span></a>) time window for each condition to examine the effects of set size and grouping on the amplitude of the CDA (<a href="/pmc/articles/PMC4068940/figure/F6/" target="figure" class="fig-table-link figpopup" rid-figpopup="F6" rid-ob="ob-F6" co-legend-rid="lgnd_F6"><span>Figure 6D</span></a>). This procedure revealed a main effect of set size, <em>F</em>(1, 34) = 7.99, <em>p</em> &#x0003c; .01 and grouping, <em>F</em>(1, 34) = 18.02, <em>p</em> &#x0003c; .001 on CDA amplitude. Thus, CDA amplitude was larger for set size 4 than for set size 2, <em>t</em>(35) = 2.88, <em>p</em> &#x0003c; .01, and CDA amplitude was reduced in the grouped condition relative to the ungrouped condition. Indeed, there was no observed difference in amplitude between storing two individual elements (set size 2 ungrouped) and two perceptual groups (set size 4 grouped), <a href="/pmc/articles/PMC4068940/figure/F7/" target="figure" class="fig-table-link figpopup" rid-figpopup="F7" rid-ob="ob-F7" co-legend-rid="lgnd_F7"><span>Figure 7C</span></a>; <em>t</em>(34) = 1.45, <em>p</em> &#x0003e; .15, whereas there was a reliable difference in amplitude between storing four individual elements (set size 4 ungrouped) and four elements grouped into two pairs (set size 4 grouped), <em>t</em>(34) = 2.89, <em>p</em> &#x0003c; .01. Thus, given past findings that the CDA provides a sensitive measure of the number of items stored in working memory, equivalent CDA amplitudes in the conditions with two individual elements and two perceptual groups suggest that perceptual grouping led to a halving of the number of representations stored. Replicating previous work (<a href="#R31" rid="R31" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880786">Vogel &#x00026; Machizawa, 2004</a>; <a href="#R25" rid="R25" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880797">McCollough, Machizawa, &#x00026; Vogel, 2007</a>) we also observed a strong relationship between WM capacity and the rise in CDA amplitude (<a href="/pmc/articles/PMC4068940/figure/F6/" target="figure" class="fig-table-link figpopup" rid-figpopup="F6" rid-ob="ob-F6" co-legend-rid="lgnd_F6"><span>Figure 6E</span></a>; <em>R</em><sup>2</sup> = .25, <em>p</em> &#x0003c; .01). Thus, storage-related neural activity also corroborates the conclusions from Experiment 1. Each perceptual group consumed the same mnemonic resources as a single item.</p><p id="P36" class="p p-last">The results of Experiment 2 provide robust converging evidence with the findings from Experiment 1. The finding that storage-related neural responses are determined by the perceived number of groups in a display strongly complements the behavioral findings from Experiment 1 by showing that perceptual groups directly affect the online maintenance of items in working memory, rather than being derived from enhanced long term memory or other strategies that are peripheral to active maintenance per se. In addition, the electrophysiological data provide new information regarding the time course of the modal completion effect generated by collinearity. Specifically, the N2pc data show that modal completion has been achieved within the first 200 ms after the stimuli appeared. This rapid time course also argues against the hypothesis that grouping benefits reflect changes in later decision-related stage of processing in these tasks. Finally, it is noteworthy that N2pc and CDA amplitudes were equivalent across strong changes in the physical characteristics of the displays (i.e., the doubling of elements in the 4-item grouped condition, as compared with the 2-item ungrouped condition), while the same components provided a sensitive measure of perceived set size and individual differences in storage ability. This corroborates the important assumption that these components measure the number of discrete &#x0201c;units&#x0201d; that are stored and selected, rather than physical aspects of the sample display such as the overall change in luminance or the display area occupied by the sample elements.</p></div></div><div id="S22" class="tsec sec"><h2 class="head no_bottom_margin" id="S22title">General Discussion</h2><p id="P37" class="p p-first">Because there are multiple levels of organization within a visual scene, it is useful to acknowledge a distinction between image- and scene-level representations (<a href="#R18" rid="R18" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880809">Enns &#x00026; Rensink, 1990</a>; <a href="#R19" rid="R19" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880802">Enns &#x00026; Rensink, 1991</a>). In the present work, an image-level description of the grouped stimuli might treat each individual disk as a separate element. By contrast, in a scene-level description of the same display, the collinear pairs of disks could be described as discrete units within the display, commensurate with the subjective perceptual experience of the observer. Thus, the memoranda can be described in a hierarchical fashion with at least two distinct levels of representation. Our primary conclusion is that storage in visual WM is constrained by a discrete item limit, but that an &#x0201c;item&#x0201d; is best defined by the perceptual groups that occupy top level of the observers&#x02019; hierarchical representation of the scene (<a href="#R8" rid="R8" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865122">Brady, Konkle, &#x00026; Alvarez, 2011</a>). This perspective on the &#x0201c;units&#x0201d; of storage in visual WM dovetails with recent work in the verbal domain, in which it has been shown that the capacity of verbal WM is determined not by the total number of words to be stored, but by the total number of chunks that are required to represent those words (<a href="#R13" rid="R13" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880794">Cowan, Chen &#x00026; Rouder, 2004</a>; <a href="#R10" rid="R10" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865129">Chen &#x00026; Cowan, 2009</a>). Thus, <a href="#R10" rid="R10" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865131">Chen and Cowan (2009)</a> demonstrated that a similar discrete capacity limit (three items) explained performance regardless of whether the &#x0201c;units&#x0201d; stored were clusters of associated words or single unrelated words. Here, we extend this finding to the visual domain to show that pairs of elements grouped by collinearity count as single &#x0201c;items&#x0201d; in an orientation WM task.</p><p id="P38">In Experiment 1, the key empirical pattern was the shape of the resolution by set size function for ungrouped and grouped elements. Replicating previous work (<a href="#R1" rid="R1" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_477865117">Anderson et al., 2011</a>), we found that mnemonic resolution in the ungrouped condition declined until set size 4, and then reached a stable plateau for all remaining set sizes. This plateau in mnemonic resolution is clearly predicted by discrete resource models which assert that no further items are encoded into WM after putative item limits are exceeded. Critically, we found evidence of a similar plateau when pairs of items were grouped via collinearity, but in this case the plateau was observed at a set size approximately twice that in the un-grouped condition. These results verify a clear signature of discrete item limits in the grouped condition, and fit the quantitative predictions of a model in which each grouped pair counted as a single item in visual WM. Experiment 2 corroborated these conclusions by showing that neural activity related to the number of items selected (N2pc) and stored (CDA) in WM was cut in half in the grouped condition, again consistent with the hypothesis that each perceptual group elicited a neural response commensurate with that of a single ungrouped item.</p><p id="P39">The visual world is rich with information, and the organization of this information can be quantized into discrete, perceptual groups that simultaneously belong to distinct and identical objects, depending on the level of organization. For example, the human body is a complex object that is composed of a hierarchical organization of smaller parts; each part is distinct from another, such as the arms and the legs, yet each part belongs to the body as a whole. In the current work, we manipulated the alignment of two distinct elements to form a strong subjective impression of a single oriented bar. We demonstrate that WM stores each of these perceptual groups as a single item, while maximum storage limits were still constrained by a discrete item limit. Another question raised by our findings is whether a discrete resource perspective will also be able to account for nonperceptual grouping effects in which the grouped elements do not elicit a strong subjective experience of a single &#x0201c;item.&#x0201d; For example, <a href="#R7" rid="R7" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880835">Brady, Konkle, and Alvarez (2009)</a> showed that when pairs of colors were regularly associated with each other across trials, observers were able to store those familiar pairs as efficiently as a single ungrouped item, despite the fact that the key statistical regularities were not associated with differences in low-level gestalt grouping cues. Recalling the findings of <a href="#R13" rid="R13" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880834">Cowan et al. (2004)</a>, in which familiar pairs of words were stored as efficiently as single words, we speculate that the memory compression effects reported by <a href="#R7" rid="R7" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880813">Brady et al. (2009)</a> will still fall in line with a discrete resource account. That said, statistical regularities might influence storage in a qualitatively different fashion for visual and verbal stimuli. Thus, it remains to be seen whether or not the memory compression effect observed by <a href="#R7" rid="R7" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_384880804">Brady et al. (2009)</a> will also be constrained by an underlying discrete resource limit.</p><p id="P40" class="p p-last">In conclusion, we found robust enhancements in WM performance when pairs of elements were perceptually grouped. In addition, in both the grouped and ungrouped conditions, we replicated prior findings showing a plateau in the precision by set size function. Moreover, the precise set size at which this plateau occurred was doubled in the grouped condition, indicating that each pair of items consumed the same proportion of mnemonic resources as a single ungrouped item. Thus, the unit of storage depends on the organization of the scene, and a common discrete resource limits the number of these units that can be stored. In other words, the enhanced storage of grouped elements reflects the optimization of the information stored within an otherwise fixed set of discrete &#x0201c;slots&#x0201d; rather than a change in the number of discrete items that can be maintained.</p></div><div id="S23" class="tsec sec"><h2 class="head no_bottom_margin" id="S23title">Acknowledgments</h2><div class="sec"><p id="__p2">Supported by NIH-R01MH077105 to Edward Awh. Edward K. Vogel, Edward Awh, and David E. Anderson conceived and designed the experiment. David E. Anderson collected and analyzed data. David E. Anderson, Edward K. Vogel, and Edward Awh wrote the manuscript.</p></div></div><div id="idm139702397368144" class="tsec sec"><h2 class="head no_bottom_margin" id="idm139702397368144title">References</h2><div class="ref-list-sec sec" id="reference-list"><ul class="back-ref-list" style="list-style-type:decimal;"><li id="R1"><span class="element-citation">Anderson DE, Vogel EK, Awh E. Precision in visual working memory reaches a stable plateau when individual item limits are exceeded. <span><span class="ref-journal">The Journal of Neuroscience. </span>2011;<span class="ref-vol">31</span>:1128–1138. doi: 10.1523/JNEUROSCI.4125-10.2011.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC4476280/">PMC free article</a>]</span> [<a href="/pubmed/21248137" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1523%2FJNEUROSCI.4125-10.2011" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=The+Journal+of+Neuroscience&amp;title=Precision+in+visual+working+memory+reaches+a+stable+plateau+when+individual+item+limits+are+exceeded&amp;author=DE+Anderson&amp;author=EK+Vogel&amp;author=E+Awh&amp;volume=31&amp;publication_year=2011&amp;pages=1128-1138&amp;pmid=21248137&amp;doi=10.1523/JNEUROSCI.4125-10.2011&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span><link class="retraction-forward" pmcaccid="PMC4549410" /> <a class="red" href="/pmc/articles/PMC4549410/">Retracted</a></span></li><li id="R2"><span class="element-citation">Awh E, Barton B, Vogel EK. Visual working memory represents a fixed number of items regardless of complexity. <span><span class="ref-journal">Psychological Science. </span>2007;<span class="ref-vol">18</span>:622–628. doi: 10.1111/j.1467-9280.2007.01949.x.</span> [<a href="/pubmed/17614871" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1111%2Fj.1467-9280.2007.01949.x" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Psychological+Science&amp;title=Visual+working+memory+represents+a+fixed+number+of+items+regardless+of+complexity&amp;author=E+Awh&amp;author=B+Barton&amp;author=EK+Vogel&amp;volume=18&amp;publication_year=2007&amp;pages=622-628&amp;pmid=17614871&amp;doi=10.1111/j.1467-9280.2007.01949.x&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R3"><span class="element-citation">Barton B, Ester EF, Awh E. Discrete resource allocation in visual working memory. <span><span class="ref-journal">Journal of Experimental Psychology: Human Perception and Performance. </span>2009;<span class="ref-vol">35</span>:1359–1367. doi: 10.1037/a0015792.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC2782709/">PMC free article</a>]</span> [<a href="/pubmed/19803642" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1037%2Fa0015792" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Journal+of+Experimental+Psychology:+Human+Perception+and+Performance&amp;title=Discrete+resource+allocation+in+visual+working+memory&amp;author=B+Barton&amp;author=EF+Ester&amp;author=E+Awh&amp;volume=35&amp;publication_year=2009&amp;pages=1359-1367&amp;pmid=19803642&amp;doi=10.1037/a0015792&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R4"><span class="element-citation">Bays PM, Catalao RFG, Husain M. The precision of visual working memory is set by allocation of a shared resource. <span><span class="ref-journal">Journal of Vision. </span>2009;<span class="ref-vol">9</span>:7–11. doi: 10.1167/9.10.7.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC3118422/">PMC free article</a>]</span> [<a href="/pubmed/19810788" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1167%2F9.10.7" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Journal+of+Vision&amp;title=The+precision+of+visual+working+memory+is+set+by+allocation+of+a+shared+resource&amp;author=PM+Bays&amp;author=RFG+Catalao&amp;author=M+Husain&amp;volume=9&amp;publication_year=2009&amp;pages=7-11&amp;pmid=19810788&amp;doi=10.1167/9.10.7&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R5"><span class="element-citation">Bays PM, Husain M. Dynamic shifts of limited working memory resources in human vision. <span><span class="ref-journal">Science. </span>2008;<span class="ref-vol">321</span>:851–854. doi: 10.1126/science.1158023.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC2532743/">PMC free article</a>]</span> [<a href="/pubmed/18687968" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1126%2Fscience.1158023" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Science&amp;title=Dynamic+shifts+of+limited+working+memory+resources+in+human+vision&amp;author=PM+Bays&amp;author=M+Husain&amp;volume=321&amp;publication_year=2008&amp;pages=851-854&amp;pmid=18687968&amp;doi=10.1126/science.1158023&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R6"><span class="element-citation">Brady TF, Fougnie D, Alvarez GA. Comparisons between different measures of working memory capacity must be made with estimates that are derived from independent data. <span><span class="ref-journal">Journal of Neuroscience Online. </span>2011 Oct 14;</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Journal+of+Neuroscience+Online&amp;title=Comparisons+between+different+measures+of+working+memory+capacity+must+be+made+with+estimates+that+are+derived+from+independent+data&amp;author=TF+Brady&amp;author=D+Fougnie&amp;author=GA+Alvarez&amp;publication_year=2011&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R7"><span class="element-citation">Brady TF, Konkle T, Alvarez GA. Compression in visual working memory: Using statistical regularities to form more efficient memory representations. <span><span class="ref-journal">Journal of Experimental Psychology: General. </span>2009;<span class="ref-vol">138</span>:487–502.</span> [<a href="/pubmed/19883132" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Journal+of+Experimental+Psychology:+General&amp;title=Compression+in+visual+working+memory:+Using+statistical+regularities+to+form+more+efficient+memory+representations&amp;author=TF+Brady&amp;author=T+Konkle&amp;author=GA+Alvarez&amp;volume=138&amp;publication_year=2009&amp;pages=487-502&amp;pmid=19883132&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R8"><span class="element-citation">Brady TF, Konkle T, Alvarez GA. A review of visual memory capacity: Beyond individual items and towards structured representations. <span><span class="ref-journal">Journal of Vision. </span>2011;<span class="ref-vol">11</span>:1–34. doi: 10.1167/11.5.4.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC3405498/">PMC free article</a>]</span> [<a href="/pubmed/21617025" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1167%2F11.5.4" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Journal+of+Vision&amp;title=A+review+of+visual+memory+capacity:+Beyond+individual+items+and+towards+structured+representations&amp;author=TF+Brady&amp;author=T+Konkle&amp;author=GA+Alvarez&amp;volume=11&amp;publication_year=2011&amp;pages=1-34&amp;doi=10.1167/11.5.4&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R9"><span class="element-citation">Brainard DH. The psychophysics toolbox. <span><span class="ref-journal">Spatial Vision. </span>1997;<span class="ref-vol">10</span>:433–436. doi: 10.1163/156856897X00357.</span> [<a href="/pubmed/9176952" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1163%2F156856897X00357" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Spatial+Vision&amp;title=The+psychophysics+toolbox&amp;author=DH+Brainard&amp;volume=10&amp;publication_year=1997&amp;pages=433-436&amp;pmid=9176952&amp;doi=10.1163/156856897X00357&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R10"><span class="element-citation">Chen ZJ, Cowan N. Core verbal working-memory capacity: The limit in words retained without covert articulation. <span><span class="ref-journal">Quarterly Journal of Experimental Psychology. </span>2009;<span class="ref-vol">62</span>:1420–1429. doi: 10.1080/17470210802453977.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC2693080/">PMC free article</a>]</span> [<a href="/pubmed/19048451" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1080%2F17470210802453977" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Quarterly+Journal+of+Experimental+Psychology&amp;title=Core+verbal+working-memory+capacity:+The+limit+in+words+retained+without+covert+articulation&amp;author=ZJ+Chen&amp;author=N+Cowan&amp;volume=62&amp;publication_year=2009&amp;pages=1420-1429&amp;doi=10.1080/17470210802453977&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R11"><span class="element-citation">Cohen J. A power primer. <span><span class="ref-journal">Psychological Bulletin. </span>1992;<span class="ref-vol">112</span>:155–159. doi: 10.1037/0033-2909.112.1.155.</span> [<a href="/pubmed/19565683" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1037%2F0033-2909.112.1.155" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Psychological+Bulletin&amp;title=A+power+primer&amp;author=J+Cohen&amp;volume=112&amp;publication_year=1992&amp;pages=155-159&amp;pmid=19565683&amp;doi=10.1037/0033-2909.112.1.155&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R12"><span class="element-citation">Cowan N. The magical number 4 in short-term memory: A reconsideration of mental storage capacity. <span><span class="ref-journal">Behavioral and Brain Sciences. </span>2001;<span class="ref-vol">24</span>:87–114. doi: 10.1017/S0140525X01003922.</span> [<a href="/pubmed/11515286" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1017%2FS0140525X01003922" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Behavioral+and+Brain+Sciences&amp;title=The+magical+number+4+in+short-term+memory:+A+reconsideration+of+mental+storage+capacity&amp;author=N+Cowan&amp;volume=24&amp;publication_year=2001&amp;pages=87-114&amp;pmid=11515286&amp;doi=10.1017/S0140525X01003922&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R13"><span class="element-citation">Cowan N, Chen ZJ, Rouder JN. Constant capacity in an immediate serial-recall task: A logical sequel to Miller (1956) <span><span class="ref-journal">Psychological Science. </span>2004;<span class="ref-vol">15</span>:634–640. doi: 10.1111/j.0956-7976.2004.00732.x.</span> [<a href="/pubmed/15327636" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1111%2Fj.0956-7976.2004.00732.x" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Psychological+Science&amp;title=Constant+capacity+in+an+immediate+serial-recall+task:+A+logical+sequel+to+Miller+(1956)&amp;author=N+Cowan&amp;author=ZJ+Chen&amp;author=JN+Rouder&amp;volume=15&amp;publication_year=2004&amp;pages=634-640&amp;pmid=15327636&amp;doi=10.1111/j.0956-7976.2004.00732.x&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R14"><span class="element-citation">Cowan N, Elliot EM, Saults JS, Morey CC, Mattox S, Hismjatullina A, Conway ARA. On the capacity of attention: Its estimation and its role in working memory and cognitive aptitudes. <span><span class="ref-journal">Cognitive Psychology. </span>2005;<span class="ref-vol">51</span>:42–100. doi: 10.1016/j.cogpsych.2004.12.001.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC2673732/">PMC free article</a>]</span> [<a href="/pubmed/16039935" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1016%2Fj.cogpsych.2004.12.001" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Cognitive+Psychology&amp;title=On+the+capacity+of+attention:+Its+estimation+and+its+role+in+working+memory+and+cognitive+aptitudes&amp;author=N+Cowan&amp;author=EM+Elliot&amp;author=JS+Saults&amp;author=CC+Morey&amp;author=S+Mattox&amp;volume=51&amp;publication_year=2005&amp;pages=42-100&amp;pmid=16039935&amp;doi=10.1016/j.cogpsych.2004.12.001&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R15"><span class="element-citation">Drew T, Vogel EK. Neural measures of individual differences in selecting and tracking multiple moving objects. <span><span class="ref-journal">The Journal of Neuroscience. </span>2008;<span class="ref-vol">28</span>:4183–4191. doi: 10.1523/JNEUROSCI.0556-08.2008.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC2570324/">PMC free article</a>]</span> [<a href="/pubmed/18417697" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1523%2FJNEUROSCI.0556-08.2008" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=The+Journal+of+Neuroscience&amp;title=Neural+measures+of+individual+differences+in+selecting+and+tracking+multiple+moving+objects&amp;author=T+Drew&amp;author=EK+Vogel&amp;volume=28&amp;publication_year=2008&amp;pages=4183-4191&amp;pmid=18417697&amp;doi=10.1523/JNEUROSCI.0556-08.2008&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R16"><span class="element-citation">Egly R, Driver J, Rafal RD. Shifting visual attention between objects and locations: Evidence from normal and parietal lesion subjects. <span><span class="ref-journal">Journal of Experimental Psychology: General. </span>1994;<span class="ref-vol">123</span>:161–177. doi: 10.1037/0096-3445.123.2.161.</span> [<a href="/pubmed/8014611" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1037%2F0096-3445.123.2.161" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Journal+of+Experimental+Psychology:+General&amp;title=Shifting+visual+attention+between+objects+and+locations:+Evidence+from+normal+and+parietal+lesion+subjects&amp;author=R+Egly&amp;author=J+Driver&amp;author=RD+Rafal&amp;volume=123&amp;publication_year=1994&amp;pages=161-177&amp;pmid=8014611&amp;doi=10.1037/0096-3445.123.2.161&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R17"><span class="element-citation">Engle RW. Working memory capacity as executive attention. <span><span class="ref-journal">Current Directions in Psychological Science. </span>2002;<span class="ref-vol">11</span>:19–23. doi: 10.1111/1467-8721.00160.</span> [<a href="//dx.doi.org/10.1111%2F1467-8721.00160" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Current+Directions+in+Psychological+Science&amp;title=Working+memory+capacity+as+executive+attention&amp;author=RW+Engle&amp;volume=11&amp;publication_year=2002&amp;pages=19-23&amp;doi=10.1111/1467-8721.00160&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R18"><span class="element-citation">Enns JT, Rensink RA. Influence of scene-based properties on visual search. <span><span class="ref-journal">Science. </span>1990;<span class="ref-vol">247</span>:721–723. doi: 10.1126/science.2300824.</span> [<a href="/pubmed/2300824" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1126%2Fscience.2300824" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Science&amp;title=Influence+of+scene-based+properties+on+visual+search&amp;author=JT+Enns&amp;author=RA+Rensink&amp;volume=247&amp;publication_year=1990&amp;pages=721-723&amp;pmid=2300824&amp;doi=10.1126/science.2300824&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R19"><span class="element-citation">Enns JT, Rensink RA. Preattentive recovery of 3-dimensional orientation from line drawings. <span><span class="ref-journal">Psychological Review. </span>1991;<span class="ref-vol">98</span>:335–351. doi: 10.1037/0033-295X.98.3.335.</span> [<a href="/pubmed/1891522" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1037%2F0033-295X.98.3.335" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Psychological+Review&amp;title=Preattentive+recovery+of+3-dimensional+orientation+from+line+drawings&amp;author=JT+Enns&amp;author=RA+Rensink&amp;volume=98&amp;publication_year=1991&amp;pages=335-351&amp;pmid=1891522&amp;doi=10.1037/0033-295X.98.3.335&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R20"><span class="element-citation">Ester EF, Drew T, Klee D, Vogel EK, Awh E. Neural measures reveal a fixed item limit in subitizing. <span><span class="ref-journal">The Journal of Neuroscience. </span>2012;<span class="ref-vol">32</span>:7169–7177. doi: 10.1523/JNEUROSCI.1218-12.2012.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC3370889/">PMC free article</a>]</span> [<a href="/pubmed/22623661" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1523%2FJNEUROSCI.1218-12.2012" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=The+Journal+of+Neuroscience&amp;title=Neural+measures+reveal+a+fixed+item+limit+in+subitizing&amp;author=EF+Ester&amp;author=T+Drew&amp;author=D+Klee&amp;author=EK+Vogel&amp;author=E+Awh&amp;volume=32&amp;publication_year=2012&amp;pages=7169-7177&amp;pmid=22623661&amp;doi=10.1523/JNEUROSCI.1218-12.2012&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R21"><span class="element-citation">Fukuda K, Vogel EK, Mayr U, Awh E. Quantity not quality: The relationship between fluid and working memory capacity. <span><span class="ref-journal">Psychonomic Bulletin &#x00026; Review. </span>2010;<span class="ref-vol">17</span>:673–679. doi: 10.3758/17.5.673.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC3050565/">PMC free article</a>]</span> [<a href="/pubmed/21037165" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.3758%2F17.5.673" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Psychonomic+Bulletin+&#x00026;+Review&amp;title=Quantity+not+quality:+The+relationship+between+fluid+and+working+memory+capacity&amp;author=K+Fukuda&amp;author=EK+Vogel&amp;author=U+Mayr&amp;author=E+Awh&amp;volume=17&amp;publication_year=2010&amp;pages=673-679&amp;pmid=21037165&amp;doi=10.3758/17.5.673&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R22"><span class="element-citation">Jacoby L. A process dissociation framework: Separating automatic from intentional uses of memory. <span><span class="ref-journal">Journal of Memory and Language. </span>1991;<span class="ref-vol">30</span>:513–541. doi: 10.1016/0749-596X(91)90025-F.</span> [<a href="//dx.doi.org/10.1016%2F0749-596X(91)90025-F" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Journal+of+Memory+and+Language&amp;title=A+process+dissociation+framework:+Separating+automatic+from+intentional+uses+of+memory&amp;author=L+Jacoby&amp;volume=30&amp;publication_year=1991&amp;pages=513-541&amp;doi=10.1016/0749-596X(91)90025-F&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R23"><span class="element-citation">Luck SJ, Hillyard SA. Electrophysiological correlates of feature analysis during visual search. <span><span class="ref-journal">Psychophysiology. </span>1994;<span class="ref-vol">31</span>:291–308. doi: 10.1111/j.1469-8986.1994.tb02218.x.</span> [<a href="/pubmed/8008793" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1111%2Fj.1469-8986.1994.tb02218.x" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Psychophysiology&amp;title=Electrophysiological+correlates+of+feature+analysis+during+visual+search&amp;author=SJ+Luck&amp;author=SA+Hillyard&amp;volume=31&amp;publication_year=1994&amp;pages=291-308&amp;pmid=8008793&amp;doi=10.1111/j.1469-8986.1994.tb02218.x&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R24"><span class="element-citation">Marr D.  <span class="ref-journal">Vision.</span> New York, NY: W. H. Freeman; 1982.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Vision&amp;author=D+Marr&amp;publication_year=1982&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R25"><span class="element-citation">McCollough AW, Machizawa MG, Vogel EK. Electrophysiological measures of maintaining representations in visual working memory. <span><span class="ref-journal">Cortex: A Journal Devoted to the Study of the Nervous System and Behavior. </span>2007;<span class="ref-vol">43</span>:77–94. doi: 10.1016/S0010-9452(08)70447-7.</span> [<a href="/pubmed/17334209" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1016%2FS0010-9452(08)70447-7" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Cortex:+A+Journal+Devoted+to+the+Study+of+the+Nervous+System+and+Behavior&amp;title=Electrophysiological+measures+of+maintaining+representations+in+visual+working+memory&amp;author=AW+McCollough&amp;author=MG+Machizawa&amp;author=EK+Vogel&amp;volume=43&amp;publication_year=2007&amp;pages=77-94&amp;pmid=17334209&amp;doi=10.1016/S0010-9452(08)70447-7&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R26"><span class="element-citation">Pelli DG. The VideoToolbox software for visual psychophysics: Transforming numbers into movies. <span><span class="ref-journal">Spatial Vision. </span>1997;<span class="ref-vol">10</span>:437–442. doi: 10.1163/156856897X00366.</span> [<a href="/pubmed/9176953" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1163%2F156856897X00366" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Spatial+Vision&amp;title=The+VideoToolbox+software+for+visual+psychophysics:+Transforming+numbers+into+movies&amp;author=DG+Pelli&amp;volume=10&amp;publication_year=1997&amp;pages=437-442&amp;pmid=9176953&amp;doi=10.1163/156856897X00366&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R27"><span class="element-citation">Rouder JN, Morey RD, Cowan N, Zwilling CE, Morey CC, Pratte MS. An assessment of fixed capacity models of visual working memory. <span><span class="ref-journal">Proceedings of the National Academy of Sciences. </span>2008;<span class="ref-vol">105</span>:5975–5979. doi: 10.1073/pnas.0711295105.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC2329704/">PMC free article</a>]</span> [<a href="/pubmed/18420818" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1073%2Fpnas.0711295105" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+National+Academy+of+Sciences&amp;title=An+assessment+of+fixed+capacity+models+of+visual+working+memory&amp;author=JN+Rouder&amp;author=RD+Morey&amp;author=N+Cowan&amp;author=CE+Zwilling&amp;author=CC+Morey&amp;volume=105&amp;publication_year=2008&amp;pages=5975-5979&amp;doi=10.1073/pnas.0711295105&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R28"><span class="element-citation">Sompolinsky H, Shapley R. New perspectives on the mechanisms for orientation selectivity. <span><span class="ref-journal">Current Opinions in Neurobiology. </span>1997;<span class="ref-vol">7</span>:514–522. doi: 10.1016/S0959-4388(97)80031-1.</span> [<a href="/pubmed/9287203" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1016%2FS0959-4388(97)80031-1" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Current+Opinions+in+Neurobiology&amp;title=New+perspectives+on+the+mechanisms+for+orientation+selectivity&amp;author=H+Sompolinsky&amp;author=R+Shapley&amp;volume=7&amp;publication_year=1997&amp;pages=514-522&amp;doi=10.1016/S0959-4388(97)80031-1&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R29"><span class="element-citation">van den Berg R, Shin H, Chou WC, George R, Ma WJ. Variability in encoding precision accounts for visual short-term memory limitations. <span><span class="ref-journal">PNAS: Proceedings of the National Academy of Sciences of the United States of America. </span>2012;<span class="ref-vol">109</span>:8780–8785. doi: 10.1073/pnas.1117465109.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC3365149/">PMC free article</a>]</span> [<a href="/pubmed/22582168" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1073%2Fpnas.1117465109" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=PNAS:+Proceedings+of+the+National+Academy+of+Sciences+of+the+United+States+of+America&amp;title=Variability+in+encoding+precision+accounts+for+visual+short-term+memory+limitations&amp;author=R+van+den+Berg&amp;author=H+Shin&amp;author=WC+Chou&amp;author=R+George&amp;author=WJ+Ma&amp;volume=109&amp;publication_year=2012&amp;pages=8780-8785&amp;doi=10.1073/pnas.1117465109&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R30"><span class="element-citation">Vogel EK, Luck SJ, Shapiro KL. Electrophysiological evidence for a postperceptual locus of suppression during the attentional blink. <span><span class="ref-journal">Journal of Experimental Psychology: Human Perception and Performance. </span>1998;<span class="ref-vol">24</span>:1656–1674. doi: 10.1037/0096-1523.24.6.1656.</span> [<a href="/pubmed/9861716" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1037%2F0096-1523.24.6.1656" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Journal+of+Experimental+Psychology:+Human+Perception+and+Performance&amp;title=Electrophysiological+evidence+for+a+postperceptual+locus+of+suppression+during+the+attentional+blink&amp;author=EK+Vogel&amp;author=SJ+Luck&amp;author=KL+Shapiro&amp;volume=24&amp;publication_year=1998&amp;pages=1656-1674&amp;pmid=9861716&amp;doi=10.1037/0096-1523.24.6.1656&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R31"><span class="element-citation">Vogel EK, Machizawa MG. Neural activity predicts individual differences in visual working memory capacity. <span><span class="ref-journal">Nature. </span>2004;<span class="ref-vol">428</span>:748–751. doi: 10.1038/nature02447.</span> [<a href="/pubmed/15085132" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1038%2Fnature02447" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Nature&amp;title=Neural+activity+predicts+individual+differences+in+visual+working+memory+capacity&amp;author=EK+Vogel&amp;author=MG+Machizawa&amp;volume=428&amp;publication_year=2004&amp;pages=748-751&amp;pmid=15085132&amp;doi=10.1038/nature02447&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R32"><span class="element-citation">Walker P, Davies SJ. Perceptual completion and object-based representations in short-term visual memory. <span><span class="ref-journal">Memory &#x00026; Cognition. </span>2003;<span class="ref-vol">31</span>:746–760. doi: 10.3758/BF03196113.</span> [<a href="/pubmed/12956239" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.3758%2FBF03196113" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Memory+&#x00026;+Cognition&amp;title=Perceptual+completion+and+object-based+representations+in+short-term+visual+memory&amp;author=P+Walker&amp;author=SJ+Davies&amp;volume=31&amp;publication_year=2003&amp;pages=746-760&amp;pmid=12956239&amp;doi=10.3758/BF03196113&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R33"><span class="element-citation">Wilken P, Ma WJ. A detection theory account of change detection. <span><span class="ref-journal">Journal of Vision. </span>2004;<span class="ref-vol">4</span>:1120–1135. doi: 10.1167/4.12.11.</span> [<a href="/pubmed/15669916" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1167%2F4.12.11" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Journal+of+Vision&amp;title=A+detection+theory+account+of+change+detection&amp;author=P+Wilken&amp;author=WJ+Ma&amp;volume=4&amp;publication_year=2004&amp;pages=1120-1135&amp;pmid=15669916&amp;doi=10.1167/4.12.11&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R34"><span class="element-citation">Woodman GF, Vecera SP, Luck SJ. Perceptual organization influences visual working memory. <span><span class="ref-journal">Psychonomic Bulletin &#x00026; Review. </span>2003;<span class="ref-vol">10</span>:80–87. doi: 10.3758/BF03196470.</span> [<a href="/pubmed/12747493" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.3758%2FBF03196470" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Psychonomic+Bulletin+&#x00026;+Review&amp;title=Perceptual+organization+influences+visual+working+memory&amp;author=GF+Woodman&amp;author=SP+Vecera&amp;author=SJ+Luck&amp;volume=10&amp;publication_year=2003&amp;pages=80-87&amp;pmid=12747493&amp;doi=10.3758/BF03196470&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R35"><span class="element-citation">Xu Y. Encoding objects in visual short-term memory: The roles of feature proximity and connectedness. <span><span class="ref-journal">Perception &#x00026; Psychophysics. </span>2006;<span class="ref-vol">68</span>:815–828. doi: 10.3758/BF03193704.</span> [<a href="/pubmed/17076349" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.3758%2FBF03193704" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Perception+&#x00026;+Psychophysics&amp;title=Encoding+objects+in+visual+short-term+memory:+The+roles+of+feature+proximity+and+connectedness&amp;author=Y+Xu&amp;volume=68&amp;publication_year=2006&amp;pages=815-828&amp;pmid=17076349&amp;doi=10.3758/BF03193704&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R36"><span class="element-citation">Xu Y. Representing connected and disconnected shapes in human inferior intra- parietal sulcus. <span><span class="ref-journal">Neuroimage. </span>2008;<span class="ref-vol">40</span>:1849–1856. doi: 10.1016/j.neuroimage.2008.02.014.</span> [<a href="/pubmed/18353688" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1016%2Fj.neuroimage.2008.02.014" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Neuroimage&amp;title=Representing+connected+and+disconnected+shapes+in+human+inferior+intra-+parietal+sulcus&amp;author=Y+Xu&amp;volume=40&amp;publication_year=2008&amp;pages=1849-1856&amp;pmid=18353688&amp;doi=10.1016/j.neuroimage.2008.02.014&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R37"><span class="element-citation">Xu Y, Chun MM. Visual grouping in human parietal cortex. <span><span class="ref-journal">PNAS: Proceedings of the National Academy of Sciences, USA. </span>2007;<span class="ref-vol">104</span>:18766–18771. doi: 10.1073/pnas.0705618104.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC2141851/">PMC free article</a>]</span> [<a href="/pubmed/17998539" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1073%2Fpnas.0705618104" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=PNAS:+Proceedings+of+the+National+Academy+of+Sciences,+USA&amp;title=Visual+grouping+in+human+parietal+cortex&amp;author=Y+Xu&amp;author=MM+Chun&amp;volume=104&amp;publication_year=2007&amp;pages=18766-18771&amp;doi=10.1073/pnas.0705618104&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li><li id="R38"><span class="element-citation">Zhang WW, Luck SJ. Discrete fixed-resolution representations in visual working memory. <span><span class="ref-journal">Nature. </span>2008;<span class="ref-vol">453</span>:233–235. doi: 10.1038/nature06860.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC2588137/">PMC free article</a>]</span> [<a href="/pubmed/18385672" target="pmc_ext" ref="reftype=pubmed&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="//dx.doi.org/10.1038%2Fnature06860" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Nature&amp;title=Discrete+fixed-resolution+representations+in+visual+working+memory&amp;author=WW+Zhang&amp;author=SJ+Luck&amp;volume=453&amp;publication_year=2008&amp;pages=233-235&amp;pmid=18385672&amp;doi=10.1038/nature06860&amp;" target="pmc_ext" ref="reftype=other&amp;article-id=4068940&amp;issue-id=239330&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></li></ul></div></div></div><!--post-content--></div>
            
            
        
            
        </div>
        <!-- Book content -->
    </div>
    
    <div id="rightcolumn" class="four_col col last">
        <!-- Custom content above discovery portlets -->
        <div class="col6">
            
        </div>
        
        <div xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><div class="format-menu"><h2>Formats:</h2><ul><li class="selected">Article</li> | <li><a href="#" data-citationid="PMC4068940" class="citationexporter ctxp">Citation</a></li></ul></div></div><div xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="share-buttons"><h2>Share</h2><ul><li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4068940%2F"><img src="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/img/4047626" alt="Share on Facebook" />
                             Facebook
                        </a></li><li class="twitter"><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4068940%2F&amp;text=Selection%20and%20Storage%20of%20Perceptual%20Groups%20Is%20Constrained%20by%20a%20Discrete%20Resource%20in%20Working%20Memory"><img src="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/img/4047627" alt="Share on Twitter" />
                             Twitter
                        </a></li><li class="gplus"><a href="https://plus.google.com/share?url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4068940%2F"><img src="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/img/4047628" alt="Share on Google Plus" />
                             Google+
                        </a></li></ul></div>
        
        <div id="ajax-portlets" data-pmid="23067117" data-aiid="4068940" data-aid="4068940" data-iid="239330" data-domainid="319" data-domain="nihpa" data-accid="PMC4068940" data-md5="e56e3cead3b5bc8c7e2759de3c85987a"></div>
                
        <!-- Custom content below discovery portlets -->
        <div class="col7">
            
        </div>
    </div>
</div>

<!-- Custom content after all -->
<div class="col8">
    
</div>
<div class="col9">
    
</div>

<script src="/corehtml/pmc/js/jquery.scrollTo-1.4.2.js"></script>
<script>
    (function($){
        $('.skiplink').each(function(i, item){
            var href = $($(item).attr('href'));
            href.attr('tabindex', '-1').addClass('skiptarget'); // ensure the target can receive focus
            $(item).on('click', function(event){
                event.preventDefault();
                $.scrollTo(href, 0, {
                    onAfter: function(){
                        href.focus();
                    }
                });
            });
        });
    })(jQuery);
</script>



<div id="body-link-poppers"></div>
                        </div>
                        <div class="bottom">
                            
                            <div id="NCBIFooter_dynamic">
    <a id="help-desk-link" class="help_desk" href="" target="_blank">Support Center</a>
    <a id="help-desk-link" class="help_desk" href="https://support.ncbi.nlm.nih.gov/ics/support/KBList.asp?Time=2019-05-07T01:37:59-04:00&amp;Snapshot=%2Fprojects%2FPMC%2FPMCViewer@4.46&amp;Host=portal104&amp;ncbi_phid=CE8BBFEFCD118FF100000000007D0057&amp;ncbi_session=CE8B5449CD114B21_0091SID&amp;from=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4068940%2F&amp;Db=pmc&amp;folderID=132&amp;Ncbi_App=pmc&amp;Page=literature&amp;style=classic&amp;deptID=28049" target="_blank">Support Center</a>
    
</div>

                            <div class="footer" id="footer">
    
    <div class="subfooter"> </div><script type="text/javascript" src="/portal/portal3rc.fcgi/static/js/preloaderWidget.js"> </script>
    <div id="external-disclaimer" class="offscreen_noflow">
        External link. Please review our <a href="https://www.nlm.nih.gov/privacy.html">privacy policy</a>.
    </div>    
    <div id="ncbifooter" class="contact_info">      
        <div id="footer-contents-right">
            <div id="nlm_thumb_logo">
                <a href="https://www.nlm.nih.gov" title="NLM">NLM</a>
            </div>
            <div id="nih_thumb_logo">
                <a href="https://www.nih.gov" title="NIH">NIH</a>
            </div>
            <div id="hhs_thumb_logo">
                <a href="https://www.hhs.gov" title="DHHS">DHHS</a>
            </div>
            <div id="usagov_thumb_logo">
                <a href="https://www.usa.gov" title="USA.gov">USA.gov</a>
            </div>         
        </div>
        
        <div id="footer-contents-left">
            <p class="address vcard">
                <span class="url">
                    <a class="fn url newdomain" href="https://www.ncbi.nlm.nih.gov">National Center for
                        Biotechnology Information</a>,
                </span> <span class="org url newdomain"><a href="https://www.nlm.nih.gov/">U.S. National Library of Medicine</a></span>
                <span class="adr">
                    <span class="street-address">8600 Rockville Pike</span>, <span class="locality">Bethesda</span>
                    <span class="region">MD</span>, <span class="postal-code">20894</span>
                    <span class="country-name">USA</span>
                </span>
            </p>
            
            <a href="/home/about/policies.shtml">Policies and Guidelines</a> | <a href="/home/about/contact.shtml">Contact</a>
        </div>
    </div>
    <script type="text/javascript" src="/portal/portal3rc.fcgi/rlib/js/InstrumentOmnitureBaseJS/InstrumentNCBIConfigJS/InstrumentNCBIBaseJS/InstrumentPageStarterJS.js?v=1"> </script>    
    <script type="text/javascript" src="/portal/portal3rc.fcgi/static/js/hfjs2.js"> </script>
</div>
                        </div>
                    </div>
                    <!--/.page-->
                </div>
                <!--/.wrap-->
            </div><!-- /.twelve_col -->
        </div>
        <!-- /.grid -->

        <span class="PAFAppResources"></span>
        
        <!-- BESelector tab -->
        
        
        
        <noscript><img alt="statistics" src="/stat?jsdisabled=true&amp;ncbi_db=pmc&amp;ncbi_pdid=article&amp;ncbi_acc=&amp;ncbi_domain=nihpa&amp;ncbi_report=record&amp;ncbi_type=fulltext&amp;ncbi_objectid=&amp;ncbi_pcid=/articles/PMC4068940/&amp;ncbi_app=pmc" /></noscript>
        
        
        <!-- usually for JS scripts at page bottom -->
        <!--<component id="PageFixtures" label="styles"></component>-->
    

<!-- CE8B5449CD114B21_0091SID /projects/PMC/PMCViewer@4.46 portal104 v4.1.r584435 Thu, Apr 11 2019 12:42:06 -->

<script type="text/javascript" src="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/js/3879255/4121861/3818874/4168176/3821238/4117325/4087685/4072593/4076480/3921943/4105668/4065628.js" snapshot="pmc"></script></body>
</html>