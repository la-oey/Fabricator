doi,title,text
10.1016/j.cognition.2008.01.001,"
               THE BACON not the bacon: How children and adults understand accented and unaccented noun phrases ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080320', '$': '2008-03-20'}}}}"
10.1016/j.cognition.2008.01.002,The SNARC effect does not imply a mental number line ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080303', '$': '2008-03-03'}}}}"
10.1016/j.cognition.2008.02.001,When can we say ‘if’? ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080310', '$': '2008-03-10'}}}}"
10.1016/j.cognition.2008.02.002,Emotion knowledge and autobiographical memory across the preschool years: A cross-cultural longitudinal investigation ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080318', '$': '2008-03-18'}}}}"
10.1016/j.cognition.2008.02.003,The link between statistical segmentation and word learning in adults ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080319', '$': '2008-03-19'}}}}"
10.1016/j.cognition.2008.02.004,Reference directions and reference objects in spatial memory of a briefly viewed layout ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080314', '$': '2008-03-14'}}}}"
10.1016/j.cognition.2008.02.005,Moral appraisals affect doing/allowing judgments ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080402', '$': '2008-04-02'}}}}"
10.1016/j.cognition.2008.02.006,The effect of neighborhood frequency in reading: Evidence with transposed-letter neighbors ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080418', '$': '2008-04-18'}}}}"
10.1016/j.cognition.2008.02.007,Does language guide event perception? Evidence from eye movements ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080418', '$': '2008-04-18'}}}}"
10.1016/j.cognition.2008.02.008,On the role of regular phonological variation in lexical access: Evidence from voice assimilation in French ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080408', '$': '2008-04-08'}}}}"
10.1016/j.cognition.2008.02.009,Understanding the referential nature of looking: Infants’ preference for object-directed gaze ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080326', '$': '2008-03-26'}}}}"
10.1016/j.cognition.2008.02.010,Transitive and pseudo-transitive inferences ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080418', '$': '2008-04-18'}}}}"
10.1016/j.cognition.2008.02.011,When facts go down the rabbit hole: Contrasting features and objecthood as indexes to memory ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080418', '$': '2008-04-18'}}}}"
10.1016/j.cognition.2008.02.012,Visual memory for agents and their actions ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080509', '$': '2008-05-09'}}}}"
10.1016/j.cognition.2008.03.001,Principled moral sentiment and the flexibility of moral judgment and decision making ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080516', '$': '2008-05-16'}}}}"
10.1016/j.cognition.2008.03.002,Sample diversity and premise typicality in inductive reasoning: Evidence for developmental change ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080423', '$': '2008-04-23'}}}}"
10.1016/j.cognition.2008.03.003,Freeze or flee? Negative stimuli elicit selective responding ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080422', '$': '2008-04-22'}}}}"
10.1016/j.cognition.2008.03.004,Stereotype priming in face recognition: Interactions between semantic and visual information in face encoding ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080422', '$': '2008-04-22'}}}}"
10.1016/j.cognition.2008.03.005,Representational flexibility and specificity following spatial descriptions of real-world environments ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080421', '$': '2008-04-21'}}}}"
10.1016/j.cognition.2008.03.006,Crime and punishment: Distinguishing the roles of causal and intentional analyses in moral judgment ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080424', '$': '2008-04-24'}}}}"
10.1016/j.cognition.2008.03.007,"On the relations between action planning, object identification, and motor representations of observed actions and objects ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080502', '$': '2008-05-02'}}}}"
10.1016/j.cognition.2008.03.008,Meaning matters in children’s plural productions ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080502', '$': '2008-05-02'}}}}"
10.1016/j.cognition.2008.03.009,The conceptual grouping effect: Categories matter (and named categories matter more) ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080429', '$': '2008-04-29'}}}}"
10.1016/j.cognition.2008.03.010,When more is less: Feedback effects in perceptual category learning ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080501', '$': '2008-05-01'}}}}"
10.1016/j.cognition.2008.04.001,Reading space into numbers – a cross-linguistic comparison of the SNARC effect ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080602', '$': '2008-06-02'}}}}"
10.1016/j.cognition.2008.04.002,The curse of knowledge: First language knowledge impairs adult learners’ use of novel statistics for word segmentation ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080603', '$': '2008-06-03'}}}}"
10.1016/j.cognition.2008.04.003,Recognition memory and mechanisms of induction: Comment on Wilburn and Feeney ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080603', '$': '2008-06-03'}}}}"
10.1016/j.cognition.2008.04.004,Perception of speech reflects optimal use of probabilistic speech cues ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080625', '$': '2008-06-25'}}}}"
10.1016/j.cognition.2008.04.005,Concurrent processing of words and their replacements during speech ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080610', '$': '2008-06-10'}}}}"
10.1016/j.cognition.2008.04.006,Attentional SNARC: There’s something special about numbers (let us count the ways) ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080606', '$': '2008-06-06'}}}}"
10.1016/j.cognition.2008.04.007,Number as a cognitive technology: Evidence from Pirahã language and cognition ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080610', '$': '2008-06-10'}}}}"
10.1016/j.cognition.2008.04.008,The role of perspective in identifying domains of reference ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080630', '$': '2008-06-30'}}}}"
10.1016/j.cognition.2008.04.009,Infants discriminate manners and paths in non-linguistic dynamic events ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080702', '$': '2008-07-02'}}}}"
10.1016/j.cognition.2008.04.010,Deciding between theories of how reasoning develops is hard ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080618', '$': '2008-06-18'}}}}"
10.1016/j.cognition.2008.05.001,Intuition in the context of object perception: Intuitive gestalt judgments rest on the unconscious activation of semantic representations ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080624', '$': '2008-06-24'}}}}"
10.1016/j.cognition.2008.05.002,Simplicity and generalization: Short-cutting abstraction in children’s object categorizations ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080618', '$': '2008-06-18'}}}}"
10.1016/j.cognition.2008.05.003,Representational change and magnitude estimation: Why young children can make more accurate salary comparisons than adults ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080624', '$': '2008-06-24'}}}}"
10.1016/j.cognition.2008.05.004,How speakers interrupt themselves in managing problems in speaking: Evidence from self-repairs ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080626', '$': '2008-06-26'}}}}"
10.1016/j.cognition.2008.05.005,Why good thoughts block better ones: The mechanism of the pernicious Einstellung (set) effect ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080618', '$': '2008-06-18'}}}}"
10.1016/j.cognition.2008.05.006,Monkeys match and tally quantities across senses ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080620', '$': '2008-06-20'}}}}"
10.1016/j.cognition.2008.05.007,How counting represents number: What children must learn and when they learn it ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080624', '$': '2008-06-24'}}}}"
10.1016/j.cognition.2008.05.008,Cross-modal interactions in the experience of musical performances: Physiological correlates ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080707', '$': '2008-07-07'}}}}"
10.1016/j.cognition.2008.05.009,Visual speech contributes to phonetic learning in 6-month-old infants ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080630', '$': '2008-06-30'}}}}"
10.1016/j.cognition.2008.05.010,Predictive coding explains binocular rivalry: An epistemological review ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080722', '$': '2008-07-22'}}}}"
10.1016/j.cognition.2008.05.011,"Number words in young children’s conceptual and procedural knowledge of addition, subtraction and inversion ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080714', '$': '2008-07-14'}}}}"
10.1016/j.cognition.2008.05.012,Lexical access in Catalan Signed Language (LSC) production ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080724', '$': '2008-07-24'}}}}"
10.1016/j.cognition.2008.06.001,Categorical priming of famous person recognition: A hitherto overlooked methodological factor can resolve a long-standing debate ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080722', '$': '2008-07-22'}}}}"
10.1016/j.cognition.2008.06.002,Electrophysiological evidence for the time-course of verifying text ideas ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080803', '$': '2008-08-03'}}}}"
10.1016/j.cognition.2008.06.003,Talker adaptation in speech perception: Adjusting the signal or the representations? ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080723', '$': '2008-07-23'}}}}"
10.1016/j.cognition.2008.06.004,Local and global processing: Observations from a remote culture ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080726', '$': '2008-07-26'}}}}"
10.1016/j.cognition.2008.06.005,Immediate effects of form-class constraints on spoken word recognition ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080801', '$': '2008-08-01'}}}}"
10.1016/j.cognition.2008.06.006,Visual working memory capacity for objects from different categories: A face-specific maintenance effect ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080801', '$': '2008-08-01'}}}}"
10.1016/j.cognition.2008.06.007,Do individuals with autism process words in context? Evidence from language-mediated eye-movements ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080808', '$': '2008-08-08'}}}}"
10.1016/j.cognition.2008.06.008,"The conjunction fallacy and the many meanings of and
             ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080823', '$': '2008-08-23'}}}}"
10.1016/j.cognition.2008.06.009,Judgments of cause and blame: The effects of intentionality and foreseeability ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080815', '$': '2008-08-15'}}}}"
10.1016/j.cognition.2008.06.010,Language within your reach: Near–far perceptual space and spatial demonstratives ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080815', '$': '2008-08-15'}}}}"
10.1016/j.cognition.2008.06.011,The processing of English regular inflections: Phonological cues to morphological structure,"serial JL 271061 291210 291723 291726 291738 291743 291782 31 90 Cognition COGNITION 2008-10-01 2008-10-01 2014-10-24T16:52:43 1-s2.0-S001002770800156X S0010-0277(08)00156-X S001002770800156X 10.1016/j.cognition.2008.06.011 S300 S300.2 FULL-TEXT 1-s2.0-S0010027708X00095 2015-05-14T00:00:22.981292-04:00 0 0 20081001 20081031 2008 2008-10-01T00:00:00Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast footnotes primabst ref 0010-0277 00100277 UNLIMITED MRCUK false 109 109 1 1 Volume 109, Issue 1 2 1 17 1 17 200810 October 2008 2008-10-01 2008-10-31 2008 Regular Papers article fla Copyright © 2008 Elsevier B.V. PROCESSINGENGLISHREGULARINFLECTIONSPHONOLOGICALCUESMORPHOLOGICALSTRUCTURE POST B 1 Introduction 1.1 The inflectional rhyme pattern: Coronality and voicing 2 Methods 2.1 Design 2.2 Materials 2.3 Procedure 2.4 Participants 3 Results 3.1 Reaction times 3.2 Errors 4 Discussion 5 Conclusion Acknowledgements Appendix A List of items Appendix B Harmonic estimated marginal mean reaction times for condition estimated in two separate analyses of variance for different and same items with fixed factor condition (14 levels) and covariate word 2 duration References BAAYEN 2005 666 698 R BAAYEN 1995 R CELEXLEXICALDATABASECDROM BIRD 2003 502 526 H BOERSMA 2001 45 86 P BURZIO 2002 157 199 L BYBEE 2005 381 410 J CLAHSEN 1999 991 1013 H DAVIS 2002 218 244 M DAVIS 2003 427 462 M MORPHOLOGICALSTRUCTUREINLANGUAGEPROCESSING FREQUENCYEFFECTSINPROCESSINGINFLECTEDDUTCHNOUNSADISTRIBUTEDCONNECTIONISTACCOUNT FORSTER 2003 116 124 K GIMSON 1961 A INTRODUCTIONPRONUNCIATIONENGLISH HARE 1999 181 200 M FREQUENCYEMERGENCELINGUISTICSTRUCTURE AMBIGUITYFREQUENCYEFFECTSINREGULARVERBINFLECTION HAWKINS 2004 199 231 S HAY 2001 1041 1070 J HUME 1999 2069 2072 E JOANISSE 1999 7592 7597 M KIPARSKY 2000 351 365 P KLATT 1976 1208 1221 D KOCHETOV 2004 351 382 A LEHISTE 1972 2018 2024 I LEHTONEN 2006 182 193 M LONGWORTH 2005 1087 1097 C MADDIESON 1985 I PATTERNSSOUNDS MARSHALL 2006 302 320 C MARSLENWILSON 2007 175 193 W OXFORDHANDBOOKPSYCHOLINGUISTICS MORPHOLOGICALPROCESSESINLANGUAGECOMPREHENSION MARSLENWILSON 1997 592 594 W MARSLENWILSON 1998 428 435 W MARSLENWILSON 2003 62 63 W MARSLENWILSON 2007 823 836 W MCCLELLAND 2003 63 64 J 1991 SPECIALSTATUSCORONALSINTERNALEXTERNALEVIDENCEPHONOLOGYPHONETICS2 PETERSON 1960 693 703 G PINKER 1991 530 535 S PINKER 1999 S WORDSRULESINGREDIENTSLANGUAGE PINKER 2002 456 463 S PLAUT 2000 445 485 D PLUNKETT 1993 21 69 K RATCLIFF 1993 510 532 R RUECKL 1999 110 117 J SERENO 1997 425 437 J STEMBERGER 1991 161 185 J TABAK 2005 529 555 W LINGUISTICEVIDENCEEMPIRICALTHEORETICALCOMPUTATIONALPERSPECTIVES LEXICALSTATISTICSLEXICALPROCESSINGSEMANTICDENSITYINFORMATIONCOMPLEXTYSEXIRREGULARITYINDUTCH TAFT 1975 638 647 M TYLER 2002 79 95 L TYLER 2002 1154 1166 L TYLER 2005 1963 1974 L TYLER 2005 8375 8380 L TYLER 2008 1037 1054 L ULLMAN 2004 231 270 M ULLMAN 1997 266 276 M VITEVICH 1999 374 408 M VITEVICH 2005 193 204 M WARREN 1987 262 275 P WARREN 1988 21 30 P WILSON 1988 6 11 M WURM 1997 438 461 L POSTX2008X1 POSTX2008X1X17 POSTX2008X1XB POSTX2008X1X17XB Full 2013-07-16T19:12:22Z FundingBody Medical Research Council http://creativecommons.org/licenses/by/3.0/ item S0010-0277(08)00156-X S001002770800156X 1-s2.0-S001002770800156X 10.1016/j.cognition.2008.06.011 271061 2014-10-24T12:16:24.172122-04:00 2008-10-01 2008-10-31 UNLIMITED MRCUK 1-s2.0-S001002770800156X-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/MAIN/application/pdf/8d1930e2c925b32d856009b8aa03984b/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/MAIN/application/pdf/8d1930e2c925b32d856009b8aa03984b/main.pdf main.pdf pdf true 566715 MAIN 17 1-s2.0-S001002770800156X-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/PREVIEW/image/png/ae5e874fc2fe81e3bb7af00bb8b414c8/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/PREVIEW/image/png/ae5e874fc2fe81e3bb7af00bb8b414c8/main_1.png main_1.png png 54470 849 656 IMAGE-WEB-PDF 1 1-s2.0-S001002770800156X-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/gr4/DOWNSAMPLED/image/jpeg/db2cd957f870b518c9f3c28cc1918493/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/gr4/DOWNSAMPLED/image/jpeg/db2cd957f870b518c9f3c28cc1918493/gr4.jpg gr4 gr4.jpg jpg 18626 264 328 IMAGE-DOWNSAMPLED 1-s2.0-S001002770800156X-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/gr3/DOWNSAMPLED/image/jpeg/8dec1fc838f0337b8b5c0fdf2ac130e6/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/gr3/DOWNSAMPLED/image/jpeg/8dec1fc838f0337b8b5c0fdf2ac130e6/gr3.jpg gr3 gr3.jpg jpg 21584 238 323 IMAGE-DOWNSAMPLED 1-s2.0-S001002770800156X-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/gr2/DOWNSAMPLED/image/jpeg/a036c2ff93414b4371354e15a1fcf050/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/gr2/DOWNSAMPLED/image/jpeg/a036c2ff93414b4371354e15a1fcf050/gr2.jpg gr2 gr2.jpg jpg 18783 243 326 IMAGE-DOWNSAMPLED 1-s2.0-S001002770800156X-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/gr1/DOWNSAMPLED/image/jpeg/b6a9dc52cae45e06346bce49ea3a70a1/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/gr1/DOWNSAMPLED/image/jpeg/b6a9dc52cae45e06346bce49ea3a70a1/gr1.jpg gr1 gr1.jpg jpg 18744 274 333 IMAGE-DOWNSAMPLED 1-s2.0-S001002770800156X-fx2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/fx2/DOWNSAMPLED/image/jpeg/9c9ed3dc235bfa4c2aaea3e2de368b2a/fx2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/fx2/DOWNSAMPLED/image/jpeg/9c9ed3dc235bfa4c2aaea3e2de368b2a/fx2.jpg fx2 fx2.jpg jpg 618 14 23 IMAGE-DOWNSAMPLED 1-s2.0-S001002770800156X-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/fx1/DOWNSAMPLED/image/jpeg/059b9af4ce3860d4a67c7ad2004b1dac/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/fx1/DOWNSAMPLED/image/jpeg/059b9af4ce3860d4a67c7ad2004b1dac/fx1.jpg fx1 fx1.jpg jpg 1024 12 65 IMAGE-DOWNSAMPLED 1-s2.0-S001002770800156X-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/gr4/THUMBNAIL/image/gif/02b8073fdab8ee581e757fddb3953906/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/gr4/THUMBNAIL/image/gif/02b8073fdab8ee581e757fddb3953906/gr4.sml gr4 gr4.sml sml 5438 164 204 IMAGE-THUMBNAIL 1-s2.0-S001002770800156X-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/gr3/THUMBNAIL/image/gif/c48929d978a275f866f69040fe5510c8/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/gr3/THUMBNAIL/image/gif/c48929d978a275f866f69040fe5510c8/gr3.sml gr3 gr3.sml sml 7334 161 219 IMAGE-THUMBNAIL 1-s2.0-S001002770800156X-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/gr2/THUMBNAIL/image/gif/7f1d40ee2fe4a94df48b9a38378ab442/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/gr2/THUMBNAIL/image/gif/7f1d40ee2fe4a94df48b9a38378ab442/gr2.sml gr2 gr2.sml sml 5745 163 219 IMAGE-THUMBNAIL 1-s2.0-S001002770800156X-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/gr1/THUMBNAIL/image/gif/034c58e792a5bc47e004dc9f02713e33/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/gr1/THUMBNAIL/image/gif/034c58e792a5bc47e004dc9f02713e33/gr1.sml gr1 gr1.sml sml 5352 164 199 IMAGE-THUMBNAIL 1-s2.0-S001002770800156X-fx2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/fx2/THUMBNAIL/image/gif/2370d34d598963fa637c28b0a4f8af86/fx2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/fx2/THUMBNAIL/image/gif/2370d34d598963fa637c28b0a4f8af86/fx2.sml fx2 fx2.sml sml 1688 63 103 IMAGE-THUMBNAIL 1-s2.0-S001002770800156X-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800156X/fx1/THUMBNAIL/image/gif/16433c24e9c3a2d1621398baf3ee62f7/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800156X/fx1/THUMBNAIL/image/gif/16433c24e9c3a2d1621398baf3ee62f7/fx1.sml fx1 fx1.sml sml 2928 39 219 IMAGE-THUMBNAIL COGNIT 1833 S0010-0277(08)00156-X 10.1016/j.cognition.2008.06.011 Elsevier B.V. Fig. 1 Harmonic estimated marginal mean reaction times for the conditions testing coronality and the pattern of the rhyme (different items only). Fig. 2 Harmonic estimated marginal mean reaction times for the voiceless items in the conditions testing coronality and rhyme pattern (different items only). Fig. 3 Harmonic estimated marginal means for the conditions testing manner of articulation (inflectional paradigm), coronality and rhyme pattern (different items only). Fig. 4 Harmonic estimated marginal mean reaction times for the conditions testing syllabicity (different items only). Table 1 Overview of experimental conditions Real word conditions Nonword conditions Regular past tense baseline 1 Regular past in /t/& /d/ [+Coronal, +Voice Agreement] filled – fill in /t/ and /d/ gubbed - gub Coronality and voicing 2 Pseudo past in /t/ & /d/ [+Coronal, +Voice Agreement] mild – mile also gubbed - gub 3 [+Coronal, -VoiceAgreement] in /t/ belt - bell in /t/ steet - stee 4 [-Coronal, -VoiceAgreement] in /p/ & /k/ lamp - lamb in /p/ and /k/ wump - wum Inflectional paradigm (Manner of articulation) 5 Present tense in /s/ & /z/ [+Coronal, +Voice Agreement] fails - fail in /s/ and /z/ pakes - pake 6 Plural in /s/ & /z/ [+Coronal, +Voice Agreement] meals - meal also pakes - pake Syllabicity 7 Regular past in /id/ folded - fold in / id/ milted – milt 8 Progressive aspect fending – fend in sunching - sunch Table 2 Mean duration of the second word for each condition Condition Duration word 2 in ms Real words Nonwords Overall Same Diff. Overall Same Diff. Real regular past filled–fill 741 765 717 733 752 713 Pseudo past in /t/ /d/ mild–mile 721 753 689 [−Cor, −Voice] in /p/ /k/ lamp–lamb 683 707 658 661 680 641 [+Cor, −Voice] in /t/ belt–bell 665 697 632 693 713 672 Present tense in /s/ /z/ fails–fail 725 796 654 703 761 645 Plural in /s/ and /z/ meals–meal 761 813 709 Regular past in /Id/ folded–fold 754 819 689 784 822 745 Progressive aspect fending–fend 810 851 768 846 879 812 Table 3 Descriptive lexical statistics by condition: median lemma frequencies per million, summed word form frequencies per million, and familiarity and imageability ratings (word 2 medians reported for the different pairs) Condition Word 1 Word 2 Lemma Wf sum Fam Imag Lemma Wf sum Fam Imag noun verb noun verb Real regular past filled–fill 0 37 14 500 415 0 37 13 504 441 Pseudo past in /t/ /d/ mild–mile 5 0 14 539 504 5 0 14 506 505 [−Cor, −Voice] in /p/ /k/ lamp–lamb 3 3 3 435 463 5 3 10 469 467 [+Cor, −Voice] in /t/ belt–bell 10 1 9 481 449 9 1 10 517 447 Present tense in /s/ /z/ fails–fail 0 14 1 469 400 0 14 1 484 400 Plural in /s/ and /z/ meals–meal 37 0 13 510 549 37 0 10 510 569 Regular past in /Id/ folded–fold 0 7 2 491 398 0 7 5 491 408 Progressive aspect fending–fend 0 22 6 429 384 0 22 7 468 398 Table 4 Harmonic mean reaction times and error rates for same and different judgments: (1) grand mean, (2) same items, and (3) different items, by condition Condition Harmonic mean RT (ms) Error proportion (%) Overall Same Diff. Overall Same Diff. Regular past /t/ /d/ filled–fill 949 922 979 4.0 4.1 3.9 Pseudo past /t/ /d/ mild–mile 932 895 973 5.5 4.2 6.9 [−Cor, −VoiAgree] /k/ /p/ lamp–lamb 821 831 812 1.6 2.3 0.9 [+Cor, −VoiAgree] /t/ belt–bell 806 813 799 2.5 1.9 3.1 Present /s/ /z/ fails–fail 909 905 914 2.9 4.0 1.7 Plural /s/ /z/ meals–meal 927 912 942 3.8 3.5 4.0 Regular past /Id/ folded–fold 819 832 806 2.0 2.5 1.5 Progressive fending–fend 876 887 866 3.1 2.5 3.8 Nonword /d/ /t/ gubbed–gub 908 886 932 3.1 1.5 4.8 Nonword /t/ (not past) steet–stee 853 858 848 3.2 4.6 1.9 Nonword /p/ /k/ wump–wum 816 817 815 3.2 4.2 2.2 Nonword /s/ /z/ pakes–pake 900 872 929 3.6 3.1 4.2 Nonword /Id/ milted–milt 860 866 853 3.8 5.0 2.6 Nonword sunching–sunch 879 879 879 2.2 3.3 1.0 Table 5 Regression analysis of reaction time including all interactions with judgment type: standardized coefficients with t values and significance levels St. Coeff. Beta t Sig. Level 1: regressors (Constant) 58.89 p <.001 Duration word 2 −0.63 −18.78 p <.001 Morphological structure 0.00 −0.09 p =.92 Word type 0.02 0.54 p =.59 Rhyme pattern −0.35 −6.79 p <.001 Place (coronal or not) 0.03 0.71 p =.48 Voice 0.07 1.53 p =.13 Syllabicity 0.41 9.64 p <.001 Manner (stop or not) −0.05 −1.21 p =.23 Judgment type −0.71 −3.36 p <.001 Level 2: Interactions with judgment type Duration word 2×judgment type 0.06 1.23 p =.22 Morphological structure×judgment type −0.03 −0.75 p =.45 Word type×judgment type −0.24 −4.33 p <.001 Rhyme pattern×judgment type −0.02 −0.43 p =.67 Place (coronal or not) ×judgment type 0.10 2.23 p <.05 Voice×judgment type 0.04 0.92 p =.36 Syllabicity×judgment type 0.04 1.04 p =.30 Manner (stop or not) ×judgment type 0.61 2.98 p <.001 The processing of English regular inflections: Phonological cues to morphological structure Brechtje Post a ⁎ bmbp2@cam.ac.uk William D. Marslen-Wilson b Billi Randall c Lorraine K. Tyler c a Research Centre for English and Applied Linguistics, University of Cambridge, English Faculty Building, 9 West Road, Cambridge CB3 9DP, United Kingdom b MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge, United Kingdom c Centre for Speech, Language and the Brain, Department of Experimental Psychology, University of Cambridge, Downing Street, Cambridge, United Kingdom ⁎ Corresponding author. Abstract Previous studies suggest that different neural and functional mechanisms are involved in the analysis of irregular (caught) and regular (filled) past tense forms in English. In particular, the comprehension and production of regular forms is argued to require processes of morpho-phonological assembly and disassembly, analysing these forms into a stem plus an inflectional affix (e.g., {fill}+{-ed}), as opposed to irregular forms, which do not have an overt stem+affix structure and must be analysed as full forms [Marslen-Wilson, W. D., & Tyler, L. K. (1997). Dissociating types of mental computation. Nature, 387, 592–594; Marslen-Wilson, W. D., & Tyler, L. K. (1998). Rules, representations, and the English past tense. Trends in Cognitive Science, 2, 428–435]. On this account, any incoming string that shows the critical diagnostic properties of an inflected form – a final coronal consonant (/t/, /d/, /s/, /z/) that agrees in voicing with the preceding segment as in filled, mild, or nilled – will automatically trigger an attempt at segmentation. We report an auditory speeded judgment experiment which explored the contribution of these critical morpho-phonological properties (labelled as the English inflectional rhyme pattern) to the processing of English regular inflections. The results show that any stimulus that can be interpreted as ending in a regular inflection, whether it is a real inflection (filled–fill), a pseudo-inflection (mild–mile) or a phonologically matched nonword (nilled–nill), is responded to more slowly than an unambiguously monomorphemic stimulus pair (e.g., belt–bell). This morpho-phonological effect was independent of phonological effects of voicing and syllabicity. The findings are interpreted as evidence for a basic morpho-phonological parsing process that applies to all items with the criterial phonological properties. Keywords Speech processing Morphology Phonology English inflection 1 Introduction Recent research into the neural and functional architecture of the human language system has been strongly influenced by the contrast between the regular and irregular past tense in English, which is regarded as a critical test case for discriminating competing claims about the organisation of the language system (Joanisse & Seidenberg, 1999; Marslen-Wilson & Tyler, 1997; Marslen-Wilson & Tyler, 1998; Marslen-Wilson & Tyler, 2003; Pinker, 1991; Pinker & Ullman, 2002; Plunkett & Marchman, 1993; Rumelhart & McClelland, 1986; Ullman 2004; Ullman et al., 1997). The central issue is whether the representation and processing of regular past tense forms, involving the combination of stems and affixes (e.g., play +/d/= played), requires specialised cognitive and neural procedures which are not invoked by the unpredictable and idiosyncratic irregular forms (e.g., buy–bought, hit–hit, or creep–crept), where there is typically no overt combination of stem and affix. The investigation of this issue has raised a set of more specific questions about the processing mechanisms involved in the cognitive analysis of regular and irregular forms in language comprehension (and production). Based on a number of neuropsychological and neuro-imaging studies, Marslen-Wilson, Tyler and colleagues argue for a distinction between lexical access processes that involve morpho-phonological decomposition, and those based on more direct access to stored forms (Marslen-Wilson & Tyler, 1997; Marslen-Wilson & Tyler, 1998; Marslen-Wilson & Tyler, 2003; Marslen-Wilson & Tyler, 2007; Tyler, Marslen-Wilson, & Stamatakis, 2005b; Tyler, Randall, & Marslen-Wilson, 2002b; Tyler, Stamatakis, Post, Randall, & Marslen-Wilson, 2005a; Tyler et al., 2002a). This emphasis on the morphological decomposition of regular inflected forms clearly allies this account with the “Words and Rules” (e.g., Clahsen, 1999; Pinker, 1999) and the procedural/declarative (e.g., Ullman, 2004) approaches, in distinction to non-decompositional, usually connectionist approaches, which deny the existence of separable stem and inflectional morphemes, and which argue instead that inflected forms are processed and represented as patterns of activation across pools of simple neuron-like processing units which share certain semantic, phonological and orthographic information (e.g., McClelland & Patterson, 2003; Rumelhart & McClelland, 1986). Unlike Pinker and colleagues, however, we do not assume that the presence or absence of grammatical morphemes implicates differences in the nature of mental computation. Our concern is with the functional architecture of the language processing system, not its underlying computational properties. The Marslen-Wilson and Tyler morpho-phonological account was directly tested in a comprehension experiment with four nonfluent aphasics with a documented regular past tense deficit, using a speeded same–different judgment task (Tyler et al., 2002a). In this task, participants hear trials of matched pairs of spoken stimuli. Half of the trials are same pairs in which the first word is repeated (e.g., filled–filled), and half are different pairs with a minimally different first and second word (e.g., filled–fill). Participants decide as quickly and as accurately as possible whether the two members of a pair sound the same or different. The effects of phonological complexity were controlled by including monomorphemic words and nonwords that were matched for form on a one-to-one basis to the regular and irregular pairs (e.g., pseudo-regular jade–jay and nonword kade–kay for real regular played–play). In a further condition, controlling for possible segmentation effects, the first and the second word again differed in the removal of the final phoneme of the first member of the pair (e.g., claim–clay), but here the final phoneme was not a possible inflectional affix. There were two important aspects to the results. The first was that the performance of patients with past tense deficits was most impaired for the real regular pairs, with significantly slower responses than to matched conditions (such as pseudo-regulars and nonword regulars). The second main result – and the stimulus for the research reported here – was that overall, the patients were substantially impaired for all conditions that contained a potential regular inflectional affix. Thus, although performance was poorest for the real regulars (mean reaction time of 1420ms and error rate of 31%), it was also poor both for the pseudo-regulars (RT of 1252ms and error rate of 25%) and for the nonword regulars (RT of 1244ms and error rate of 22%). Performance was much less impaired, and closer to normal levels of accuracy, for the control pairs such as claim–clay (RT of 1044ms and error rate of 5%), where the first member of the pair did not end in a potential affix. A similar grouping of responses to real regulars, pseudo-regulars and nonword regulars, in distinction to morphologically simple pairs of the claim–clay type, was also observed in a subsequent neuro-imaging study, where unimpaired young adults performed the same–different task on the same types of material in an event-related fMRI study (Tyler et al., 2005a). The hypothesis we explore here is that this commonality between the three critical regular past tense conditions (real, pseudo, nonword) reflects their common morpho-phonological properties – i.e., that they all share specific phonological features that are diagnostic of the presence of a potential inflectional suffix, and will therefore place specific demands on the neural and functional machinery underlying the perceptual processing of spoken words in English. These diagnostic phonological features, which we label the English inflectional rhyme pattern (IRP), have two components: the presence of a word-final coronal consonant (i.e., any sound articulated with the tip or blade of the tongue raised towards the teeth or the alveolar ridge, such as /d, t, s, z/), and the agreement in voice between the final coronal consonant and the segment that precedes it. Thus, the sequence passed /pa:st/ is a potential combination of a verbal stem pass /pa:s/ with an inflectional suffix, because it ends with the unvoiced coronal consonant /t/, and this agrees in voice with the preceding unvoiced segment /s/. The same applies to the pseudo-regular word fast, which is potentially analyzable as the (nonexistent) verb stem /fa:s/, plus the inflectional morpheme /t/. The same, furthermore, would also hold for the nonword sequence nast, also potentially analyzable as /na:s/ plus /t/. The presence or absence of these diagnostic features (the IRP) will lead a spoken lexical input to interact differentially with the machinery of lexical access and linguistic interpretation (cf. Marslen-Wilson & Tyler, 2007). This machinery, broadly speaking, is concerned on the one hand with the mapping of phonological inputs onto stored lexical representations, and on the other with the extraction and interpretation of grammatical morphemes (and other cues to structure). The successful functioning of this system requires the appropriate segmentation of speech inputs into stems and different types of affix. When an input such as /pa:st/ is encountered, corresponding to the past tense form passed, the system needs both to access the semantic and syntactic properties associated with the stem {pass} and to extract the processing implications of the presence of the grammatical morpheme {-t}. A critical claim about the functioning of this system – motivated in particular by the effects for nonword regulars in the earlier neuropsychological and neuro-imaging studies (Tyler et al., 2002a; Tyler et al., 2005a) – is that the attempt at segmentation into stem and affix is automatically triggered by any input that has the critical diagnostic properties. Whenever the system encounters a candidate string that ends with a coronal consonant that agrees in voice with its preceding segment, this will always have to be evaluated both as a monomorphemic input and as a verbal or nominal stem with an accompanying inflectional affix. This seems to be forced by the pervasive ambiguity of possible inflected inputs. An input like /peIst/ may be either the monomorphemic form paste or the past tense of pace; /treId/ could be the past tense of the stem tray, and so forth. The system cannot decide in advance which strings with the appropriate properties are inflected forms or not – even if, in a case like trade, the stem in question may never be used as a verb. This predicts that listeners should make slower responses whenever they are asked to make same–different judgments where at least one member of the pair ends with the characteristic inflectional rhyme pattern, relative to control pairs which deviate from this pattern – for example, pairs like tent–ten (where the first member of the pair ends in a coronal which does not agree in voicing with the preceding segment) or clamp–clam and bark–bar (where the first word ends in labial or velar consonants). These are less complex to process because they can only be interpreted as full forms, and will not engage morpho-phonological segmentation mechanisms that generate additional lexical complexity and competition. The purpose of the research reported here, therefore, is to explore this specifically morpho-phonological hypothesis about the nature of the processing operations associated with the presence of regular inflectional morphology in English. We need to consider this hypothesis, however, in the context of a widely held competing view, which argues that patients’ difficulties with regular past tense inflections do not reflect the morphological or morpho-phonological properties of inflected words, but rather purely phonetic and phonological factors relating to the perceptual complexity of the forms in question. These are the single mechanism connectionist models, where there is no independent representation of morphology, either regular or irregular. The currently most prominent of these models has been developed by Joanisse and Seidenberg (1999), claiming that differential effects for regulars and irregulars can be modelled in a single undifferentiated network without reference to morphological features, by exploiting the statistical regularities in the variation of semantic and phonological overlap between stem and past tense form that distinguish regulars and irregulars. This approach makes the strong prediction that any apparently morpho-phonological effects for regular inflected forms are in fact primarily phonological in nature (cf. Bird, Lambon Ralph, Seidenberg, McClelland, & Patterson, 2003; McClelland & Patterson, 2003). Regulars are argued to be more difficult to process than irregulars because they have “greater articulatory complexity and perceptual subtlety” (McClelland & Patterson, 2003, p63). The poorer performance of nonfluent patients on regular forms is therefore primarily attributed to general problems in phonological processing, and not to any specifically morphological deficit (e.g., Bird et al., 2003; cf. Tyler et al., 2002b, and Marshall & Van der Lely, 2006, for a recent study with children). Although notions of phonological complexity and perceptual salience are not fully defined in the relevant single mechanism publications, they can be taken to refer to characteristic phonological properties of regular inflected forms – in particular the structure of the final consonant cluster, and the types of phoneme involved. Since the inflection is realised as /t/ or /d/ except when the final consonant is already a /t/ or /d/ (as in forms like greeted or sighted), this often leads to unusual final consonant clusters like /spt/ in clasped (cf. Marshall & van der Lely, 2006). At the same time, as noted previously, the inflectional morpheme always ends in a coronal, which may have a special status linguistically (Paradis & Prunet, 1991). Coronals are the most common phonemes cross-linguistically (Maddieson, 1985). Moreover, they may be perceptually less salient than labials (like /p/) and dorsals (like /k/; Hume, Johnson, Seo, & Tserdanelis, 1999, for stops in Korean and English), they tend to be replaced by velars or alveolars in speech errors (Stemberger, 1991), and they have been found to be more susceptible to regressive place assimilation (Jun, 1995, reported in Kochetov, 2004). There is no clear evidence, however, that coronality itself selectively affects the phonological processing of regular past tense forms. In the current experiment, we will evaluate the processing implications of a number of phonological and morpho-phonological properties of regular inflected forms in English, taking care to control closely for phonological complexity, defined as the type of CV sequence that makes up a particular word form. The further organisation of the experiment is laid out in the following section. 1.1 The inflectional rhyme pattern: Coronality and voicing The primary set of contrasts explores the significance of the different components of the diagnostic rhyme pattern that indicate the presence of a potential word-final inflectional morpheme. Taking a set of real regular past tense items (filled–fill, blessed–bless) as a form of baseline, these are compared with three sets of morphologically simple real words, as well as with matched sets of nonwords, as shown in Table 1 . The first comparison set of real words, as in previous experiments, is a set of pseudo-regular forms like mild–mile or crest–cress. These [+Coronal, +VoiceAgreement] materials share the inflectional rhyme pattern, and have an embedded real stem, but the full form is not itself an attested past tense form. We expect slower processing of these forms relative to uninflected forms that do not have the rhyme pattern, just as for the real regulars, because the presence of the rhyme pattern should trigger the same morpho-phonological segmentation and evaluation processes. These processes will activate, for example, the spurious lexical candidate cress, when the first word crest is heard, which should both increase processing load for crest, and potentially interfere with the same–different decision to the second word, cress. The second comparison set, containing pairs like start–star or tent–ten, retains the coronal ending, but violates the second component of the inflectional rhyme pattern, since this final consonant does not agree in voice with the preceding consonant – if ten had a past tense, it would have to be tenned (/tend/, homophonous with tend). If the presence of a word-final coronal intrinsically causes perceptual difficulties, then responses should also be slower for these [+Coronal, −VoiceAgreement] materials. If it is the presence of the inflectional rhyme pattern that is critical, then these materials should be treated as monomorphemic, and therefore less complex than either the regulars or the pseudo-regulars. The third set of words moves further away from the inflectional rhyme pattern by replacing the final consonant with a noncoronal segment (either a labial /p/, as in clamp–clam, or a dorsal /k/, as in milk–mill). These [−Coronal, −VoiceAgreement] materials violate both components of the inflectional rhyme pattern, and should be treated as monomorphemic full forms in the same way as the [+Coronal, −VoiceAgreement] stimuli in the previous condition. However, if it is the presence of a coronal consonant that is critical, on a perceptual difficulty account, then performance should be improved here, relative to the [+Coronal] conditions. In order to neutralise the phonological complexity issue, all three of these sets of words will be closely matched to each other, and to the real regulars, in their CV structures, covering both word onsets and word offsets. If there are differences between conditions, these should not reflect differences in complexity. Note that this means that highly complex regular past tense forms, ending in a CCC sequence (as in clasped or asked), are not included here as part of the main experiment, since they cannot be matched across the other real word conditions. The three sets of monomorphemic comparison conditions were accompanied by three matched sets of nonwords – a pseudo-regular [+Coronal, +VoiceAgreement] set, as in minned–min /mind/ /min/ or stessed–stess /stest/ /stes/, a coronal noninflectional [+Coronal, −VoiceAgreement] set, as in rint–rin /rint/ /rin/ or lart–lar /la:t/ /la:/ and a noncoronal [−Coronal, −VoiceAgreement] set, as in plamp–plam /plæmp/ /plæm/ or tulk–tul . Again, the morpho-phonological account predicts more complex processing for the pseudo-regular set than for the other two, on the assumption that the presence of the inflectional rhyme pattern will trigger segmentation attempts that generate a pseudo-stem, such as min or stess, potentially disrupting same–different judgements to the actual second member of the pair. On the perceptual difficulty account, the [−Coronal, −VoiceAgreement] stimuli should contrast with the first two sets which both contain word-final coronal consonants. All three sets are matched to each other, and to the real regulars, in their CV structure. Two further contrasts complement this main set of materials, while also expanding the variety of materials the participants are exposed to. The first of these, using the s inflection, expands the coverage of this research beyond the set of past tense inflections, allowing us to examine the generality of the claims being made here for the influence of the inflectional rhyme pattern. The regular s inflection in English, used to mark noun plurals (as in cats–cat or yards–yard) and the third person present tense (as in lick–licks or begs–beg), observes the same diagnostic constraints as the past tense inflection. The inflection itself, whether realised as an /s/ or a /z/, is a coronal consonant, and it must agree in voice with the preceding segment – a form like sparse cannot be interpreted as the plural of spar. The difference with the regular past tense forms is the manner of articulation of the final consonant; /s/ and /z/ are fricatives, while /t/ and /d/ are stops. If the inflectional rhyme pattern has the same processing consequences here as for the past tense inflection, then we expect present tense and plural forms in /s/ and /z/ to pattern with the real and pseudo past tense forms in /t/ and /d/, rather than with the [+Coronal, −VoiceAgreement] and [−Coronal, −VoiceAgreement] sets, such as tent–ten and milk–mill, which do not conform to the inflectional rhyme pattern. The same should hold, for the same reasons, for nonword pairs like pakes–pake /peiks/ /peik/ or dags–dag /dægz/ /dæg/, relative to the parallel past tense nonword sets. English regular inflection also includes two cases which do not obey the inflectional rhyme constraint, and which are both syllabic, as opposed to the cases we have considered above. These are the syllabic past tense allomorph /id/ (e.g., folded–fold), and the progressive aspect morpheme , which we include here primarily to give full coverage of English inflection, as well as increasing the variety of materials the participants are exposed to. Although the syllabic past tense allomorph /id/ ends in a coronal just like the nonsyllabic past tense allomorphs /d/ and /t/, it does not show voicing agreement with the rhyme. Progressive does not share any phonological features with the nonsyllabic allomorphs. There is not a clear prediction here for the same–different task. In the absence of the rhyme diagnostics, we would not expect to see the slow down in response times that we anticipate for the monosyllabic inflections. At the same time, it is possible that the syllabic nature of the inflection makes the same–different judgments highly perceptually salient, which may be reflected in faster response times. 2 Methods 2.1 Design We examined the contribution of morphological and phonological factors to regular past tense processing by systematically manipulating, relative to a baseline set of past tense forms (condition 1 in Table 1 above): (i) coronality and voicing (inflectional rhyme pattern present in condition 2; absent in conditions 3 and 4), (ii) inflectional paradigm (present tense and plural in conditions 5 and 6), and (iii) syllabicity (syllabic allomorphs in conditions 7 and 8). The items are listed in Appendix A. 2.2 Materials There were 48 trials per condition, consisting of 24 different pairs with a minimally different first and second word (or nonword) which were also used as same pairs in which the first word was repeated as the second word. Eight of the 14 conditions were real word conditions and six were nonword conditions. The nonword items were mostly derived from the real words in the corresponding conditions so as to maximise their phonological similarity (sharing as many phonemes in onsets, nuclei and codas as possible). Except for items in real inflected conditions, the word pairs were semantically unrelated. All items were based on matched monosyllabic and monomorphemic stems, to avoid any confound between morpho-phonological decomposition of inflections and other morphological or phonological processes. All monosyllabic conditions were matched for the phonological complexity of the first member of each test pair, with complexity defined here as CV structure. This covered both onsets and codas across all the relevant conditions. If, for example, the regular past tense set contained the form prayed, with the CV structure CCVC, then a form with the same CV structure would occur across the other conditions. For all same–different pairs, the second word of the pair would have the same CV structure but without the final segment. For the syllabic conditions, the CV structure of the stem of the first word in the pair was used for matching instead of the whole word form (e.g., greeted–greet was matched with prayed–pray). Since the experiment contained monosyllabic and bisyllabic items in different conditions, the duration of the second word varied significantly between conditions (see Table 2 ; [F(13,648)=11.20, MSE=137,899, p <.001]). A second factor that played a role in the duration of the second word was the voicing of the final consonant (Gimson, 1961). In English, vowels that precede a voiceless consonant are shorter than vowels which precede voiced material (e.g., plate is much shorter than played; e.g., Wiik (1965)). In our experiment, since the monomorphemic conditions in /t/, /k/ and /p/ all ended in voiceless consonants, while the morphologically complex forms and the pseudo past contained both voiced and voiceless codas (12/24 voiced codas for real past, present and plural, and 16/24 voiced codas for the pseudo past), the second word in the word pairs in the latter conditions are on average longer than in the former (see Table 2). The conditions could not be matched for voicing, because the set of pseudo past forms is too small to be limited to the subset with voiceless codas. The alternative of voicing half of the items in the nonpast condition in /t/ was not a possibility, since this would have led to voicing agreement in the rhyme, turning them into pseudo past or real past items (e.g., voicing final /t/ in trait gives trade). This means that both voicing and duration of the second word have to be taken into account in the reaction time analyses. We controlled as far as possible for form class ambiguity. Items used in verbal contexts were generally more frequent as verbs, even if a noun form existed and items used in nominal contexts were more frequent as nouns, even when a homonymic verb existed. In addition, subject to the above constraints, we matched the conditions as closely as possible for lemma frequency, word form frequency, familiarity and imageability (see Table 3 ; based on the CELEX lexical database (Baayen, Piepenbrock, & Gulikers, 1995), the MRC Psycholinguistic data base (Wilson, 1988), and our own data base of locally collected information from paper-and-pencil rating tasks with minimally 15 participants). One-way analyses of variance, carried out for each “nuisance” variable with the factor condition (8 levels), nevertheless showed a significant main effect for each variable, with the exception of familiarity of the second word in the word pair. 1 Word 1: lemma frequency noun F(7,371)=6.83, p <.001, lemma frequency verb F(7,371)=4.01, p <.001, word form frequency F(7,371)=2.74, p <.01, marginal for familiarity F(7,371)=2.00, p =.054, imageability F(7,371)=6.70, p <.001; word 2: lemma frequency noun F(7,371)=6.84, p <.001], lemma frequency verb F(7,371)=3.20, p <.01, word form frequency F(7,371)=.92, p =.49, imageability F(7,371)=6.54, p <.001, familiarity F(7,371)=.59, p =.77. 1 The stimuli were recorded on DAT tape in a sound-attenuated booth, and digitised at 22.05kHz for further processing. The first item in each pair was spoken by a male speaker, and the second by a female speaker to ensure that the judgments were not made on the basis of the low-level acoustic or phonetic properties of the test pairs. Both speakers were native speakers of British English. 2.3 Procedure The pairs were presented in a single-version experiment in pseudo-random order in four sessions of 184 stimuli, each introduced by 4 dummy stimuli, and with equal numbers of pairs from each condition in each session (108 real words and 72 nonwords). Numbers of same and different stimuli were also balanced (90 of each per session), and at least one session intervened between repetitions of an item as a same or a different stimulus. The experiment began with a practise session (24 items), and each session was followed by a short break. The experimental software package DMDX (Forster & Forster, 2003) was used for the presentation of the stimuli. Participants were tested in quiet conditions, using a two-button response box, and wearing headphones. They would first hear the inflected form or its equivalent, spoken by the male voice, and after a 100ms delay, they would hear the second item, spoken by the female voice. The intertrial interval was 850ms, and the time-out was set at 3s. The participants were asked to press the button labelled same when the two items sounded the same, and different when they sounded different. The experiment took about 45min. 2.4 Participants We tested 20 participants, 5 men and 15 women, from the subject pool of the Centre for Speech, Language and the Brain. They were all native speakers of English, aged between 18 and 25, and had no known hearing deficits. The participants were paid a small fee. 3 Results 3.1 Reaction times One item was removed from the analysis because of a very high error rate (85%), and nine items were lost because of programming error (1.25% of items). 2 The item with the 85% error score was an outlier: only 5 other items had error rates above 25% (1 at 35% and 4 at 25%). The missing items were two regular past different items, one regular past same item, one present tense different item, one noncoronal /k/ /p/ different item, two different items from the nonwords in /t/ and /d/, one different item from the nonwords in /k/ and /p/, and one different item from the nonwords in /Id/. 2 The RT data, which were only collected for correct responses, were then inverse transformed to reduce the effects of outliers (Ratcliff, 1993). In the subject analysis (F1), the data were averaged over items, and in the item analysis (F2), over subjects. The mean reaction times and error proportions are shown for each condition in Table 4 . As a first examination of the data, we conducted an overall analysis of variance to see if there were differences between conditions and judgment types. There were two repeated measures in the subject analysis (condition with 14 levels and judgment type with two levels: same and different). In the item analysis, there was one repeated measure (judgment type) and one independent measure (condition). The results show a significant effect of condition [F1(13,247)=53.42, p <.001; F2(13,312)=8.41, p <.001], and a marginal effect of judgment type in the items analysis only [F1(1,19)=1.09, p =.310; F2(1,312)=3.41, p =.07]. In addition to the main effects there was a significant interaction between condition and judgment type [F1(13,247)=6.51, p <.001; F2(13,312)=2.06, p <.05]. 3 The same pattern of results obtained when we included word 2 duration as a covariate in an analysis of variance with between-subject factors condition (14 levels) and judgment type (2 levels) [condition: F(13,633)=15.81, p <.001, judgment type: F(1,633)=60.05, p <.001, condition×judgment type: F(13,633)=2.51, p <.01, word 2 duration: F(1,633)=324.07, p <.001]. 3 This is because same items are not always responded to faster than different items, even though overall, same items are responded to 20ms more slowly than different items (see Table 4 and Appendix B; this interaction is explored further in the regression analyses reported below). The overall effect of condition justifies further analyses to explore the principal factors of interest – coronality and voicing, inflectional paradigm (reflected by manner of articulation) and syllabicity. At the same time, we needed to evaluate whether any of the “nuisance” variables affected reaction time, especially since not all of these could be fully matched across conditions (see Tables 2 and 3 above). Correlation analyses showed that none of these variables, except for the duration of the second word [r(662)=−0.49, p <.001], did in fact correlate with RT. 4 For word 1: lemma frequency noun r(379)=−.04, p =.47, lemma frequency verb r(379)=−.07, p =.15, word form frequency r(379)=−.06, p =.21, familiarity r(379)=−.01, p =.43, imageability r(379)=−.08, p =.13; for word 2: lemma frequency noun r(379)=−.01, p =.93, lemma frequency verb r(379)=−.08, p =.13, word form frequency r(379)=−.01, p =.87, familiarity r(379)=−.03, p =.62, imageability r(379)=−.08, p =.10. The correlation is negative for inverse transformed reaction times. 4 We also tested for a possible confound, raised by a reviewer, with the diphone frequency of the final phonemes in the word pairs. This might have affected reaction times if participants simply relied on how dissimilar the final phonemes were to make their judgements. Responses would be quickest for same items, where the words of the pair are identical. For different items, however, less frequent combinations of consonants might be harder to process than more frequent ones, resulting in relatively slower reaction times. Calculations of the logged frequencies of the final diphones of word 1 and word 2 in the stimulus pairs as well as their ratio (using CELEX wordform frequencies, Baayen et al., 1995), showed that these did differ significantly between conditions. Correlational analyses, however, showed that diphone frequency did not correlate with RT in the experiment: word 1 r(379)=−.05, p =.31, word 2 r(379)=−.08, p =.13; ratio diphone frequency word 1/word 2 r(379)=−.08, p =.14. In the main analysis reported here, using regression techniques, we included the duration of the second word as a continuous regressor, in addition to the binary regressors which represented the factors of interest. These were (1) morphological status: items that ended in a real inflectional affix versus items that were monomorphemic (including the pseudo past tense forms), (2) word type: real words versus nonwords, (3) rhyme pattern: items that are compatible with an inflection (including pseudo past forms) versus all other items, (4) place of articulation: items that end in a coronal consonant versus all other items, (5) voice: items that end in a voiceless consonant versus items that end in a voiced consonant (including bisyllabic past and progressive forms), (6) syllabicity: mono- versus bisyllabic forms, and (7) manner of articulation: forms that end in a stop (including bisyllabic past tense forms) versus all other forms. We also included all interactions with judgment type (same or different item), because of the presence of the judgement type/condition interaction in the overall analysis of variance. The most important question here was whether the rhyme pattern effect varied as a function of the judgement required. The results are summarised in Table 5 . The duration of the second word, the rhyme pattern, syllabicity and judgment type all contributed significantly to response times in our experiment but morphological status, voice, word type, and place and manner of articulation do not. The results also show (Table 5, level 2) that judgment type does not interact significantly with rhyme pattern (for estimated marginal means for same and different items in each condition see Appendix B). Although a number of other factors did interact with judgement type, none of these seem to bear significantly on the main questions at issue here. 5 The significant interaction between judgment type and word type can be attributed to smaller differences between same and different items for nonwords than for real words; the interaction with place of articulation reflects equally fast responses to same and different items for the /k/ and /p/ conditions compared to differences between the judgement types in the other conditions, and similarly, the interaction with manner reflects a fairly consistent difference between same and different responses for all items in /s/ and /z/, but varied differences between judgment types for the other conditions. 5 For ease of visualisation, Fig. 1 shows the effect of the rhyme pattern in terms of the relevant experimental conditions. The mean reaction times in the figure have been corrected for the effect of the duration of the second word by calculating estimated marginal means in an analysis of variance with the fixed factor condition (14 levels) and the duration of the second word as a covariate [condition: F(13,313)=12.66, p<.001; duration word 2: F(1,313)=109.53, p<.001] (see Appendix B for same items). The cluster on the left-hand side represents real, pseudo and nonword regular past forms which have the rhyme pattern, and they clearly have longer reaction times than the other clusters which represent uninflected forms that do not have the rhyme pattern (all p <.01 in Bonferroni post hoc comparisons, except for nonword /t/ /d/ versus nonword /t/ p >.10). This effect occurs irrespective of coronality, morphological status and word type. Since voicing affected reaction times in the regression analysis (although only for different items), and, as mentioned in Section 2 above, the conditions were not matched for voicing, the question arises how this affects the morpho-phonological effect of the rhyme pattern. Fig. 2 shows the mean values for the same conditions when all voiced items have been excluded, estimated in an analysis of variance with the fixed factor condition (10 levels) and the duration of the second word as a covariate [condition: F(9,147)=12.42, p <.001; duration word 2: F(1,147)=46.36, p <.001] 6 Since the values were estimated in a different analysis, they are different from those in Fig. 1 for all conditions, even when no items were removed from the condition (e.g., [+Cor, −VoiceAgreement] /t/). Note that there are unequal numbers of items in the conditions in Fig. 2. 6 (see Appendix B). The figure shows that voicing has an effect, with increased response times in real, pseudo and nonword past items when voiced items are removed from these conditions. As a result, the differences between the conditions with and without the rhyme pattern are even larger than those estimated in Fig. 1, corresponding to a robust morpho-phonological effect (all p <.001 in Bonferroni post hoc comparisons). This enhanced effect indicates that the lack of matching on voicing across conditions in fact biased the results against our morpho-phonological hypothesis, rather than creating a confound. Fig. 3 illustrates that the effect of the rhyme pattern is not restricted to real and pseudo past tense forms, but also applies to the s inflection forms. The means in this figure were estimated in the same covariate analysis used for Fig. 1 (see Appendix B). Since manner of articulation did not contribute to reaction times, we can conclude that the morpho-phonological effect of the rhyme pattern appears to extend to all monosyllabic inflections in the experiment (all p <.01 in Bonferroni post hoc comparisons, except for nonword /t/ versus nonword /s/ and /z/, and nonword /t/ versus nonword /t/ and /d/, which were not significant). Finally, Fig. 4 illustrates the purely phonological effect of syllabicity on response times when word 2 duration is taken into account (again estimated in the covariate analysis used for Fig. 1; see Appendix B). Syllabic inflections are responded to faster than nonsyllabic ones (all p <.05 in Bonferroni post hoc comparisons, except for pseudo past versus progressive p >.10, and nonword /t/ and /d/ versus nonword /Id/ p >.10). 3.2 Errors Although the error rates were very low, the same set of analyses was carried out on the arcsine transformed proportion correct responses. The subjects and items analyses showed a significant effect of condition [F1(13,247)=5.06, MSE=0.251, p <.001; F2(13,312)=1.82, MSE=0.144, p <.05], and an interaction between judgment type and condition [F1(13,247)=2.99, MSE=0.151, p <.001; F2(13,312)=2.34, MSE=0.186, p <.01], but no main effect of judgment type [F1(1,19)=2.32, MSE=0.289, p =.14; F2(1,312)=1.42, MSE=0.113, p =.23]. None of the nuisance variables (listed in Tables 2 and 3 above) correlated with error proportion. 7 Word 2 duration p =.24; for word 1: lemma frequency noun p =.59, lemma frequency verb p =.69, word form frequency p =.18, familiarity p =.67, imageability p =.19; for word 2: lemma frequency noun p =.97, lemma frequency verb p =.54, word form frequency p =.36, familiarity p =.85, imageability p =.56. 7 Therefore, we only included our factors of interest in the regression analysis, together with judgment type: (1) morphological status, (2) rhyme pattern, (3) syllabicity, (4) voicing, (5) manner of articulation, (6) place of articulation, and (7) word type. Rhyme pattern (β =−0.141, p <.05) and judgment type (β =0.226, p <.001) contributed to the error scores, and there were interactions between judgment type and rhyme pattern (β =−0.299, p <.001), judgment type and word type (β =−0.130, p <.05), judgment type and morphological structure (β =0.159, p <.05), and judgment type and voicing (β =0.194, p =.001; nonsignificant regressors: morphological structure p =.56, syllabicity p =.33, voicing p =.14, manner p =.88, place p=.50, word type p =.70). The major effect of the rhyme pattern indicates that all potentially inflected forms, such as filled–fill, fails–fail and mild–mile, are more likely to be heard as same items when they are actually different, compared to unambiguously monomorphemic items like saint–sane and bank–bang. This is consistent with the view that the morpho-phonological properties of the incoming speech sounds automatically trigger an attempt at segmentation into a stem and an affix, but only when the rhyme pattern signals that it is compatible with an inflection. Finally, we established that although reaction times did correlate with error proportion [r(379)=0.31, p <.001), there was no speed–accuracy trade-off, since faster reaction times tended to coincide with lower error rates. 4 Discussion A clear pattern of results emerges from this experiment, showing that the processing of regular English inflections is influenced by morpho-phonological as well as phonological factors. We hypothesised that the neural and functional mechanisms involved in the processing of spoken words in English are differentially engaged by monomorphemic forms and by real and pseudo-inflected forms which show the critical diagnostic properties of morphologically complex inflectional forms. These diagnostic properties (the IRP) are voicing agreement in the syllable rhyme in combination with a coronal place of articulation for the final consonant of the (pseudo-)inflected form (e.g., filled, fails, meals or mild, but not saint or bank). When the IRP is present, and since the perceptual system cannot decide on the basis of acoustic–phonetic information alone whether a form does in fact bear an inflection, the presence of the IRP should trigger automatically an attempt at segmentation into a stem and an affix. This would not be triggered by unambiguously monomorphemic forms. We therefore predicted a morpho-phonological effect reflected in a difference between items that showed the diagnostic rhyme pattern and those that did not, regardless of their actual morphological status. Our findings support this hypothesis. In a same–different judgment task, we found elevated judgment times for potentially inflected items compared to items that could not be interpreted as inflected forms. 8 There is ample evidence that inflectional morphemes are not only extracted in the same–different task used here, but in many other processing conditions which do not encourage participants to focus on the endings of the items (e.g., Lehtonen, Vorobyev, Hugdahl, Tuokkola, & Laine 2006; Tyler et al. 2002a; Wurm, 1997). 8 The difference between the potentially inflected and the uninflected forms in /t/ and /d/ shows that coronality only has an effect when it combines with voicing agreement in the rhyme, but not when it occurs on its own. The findings for the pseudo- and nonword inflections confirm that the rhyme pattern itself is the critical feature, rather than the actual morphological status of the item, and that segmentation must be automatic, since reaction times are comparable for any item that shows the diagnostic pattern, including meaningless strings of sounds and real words that are not actually inflected. This also includes present and plural inflections which also combine coronality and voicing agreement in their rhymes, but do not have the same place of articulation as the regular past tense (i.e., fricative /s/ and /z/). In addition to the morpho-phonological effect, we found effects for two purely phonological factors that are independent of the morphological status of the word, for which we had made no predictions. The results show that when the past tense morpheme is realised as a syllable, participants are faster to make same–different judgments than when it is realised as a single segment. This effect of syllabicity extends to the progressive inflection , where reaction times were comparable to the syllabic past, and to the matched nonword conditions, which behaved just like the real word syllabic items. This across-the-board syllabic effect is likely to reflect the greater perceptual salience of syllabic inflections (or pseudo-inflections), even before the added syllable is heard. Polysyllabic forms provide additional early phonological cues to the presence or absence of extra material at the end of the word, giving a strong indication of whether both words in the stimulus pair are the same or different. A strong early cue is the shortening of the first syllable – for example in melted relative to melt (Klatt, 1976; Lehiste, 1972) – which has been shown to affect lexical access processes in spoken word recognition (Davis, Marslen-Wilson, & Gaskell, 2002). Other early cues could involve changes in metrical structure and in syllabification. The second phonological factor was voicing of the final segment. Overall, items which end in a voiced consonant, such as raised – raise, are responded to more quickly than items that end in a voiceless consonant like raced – race. Listeners pick up on cues to the presence or absence of a final consonant more quickly in the voiced items, possibly because cues to voicing become available early in the speech signal (e.g., Hawkins & Nguyen, 2004; Peterson & Lehiste, 1960). Such cues are exploited online to identify a word before the consonant in question is fully articulated (Warren & Marslen-Wilson, 1987; Warren & Marslen-Wilson, 1988), although it is not clear why the same cues could not be used to determine that a voiceless item was being heard. The voicing effect is independent of the morpho-phonological effect, although it introduced a bias against our hypothesis in the data. As explained in Section 2 above, the conditions did not have equal numbers of items with voiced and voiceless final consonants. Since the (pseudo)inflected items had both voiced and voiceless endings, while uninflected items only had voiceless final consonants, the faster response times for the voiced items in the (pseudo)inflected conditions speeded up responses relative to the uninflected conditions. As a result, when voicing was eliminated as a factor, the morpho-phonological effect became even stronger, further increasing the difference between monomorphemic and morphologically complex items. 5 Conclusion The segmentation of regular and pseudo-regular forms places specific demands on the neural and functional mechanisms involved in speech processing. We propose that the neuro-cognitive machinery underlying perceptual processing of spoken words in English involves both lexical access and automatic interpretative processing of the grammatical properties of the incoming words, where the extraction and interpretation of grammatical morphemes is triggered by morpho-phonological cues. This view is best accommodated in an account in which segmentation of incoming speech sounds into stems and affixes is distinguished from direct mapping between phonological forms and lexical representations. This decompositional account of the processing of regular inflections in English (Marslen-Wilson & Tyler, 2007), invoking a core left fronto-temporal neural substrate, would explain the results of the neuropsychological study discussed earlier (Tyler et al., 2002), in which patients not only had processing difficulties with regular past tense forms, but showed diminished performance across the board for items that show the critical morpho-phonological properties of inflected forms. It would also accommodate findings from priming experiments with patients with a regular past tense deficit, where regularly inflected forms did not prime either morphologically related forms (jumped – jump; Tyler, de Mornay-Davies, et al., 2002a) or semantically related forms (jumped – leap; Longworth, Marslen-Wilson, Randall, & Tyler, 2005). If the patient’s morpho-phonologically triggered processing of these forms is disrupted, this would impair access to stored lexical representations of underlying stems. The morpho-phonological account also provides an alternative interpretation of some of the findings of the neuropsychological study of Bird et al. (2003), who included two conditions that contrasted in voicing agreement (an – and versus an – ant) in a similar manner to the pseudo-inflected and [+Coronal, −Voice] conditions of the present experiment. Patients’ performance was worse for the former, which exhibited the critical morpho-phonological properties of inflections, than for the latter, which did not. In fact, if the pattern of the rhyme is as strong a cue as the present findings suggest, then the processing of irregular past tense forms that have the IRP, like slept, should initially resemble that of regulars like stepped, since the perceptual system is blind to the morphological composition of the incoming signal. The change in vowel quality in irregular past forms would still provide an early cue to the presence of an irregular rather than a real regular past tense form, but the morpho-phonologically triggered attempt at decomposing the incoming string might still slow down response times relative to “irregular irregulars” like took. This type of morpho-phonologically triggered processing may have contributed to Joanisse and Seidenberg’s recent fMRI findings, using a verb production task, which showed different activation effects in both left and right frontal regions for regulars than for irregulars, but similar activation patterns to regulars for a subset of pseudo-regular irregulars of the slept type (Joanisse & Seidenberg, 1999). This is not to say that there is no contribution from phonology in the processing of inflected forms. On the contrary, our findings for voicing and syllabicity confirm that phonological factors do play an important role in the ability to process inflected words in English, complementing previous findings about factors such as phonotactic probabilities, various semantic properties, and stem and word form frequency, which have also been shown to impinge on inflectional processing (e.g., Baayen & Moscoso del Prado Martín, 2005; Hare, Ford, & Marslen-Wilson, 1999; Hay, 2001; Sereno & Jongman, 1997; Tabak, Schreuder, & Baayen, 2005; Vitevich & Luce, 1999; Vitevich & Luce, 2005). In the Words and Rules and declarative/procedural frameworks, such effects have led to the proposal that regular inflections may also be lexically stored and accessed as full forms if they are highly frequent (e.g., Pinker & Ullman, 2002). By contrast, our proposal stresses the automaticity of the segmentation process, which is triggered for any potentially inflected form. In this respect, the account advocated here is more reminiscent of Taft and Forster’s claims for an early, obligatory process of prefix stripping in visual word recognition (Taft & Forster, 1975) – though since the focus of the two accounts is very different, it is hard to compare them directly. A direct comparison with the Words and Rules and declarative/procedural accounts is also difficult, since their predictions about relative processing times for morphologically simplex and complex words tend to focus on production (see e.g., Pinker and Ullman (2002)). They claim that the retrieval of an irregular form will block the formation of a regularly inflected form in production. If this blocking process transfers to word recognition, it would predict that only real inflected forms undergo decompositional processing. If so, pseudo-inflected forms (and irregulars with the rhyme pattern) should group with monomorphemic forms, but this is not corroborated by our findings. In terms of connectionist approaches to speech comprehension, the current results have both specific and general implications. First, the results here are inconsistent with the perceptual difficulty account proposed by McClelland, Patterson and associates (e.g., McClelland & Patterson, 2003) to explain apparent selective impairments in processes involving regular inflectional morphology. This account attributes patients’ difficulties with such forms to the additional “phonological complexity and perceptual subtlety” of words ending in coronal obstruents such as [t] and [d]. In the current research we see no evidence for greater processing demands associated with the presence of coronality or obstruency per se. Increases in response time and error rate are only seen when these phonemic elements occur in the wider context of the inflectional rhyme pattern, indicating that it is the broader functional context that is relevant here. This broader context seems to have specific morpho-phonological and morpho-syntactic properties, which are both aspects of lexical processing systems that are assigned epiphenomenal status in current connectionist thinking. These difficulties for the McClelland and Patterson account do not, of course, mean that connectionist accounts cannot be proposed which do incorporate the notion of the IRP, so that the statistical regularities associated with its distribution in English are used to influence network performance. In so far as these regularities have a signalling function that is specifically morphological in nature (as indicated by current results), then such augmented connectionist models would also need some way of capturing these higher-order properties. One way of doing so might be via the morphological sub-regularities that are seen to emerge in some recent models (Davis, van Casteren, & Marslen-Wilson, 2003; Plaut & Gonnerman, 2000; Rueckl & Raveh, 1999). It is less clear how the behaviour of the pseudo-regular pairs could be captured, since semantically they are like the noninflected word pairs, but nonetheless group with the real inflected pairs in the present experiment (though see Plaut and Gonnerman (2000)). More generally, however, even if a connectionist learning model is implemented that is able to capture the pattern of IRP effects observed here (and in earlier research), this does not mean that we are also obliged to take on board the claims of such a model for the functional architecture of the language processing system. Claims for a single system architecture are not consistent with the extensive evidence that has now accumulated for a more complex and differentiated neuro-biological substrate for human language, especially where morpho-syntactic functions are concerned (for reviews see Marslen-Wilson (2007); Marslen-Wilson and Tyler (2007); Tyler and Marslen-Wilson (2008)). There is indeed room – if not necessity – for statistical learning models as part of an explanatory neuro-cognitive theory, but only if appropriately related to a processing architecture that is neuro-biologically plausible. The contribution of this paper, in summary, is that it takes our understanding of the language processing system to a different level of specificity, forcing us to be more explicit about the conditions in which we expect certain phonological and morpho-phonological segmentation processes to occur, and how they may impinge on each other. Clearly, a strictly modular interpretation of a dual mechanism account would not have the flexibility to accommodate the multiple interacting factors that play a role during the retrieval of word forms, where some factors would appear to affect all forms regardless of their morphological status, but others uniquely surface when potentially inflected forms are encountered. Rather, as Bybee and McClelland (2005, p399) point out, the processing of these items must use general and specific information simultaneously, without presupposing that they are mutually exclusive. Whatever its underlying computational properties, the processing system will have to be able to handle morpho-phonologically cued information about morphological complexity and more direct mapping between incoming form and lexical representation, while allowing for phonological, semantic and lexical factors to take effect. Such conflicting pressures on the processing system could perhaps be insightfully considered in an optimality theoretic framework, as suggested by Burzio (2002), but as this study shows, the account will have to allow for reference to the morphological properties of words (e.g., in stratal optimality theory; Bermúdez-Otero, 1999; Kiparsky, 2000). The probabilistic nature of various factors in inflectional processing emphasised by Baayen and Moscoso del Prado Martín (2005), for instance, could also be represented if the conflicting constraints are assumed to be probabilistic in nature (e.g., Boersma and Hayes (2001)). However, regardless of the framework chosen, our study shows that the account will have to be informed by a more systematic examination of the scope of morpho-phonological effects in various inflectional paradigms in typologically different languages. Acknowledgements We would like to thank Harald Baayen and two anonymous reviewers for their helpful comments and suggestions. This work was supported by UK Medical Research Council funding to WMW (U.1055.04.002.00001.01) and LKT (G0500842), as well as a Small Research Grant from the British Academy to LKT. Appendix A List of items Real regular past tense in /t/ and /d/ Nonwords in /t/ and /d/ Word 1 Word 2 Allomorph CV struct Word 1 Word 2 Ending CV struct 1 prayed/preyed pray/prey d CCVC cayed cay d CVC 2 plied ply d CCVC gared gare d CVC 3 laid lay d CVC geed ghee d CVC 4 thawed thaw/thor d CVC miered mier d CVC 5 paid pay d CVC kied kie d CVC 6 bowed (au) bow (au) d CVC kushed kush t CVCC 7 wooed woo d CVC larned larn d CVCC 8 filled fill d CVCC meast miece t CVCC 9 rubbed rub d CVCC minned min d CVCC 10 warned warn/worn d CVCC parft parf t CVCC 11 joined join d CVCC foped fope t CVCC 12 raised raise d CVCC dapped dap t CVCC 13 blessed bless t CCVCC hessed hess t CVCC 14 clapped clap t CCVCC rawled rawl d CVCC 15 thrashed thrash t CCVCC soined soin d CVCC 16 wiped wipe t CVCC wobbed wob d CVCC 17 soaked soak t CVCC gubbed gub d CVCC 18 seeped seep t CVCC keered keer d CVCC 19 coped cope t CVCC boaked boak t CVCC 20 gaped gape t CVCC bloud blou d CCVC 21 pushed push t CVCC chayed chay d CCVC 22 washed wash t CVCC starced starce t CCVCC 23 ceased cease t CVCC stessed stess t CCVCC 24 pierced pierce t CVCC jiped jipe t CVCC Noncoronal in /p/ and /k/ Nonwords in /p/ and /k/ Word 1 Word 2 Ending CV struct Word 1 Word 2 Ending CV struct 1 peak/peek pea/pee k CVC bjupe bew p CCVC 2 bark bar/baa k CVC clope clow p CCVC 3 perk purr k CVC grulp grull p CCVCC 4 mark mar/ma k CVC qump qum p CCVCC 5 whelk well k CVCC plamp plam p CCVCC 6 bank bang k CVCC fupe foo p CVC 7 milk mill k CVCC rark rar k CVC 8 hulk hull k CVCC gurk gur k CVC 9 silk sill k CVCC sark sar k CVC 10 wink wing k CVCC durk durr k CVC 11 rink ring/wring k CVCC pelk pell k CVCC 12 kink king k CVCC tulk tull (hull) k CVCC 13 troop/troupe true p CCVC fink fing k CVCC 14 slope slow/sloe p CCVC mank mang k CVCC 15 clamp clam p CCVCC bink bing k CVCC 16 plump plum/plumb p CCVCC lilk lill k CVCC 17 cramp cram p CCVCC hink hing k CVCC 18 soap sew/so p CVC shulk shull k CVCC 19 hemp hem p CVCC famp fam p CVCC 20 lamp lamb p CVCC wump wum p CVCC 21 damp dam/damn p CVCC lemp lem p CVCC 22 hump hum p CVCC simp sim p CVCC 23 rump rum p CVCC mamp mam p CVCC 24 gulp gull p CVCC bamp bam p CVCC Nonpseudo-regulars in /t/ Nonwords in /t/ Word 1 Word 2 Ending CV struct Word 1 Word 2 Ending CV struct 1 saint sane t CVCC twight twy t CCVC 2 cult cull t CVCC steet stee t CCVC 3 tint tin t CVCC prunt prun t CCVCC 4 dent den t CVCC prilt prill t CCVCC 5 bolt bowl t CVCC crilt crill t CCVCC 6 punt pun t CVCC nart nar t CVC 7 rent wren t CVCC lart lar t CVC 8 hilt hill t CVCC shaint shane t CVC 9 guilt gill t CVCC shayt shay t CVC 10 dint din t CVCC deet dee t CVC 11 tilt till t CVCC haint hain t CVCC 12 pint pine t CVCC sult sull t CVCC 13 belt bell t CVCC rint rin t CVCC 14 tent ten t CVCC nent nen t CVCC 15 light lie t CVC ghent ghen t CVCC 16 cart car t CVC nint nin t CVCC 17 neat knee t CVC sant san t CVCC 18 port pour/paw/poor t CVC kint kine t CVCC 19 bait/bate bay t CVC rult rull t CVCC 20 stilt still t CCVCC yilt yill t CVCC 21 quilt quill t CCVCC ghelt ghell t CVCC 22 stunt stun t CCVCC shent shen t CVCC 23 slight sly t CCVC shilt shill t CVCC 24 start star t CCVC lunt lun t CVCC Pseudo-regulars in /t/ and /d/ Word 1 Word 2 Ending CV struct 1 ford for d CVC 2 wand wan d CVCC 3 wide why d CVC 4 field feel d CVCC 5 tweed twee d CCVC 6 cord core d CVC 7 beard beer d CVC 8 weird weir d CVC 9 gold goal d CVCC 10 mild mile d CVCC 11 proud prow d CCVC 12 wind win d CVCC 13 cold coal d CVCC 14 bald ball/bawl d CVCC 15 fund fun d CVCC 16 mould mole d CVCC 17 rift riff t CVCC 18 graft graph t CCVCC 19 chest chess t CVCC 20 bust bus t CVCC 21 fast farce t CVCC 22 crest cress t CCVCC 23 deft deaf t CVCC 24 tuft tough t CVCC Present in /s/ and /z/ Nonwords in /s/ and /z/ Word 1 Word 2 Allomorph CV struct Word 1 Word 2 Ending CV struct 1 gloats gloat s CCVCC groys groy z CCVC 2 sniffs sniff s CCVCC graws graw z CCVC 3 flips flip s CCVCC plocks plock s CCVCC 4 licks lick s CVCC throcks throck s CCVCC 5 mocks mock s CVCC glips glip s CCVCC 6 tucks tuck s CVCC fies fie z CVC 7 picks pick s CVCC koes ko z CVC 8 bakes bake s CVCC sares sare z CVC 9 pokes poke s CVCC tays tay z CVC 10 wraps/raps wrap/rap s CVCC tause tau z CVC 11 reaps reap s CVCC pives pive z CVCC 12 rips rip s CVCC baves bave z CVCC 13 stirs stir z CCVC cuvs cuv z CVCC 14 stows stow z CCVC dags dag z CVCC 15 dies/dyes die/dye z CVC dapes dape z CVCC 16 mows mow z CVC bips bip s CVCC 17 gnaws gnaw/nor z CVC pakes pake s CVCC 18 shows show z CVC soats soat s CVCC 19 coos/coups coo z CVC bots bot s CVCC 20 lives live z CVCC gucks guck s CVCC 21 fails fail z CVCC bicks bick s CVCC 22 begs beg z CVCC dakes dake s CVCC 23 saves save z CVCC hicks hick s CVCC 24 nags nag z CVCC lats lat s CVCC Plural in /s/ and /z/ Word 1 Word 2 Ending CV struct 1 threats threat s CCVCC 2 grapes grape s CCVCC 3 snouts snout s CCVCC 4 lips lip s CVCC 5 debts debt s CVCC 6 cats cat s CVCC 7 shirts shirt s CVCC 8 lakes lake s CVCC 9 goats goat s CVCC 10 hips hip s CVCC 11 shots shot s CVCC 12 paths path s CVCC 13 dunes dune z CCVC 14 globes globe z CCVC 15 cows cow z CVC 16 psalms psalm z CVC 17 doors door z CVC 18 thorns thorn z CVC 19 whims whim z CVC 20 birds bird z CVCC 21 cones cone z CVCC 22 barns barn z CVCC 23 meals meal z CVCC 24 yards yard z CVCC Real regular past in /Id/ Nonword /Id/ Word 1 Word 2 Allomorph CV struct Word 1 Word 2 Ending CV struct 1 greeted greet Id CCVC(VC) scaded scade Id CCVC 2 fretted fret Id CCVC(VC) snaiting snait Id CCVC 3 flaunted flaunt Id CCVCC(VC) clended clend Id CCVCC 4 jilted jilt Id CCVCC(VC) flanted flant Id CCVCC 5 scolded scold Id CCVCC(VC) groasted groast Id CCVCC 6 knitted knit/nit Id CVC(VC) ketted ket Id CVC 7 waded wade/weighed Id CVC(VC) reeted reet Id CVC 8 waited/weighted wait/weight Id CVC(VC) yitted yit Id CVC 9 faded fade Id CVC(VC) bodded bod Id CVC 10 nodded nod Id CVC(VC) saded sade Id CVC 11 lasted last Id CVCC(VC) maisted maist Id CVCC 12 melted melt Id CVCC(VC) woasted woast Id CVCC 13 welded weld Id CVCC(VC) waunted waunt Id CVCC 14 wanted want/wont Id CVCC(VC) pilded pild Id CVCC 15 basted baste/based Id CVCC(VC) bulted bult Id CVCC 16 mended mend Id CVCC(VC) relted relt Id CVCC 17 wilted wilt Id CVCC(VC) wended wend Id CVCC 18 wielded wield Id CVCC(VC) sested sest Id CVCC 19 gilded gild/guild Id CVCC(VC) walded wald Id CVCC 20 wafted waft Id CVCC(VC) munted munt Id CVCC 21 pelted pelt Id CVCC(VC) banted bant Id CVCC 22 ranted rant Id CVCC(VC) bafted baft Id CVCC 23 boasted boast Id CVCC(VC) gielded gield Id CVCC 24 shunted shunt Id CVCC(VC) milted milt Id CVCC Progressive aspect Nonword Word 1 Word 2 Allomorph CV struct Word 1 Word 2 Ending CV struct 1 drowning drown CCVC(VC) cleading clead ing CCVC 2 pleading plead CCVC(VC) cleeming cleem ing CCVC 3 cleansing cleanse CCVCC(VC) ploaxing ploax ing CCVCC 4 clanking clank CCVCC(VC) slending slend ing CCVCC 5 slinking slink CCVCC(VC) frinking frink ing CCVCC 6 hurting hurt CVC(VC) bowning bown ing CVC 7 seeming seem/seam CVC(VC) dading dade ing CVC 8 lurking lurk CVC(VC) surking surk ing CVC 9 teasing tease CVC(VC) measing mease ing CVC 10 leaning lean CVC(VC) werting wert ing CVC 11 yanking yank CVCC(VC) fanking fank ing CVCC 12 solving solve CVCC(VC) folving folve ing CVCC 13 thanking thank CVCC(VC) panking pank ing CVCC 14 founding found CVCC(VC) lounding lound ing CVCC 15 resting/wresting rest/wrest CVCC(VC) tarsting tarst ing CVCC 16 tending tend CVCC(VC) drending drend ing CVCC 17 bending bend CVCC(VC) sunching sunch ing CVCC 18 coaxing coax/cokes CVCC(VC) rouncing rounce ing CVCC 19 sounding sound CVCC(VC) fasking fask ing CVCC 20 yielding yield CVCC(VC) fifting fift ing CVCC 21 sifting sift CVCC(VC) selving selve ing CVCC 22 fending fend CVCC(VC) loasting loast ing CVCC 23 bouncing bounce CVCC(VC) touncing tounce ing CVCC 24 folding fold CVCC(VC) yixing yix ing CVCC Appendix B Harmonic estimated marginal mean reaction times for condition estimated in two separate analyses of variance for different and same items with fixed factor condition (14 levels) and covariate word 2 duration Condition Mean (ms) different items a Mean (ms) same items b Regular past /t/ /d/ filled–fill 967 926 Pseudo past /t/ /d/ mild–mile 977 907 [-Cor, −VoiAgree] /k, p/ lamp–lamb 827 869 [+Cor, −VoiAgree] /t/ belt–bell 823 856 Present /s/ /z/ fails–fail 935 889 Plural /s/ /z/ meals–meal 935 884 Regular past /Id/ folded–fold 809 805 Progressive fending–fend 835 837 Nonword /d/ /t/ gubbed–gub 922 899 Nonword /t/ (not past) steet–stee 858 896 Nonword /p/ /k/ wump–wum 838 872 Nonword /s/ /z/ pakes–pake 956 879 Nonword /Id/ milted–milt 832 836 Nonword sunching–sunch 829 815 a Condition: F(13,313)=12.66, p <.001; word 2 duration: F(1,313)=109.53, p <.001. Covariates appearing in the model are evaluated at the following values: duration word 2=696.14. b Condition: F(13,319)=5.25, p <.001; word 2 duration: F(1,319)=239.66, p <001. Covariates appearing in the model are evaluated at the following values: duration word 2=772.03. References Baayen and Moscoso del Prado Martín, 2005 R.H. Baayen F. Moscoso del Prado Martín Semantic density and past-tense formation in three Germanic languages Language 81 3 2005 666 698 Baayen et al., 1995 R.H. Baayen R. Piepenbrock L. Gulikers The CELEX Lexical Database [CD-ROM] 1995 Linguistic Data Consortium, University of Pennsylvania. Philadelphia, PA Bermúdez-Otero, 1999 Bermúdez-Otero, R. (1999). Constraint interaction in language change. Opacity and globality in phonological change. Unpublished doctoral dissertation, University of Manchester/Universidad de Santiago de Compostela. Bird et al., 2003 H. Bird M.A. Lambon Ralph M.S. Seidenberg J.L. McClelland K. Patterson Deficits in phonology and past-tense morphology: What’s the connection? Journal of Memory and Language 48 3 2003 502 526 Boersma and Hayes, 2001 P. Boersma B. Hayes Empirical tests of the gradual learning algorithm Linguistic Inquiry 32 2001 45 86 Burzio, 2002 L. Burzio Missing players: Phonology and the past-tense debate Lingua 112 2002 157 199 Bybee and McClelland, 2005 J. Bybee J.L. McClelland Alternatives to the combinatorial paradigm of linguistic theory based on domain general principles of human cognition The Linguistic Review 22 2005 381 410 Clahsen, 1999 H. Clahsen Lexical entries and rules of language: A multi-disciplinary study of German inflection Behavioral and Brain Sciences 22 6 1999 991 1013 Davis et al., 2002 M.H. Davis W.D. Marslen-Wilson M.G. Gaskell Leading up the lexical garden-path: Segmentation and ambiguity in spoken word recognition Journal of Experimental Psychology: Human Perception and Performance 28 2002 218 244 Davis et al., 2003 M.H. Davis M. van Casteren W.D. Marslen-Wilson Frequency effects in processing inflected Dutch nouns: A distributed connectionist account R.H. Baayen R. Schreuder Morphological structure in language processing 2003 Mouton Berlin 427 462 Forster and Forster, 2003 K.I. Forster J.C. Forster DMDX: A windows display program with millisecond accuracy Behaviour Research Methods, Instruments, and Computers 35 2003 116 124 Gimson, 1961 A.C. Gimson An introduction to the pronunciation of English 1961 Edward Arnold London Hare et al., 1999 M. Hare M. Ford W.D. Marslen-Wilson Ambiguity and frequency effects in regular verb inflection J. Bybee P. Hopper Frequency and the emergence of linguistic structure 1999 John Benjamins Amsterdam 181 200 Hawkins and Nguyen, 2004 S. Hawkins N. Nguyen Influence of syllable-coda voicing on the acoustic properties of syllable-onset /l/ in English Journal of Phonetics 32 2004 199 231 Hay, 2001 J. Hay Lexical frequency in morphology. Is everything relative? Linguistics 39 2001 1041 1070 Hume et al., 1999 E. Hume K. Johnson M. Seo G. Tserdanelis A cross-linguistic study of stop place perception Proceedings of the International Congress of the Phonetic Sciences 1999 2069 2072 Joanisse and Seidenberg, 1999 M.F. Joanisse M.S. Seidenberg Impairments in verb morphology after brain injury: A connectionist model Proceedings of the National Academy of Sciences 96 1999 7592 7597 Jun, 1995 Jun, J. (1995). Perceptual and articulatory factors in place assimilation: An Optimality Theoretic approach. Doctoral dissertation, University of California, Los Angeles. Kiparsky, 2000 P. Kiparsky Opacity and cyclicity The Linguistic Review 17 2000 351 365 Klatt, 1976 D. Klatt Linguistic uses of segmental duration in English: Acoustic and perceptual evidence Journal of the Acoustical Society of America 59 1976 1208 1221 Kochetov, 2004 A. Kochetov Perception of place and secondary articulation contrasts in different syllable positions: Language-particular and language-independent asymmetries Language and Speech 47 4 2004 351 382 Lehiste, 1972 I. Lehiste The timing of utterances and linguistic boundaries Journal of the Acoustical Society of America 51 1972 2018 2024 Lehtonen et al., 2006 M. Lehtonen V.A. Vorobyev K. Hugdahl T. Tuokkola M. Laine Neural correlates of morphological decomposition in a morphologically rich language: An fMRI study Brain and Language 98 2006 182 193 Longworth et al., 2005 C.E. Longworth W.D. Marslen-Wilson B. Randall L.K. Tyler Getting to the meaning of the regular past tense: Evidence from neuropsychology Journal of Cognitive Neuroscience 17 7 2005 1087 1097 Maddieson, 1985 I. Maddieson Patterns of sounds 1985 Cambridge University Press Cambridge Marshall and van der Lely, 2006 C. Marshall H. van der Lely A challenge to current models of past tense inflection: The impact of phonotactics Cognition 100 2006 302 320 Marslen-Wilson, 2007 W.D. Marslen-Wilson Morphological processes in language comprehension G. Gaskell Oxford handbook of psycholinguistics 2007 OUP Oxford 175 193 Marslen-Wilson and Tyler, 1997 W.D. Marslen-Wilson L.K. Tyler Dissociating types of mental computation Nature 387 1997 592 594 Marslen-Wilson and Tyler, 1998 W.D. Marslen-Wilson L.K. Tyler Rules, representations, and the English past tense Trends in Cognitive Science 2 1998 428 435 Marslen-Wilson and Tyler, 2003 W.D. Marslen-Wilson L.K. Tyler Capturing underlying differentiation in the human language system Trends in Cognitive Sciences 7 2 2003 62 63 Marslen-Wilson and Tyler, 2007 W.D. Marslen-Wilson L.K. Tyler Morphology, language, and the brain: A decompositional substrate for language comprehension Philosophical Transactions of the Royal Society B: Biological Sciences 362 2007 823 836 McClelland and Patterson, 2003 J. McClelland K. Patterson Differentiation and integration in human language. Reply to Marslen-Wilson and Tyler Trends in Cognitive Sciences 7 2 2003 63 64 Paradis and Prunet, 1991 C. Paradis J.F. Prunet The special status of coronals: Internal and external evidence (phonology and phonetics 2) 1991 Academic Press San Diego Peterson and Lehiste, 1960 G.E. Peterson L. Lehiste Duration of syllable nuclei in English Journal of the Acoustical Society of America 32 1960 693 703 Pinker, 1991 S. Pinker Rules of language Science 253 1991 530 535 Pinker, 1999 S. Pinker Words and rules: The ingredients of language 1999 HarperCollins New York Pinker and Ullman, 2002 S. Pinker M.T. Ullman The past and future of the past tense Trends in Cognitive Sciences 6 11 2002 456 463 Plaut and Gonnerman, 2000 D.C. Plaut L.M. Gonnerman Are non-semantic morphological effects incompatible with a distributed connectionist approach to lexical processing? Language and Cognitive Processes 15 2000 445 485 Plunkett and Marchman, 1993 K. Plunkett V. Marchman From rote learning to system building: Acquiring verb morphology in children and connectionist nets Cognition 48 1993 21 69 Ratcliff, 1993 R. Ratcliff Methods for dealing with reaction time outliers Psychological Bulletin 114 1993 510 532 Rueckl and Raveh, 1999 J.G. Rueckl M. Raveh The influence of morphological regularities on the dynamics of a connectionist network Brain and Language 68 1999 110 117 Rumelhart and McClelland, 1986 Rumelhart, D. E., & McClelland, J. L. (1986). On learning the past tenses of English verbs. In J. L. McClelland, D. E. Rumelhart, & the PDP Research Group (Eds.), Parallel distributed processing: Explorations in the microstructures of cognition (Vol. 2, pp. 216–271). Cambridge: Bradford/MIT Press. Sereno and Jongman, 1997 J. Sereno A. Jongman Processing of English inflectional morphology Memory and Cognition 25 1997 425 437 Stemberger, 1991 J.P. Stemberger Apparent anti-frequency effects in language production: The Addition Bias and phonological underspecification Journal of Memory and Language 30 1991 161 185 Tabak et al., 2005 W. Tabak R. Schreuder R.H. Baayen Lexical statistics and lexical processing: Semantic density, information complexty, sex, and irregularity in Dutch S. Kepser M. Reis Linguistic evidence: Empirical, theoretical, and computational perspectives 2005 Mouton The Hague 529 555 Taft and Forster, 1975 M. Taft K.I. Forster Lexical storage and retrieval of prefixed words Journal of Verbal Learning and Verbal Behavior 14 1975 638 647 Tyler et al., 2002a L.K. Tyler P. de Mornay Davies R. Anokhina C. Longworth B. Randall W.D. Marslen-Wilson Dissociations in processing past tense morphology: Neuropathology and behavioural studies Journal of Cognitive Neuroscience 14 1 2002 79 95 Tyler et al., 2002b L.K. Tyler B. Randall W.D. Marslen-Wilson Phonology and neuropsychology of the English past tense Neuropsychologia 40 2002 1154 1166 Tyler et al., 2005a L.K. Tyler E.A. Stamatakis B. Post B. Randall W.D. Marslen-Wilson Temporal and frontal systems in speech comprehension: An fMRI study of past tense processing Neuropsychologia 43 13 2005 1963 1974 Tyler et al., 2005b L.K. Tyler W.D. Marslen-Wilson E.A. Stamatakis Differentiating lexical form, meaning and structure in the neural language system Proceedings of the National Academy of Sciences 102 23 2005 8375 8380 Tyler and Marslen-Wilson, 2008 L.K. Tyler W.D. Marslen-Wilson Fronto-temporal brain systems supporting spoken language comprehension Philosophical Transactions of the Royal Society of London B: Biological Sciences 363 2008 1037 1054 Theme Issue ‘The perception of speech: From sound to meaning’ Ullman, 2004 M.T. Ullman Contributions of memory circuits to language: The declarative/procedural model Cognition 92 2004 231 270 Ullman et al., 1997 M.T. Ullman S. Corkin M. Coppola G. Hickok J.H. Growdon W.J. Koroshetz A neural dissociation within language: Evidence that the mental dictionary is part of declarative memory, and that grammatical rules are processed by the procedural system Journal of Cognitive Neuroscience 9 1997 266 276 Vitevich and Luce, 1999 M.S. Vitevich P.A. Luce Probabilistic phonotactics and spoken word recognition Journal of Memory and Language 40 1999 374 408 Vitevich and Luce, 2005 M.S. Vitevich P.A. Luce Increases in phonotactic probability facilitate spoken nonword repetition Journal of Memory and Language 52 2005 193 204 Warren and Marslen-Wilson, 1987 P. Warren W.D. Marslen-Wilson Continuous uptake of acoustic cues in spoken word-recognition Perception & Psychophysics 41 1987 262 275 Warren and Marslen-Wilson, 1988 P. Warren W.D. Marslen-Wilson Cues to lexical choice: Discriminating place and voice Perception & Psychophysics 43 1988 21 30 Wiik, 1965 Wiik, K. (1965). Finnish and English vowels. Turku. Wilson, 1988 M.D. Wilson The MRC Psycholinguistic Database: Machine readable dictionary, version 2 Behavioural Research Methods, Instruments and Computers 20 1 1988 6 11 Wurm, 1997 L.H. Wurm Auditory processing of prefixed English words is both continuous and decompositional Journal of Memory and Language 37 1997 438 461"
10.1016/j.cognition.2008.06.012,Subliminal speech perception and auditory streaming ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081011', '$': '2008-10-11'}}}}"
10.1016/j.cognition.2008.06.013,Twelve-month-olds communicate helpfully and appropriately for knowledgeable and ignorant partners ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080821', '$': '2008-08-21'}}}}"
10.1016/j.cognition.2008.06.014,Rational and mechanistic perspectives on reinforcement learning ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080822', '$': '2008-08-22'}}}}"
10.1016/j.cognition.2008.07.001,It’s no accident: Our bias for intentional explanations ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080809', '$': '2008-08-09'}}}}"
10.1016/j.cognition.2008.07.002,Friend or foe: The effect of implicit trustworthiness judgments in social decision-making ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080821', '$': '2008-08-21'}}}}"
10.1016/j.cognition.2008.07.003,Individual differences in the perception of similarity and difference ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080821', '$': '2008-08-21'}}}}"
10.1016/j.cognition.2008.07.004,Establishing object correspondence across eye movements: Flexible use of spatiotemporal and surface feature information ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080828', '$': '2008-08-28'}}}}"
10.1016/j.cognition.2008.07.005,Pragmatic expectations and linguistic evidence: Listeners anticipate but do not integrate common ground ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080828', '$': '2008-08-28'}}}}"
10.1016/j.cognition.2008.07.006,Inductive reasoning about causally transmitted properties ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081025', '$': '2008-10-25'}}}}"
10.1016/j.cognition.2008.07.007,A case of hand waving: Action synchrony and person perception ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080827', '$': '2008-08-27'}}}}"
10.1016/j.cognition.2008.07.008,Data from eye-tracking corpora as evidence for theories of syntactic processing complexity ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081018', '$': '2008-10-18'}}}}"
10.1016/j.cognition.2008.07.009,Creators’ intentions bias judgments of function independently from causal inferences ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081002', '$': '2008-10-02'}}}}"
10.1016/j.cognition.2008.07.010,Lexical effects on speech perception in individuals with “autistic” traits ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081002', '$': '2008-10-02'}}}}"
10.1016/j.cognition.2008.07.011,Little houses and casas pequeñas: Message formulation and syntactic form in unscripted speech with speakers of English and Spanish ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081007', '$': '2008-10-07'}}}}"
10.1016/j.cognition.2008.07.012,Orienting in virtual environments: How are surface features and environmental geometry weighted in an orientation task? ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081002', '$': '2008-10-02'}}}}"
10.1016/j.cognition.2008.07.013,The spacing effect in children’s memory and category induction ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081005', '$': '2008-10-05'}}}}"
10.1016/j.cognition.2008.07.014,Regulating cognitive control through approach-avoidance motor actions ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081005', '$': '2008-10-05'}}}}"
10.1016/j.cognition.2008.07.015,Sound symbolism facilitates early verb learning ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081005', '$': '2008-10-05'}}}}"
10.1016/j.cognition.2008.07.016,Effects of language experience on the perception of American Sign Language ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081002', '$': '2008-10-02'}}}}"
10.1016/j.cognition.2008.07.017,Going beyond the evidence: Abstract laws and preschoolers’ responses to anomalous data ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081017', '$': '2008-10-17'}}}}"
10.1016/j.cognition.2008.07.018,Visual homing in the absence of feature-based landmark information ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080918', '$': '2008-09-18'}}}}"
10.1016/j.cognition.2008.07.019,"
               Tight and loose are not created equal: An asymmetry underlying the representation of fit in English- and Korean-speakers ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081117', '$': '2008-11-17'}}}}"
10.1016/j.cognition.2008.08.001,Erratum to “Meaning matters in children’s plural productions” [Cognition 108 (2008) 466–476],"serial JL 271061 291210 291723 291726 291738 291743 291782 31 Cognition COGNITION 2008-11-14 2008-11-14 2010-03-29T04:58:46 1-s2.0-S0010027708001820 S0010-0277(08)00182-0 S0010027708001820 10.1016/j.cognition.2008.08.001 S300 S300.1 FULL-TEXT 1-s2.0-S0010027708X00113 2015-05-14T00:00:22.981292-04:00 0 0 20081201 20081231 2008 2008-11-14T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype volfirst volissue webpdf webpdfpagecount body articletitle auth authfirstini authfull authlast pubtype alllist content subj ssids 0010-0277 00100277 109 109 3 3 Volume 109, Issue 3 12 431 431 200812 December 2008 2008-12-01 2008-12-31 2008 Erratum simple-article err Copyright © 2008 Elsevier B.V. All rights reserved. ERRATUMMEANINGMATTERSINCHILDRENSPLURALPRODUCTIONSCOGNITION1082008466476 ZAPF J 10.1016/j.cognition.2008.03.008 S0010027708000802 ZAPFX2008X431 ZAPFX2008X431XJ item S0010-0277(08)00182-0 S0010027708001820 1-s2.0-S0010027708001820 10.1016/j.cognition.2008.08.001 271061 2010-10-11T05:17:06.957431-04:00 2008-12-01 2008-12-31 1-s2.0-S0010027708001820-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708001820/MAIN/application/pdf/4fdc910594b5327364b4549457f55984/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708001820/MAIN/application/pdf/4fdc910594b5327364b4549457f55984/main.pdf main.pdf pdf true 98864 MAIN 1 1-s2.0-S0010027708001820-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708001820/PREVIEW/image/png/ad7ef99cc7055eb9345ef5f2b593bc1e/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708001820/PREVIEW/image/png/ad7ef99cc7055eb9345ef5f2b593bc1e/main_1.png main_1.png png 20658 849 656 IMAGE-WEB-PDF 1 COGNIT 1859 S0010-0277(08)00182-0 10.1016/j.cognition.2008.08.001 S0010-0277(08)00080-2 10.1016/j.cognition.2008.03.008 Elsevier B.V. Erratum Erratum to “Meaning matters in children’s plural productions” [Cognition 108 (2008) 466–476] Jennifer A. Zapf Linda B. Smith The publisher regrets that in the publishing of the above article Table 2 caption on p. 472 is not correct. Please replace Table 2 caption “Mean age and age ranges … mean vocabulary and vocabulary ranges per group” with the following sentence: Table 2 Mean age and age ranges (in months) as well as mean vocabulary and vocabulary ranges per group. We apologise for any embarrassment caused to the authors due to the above error."
10.1016/j.cognition.2008.08.002,The link between speech perception and production is phonological and abstract: Evidence from the shadowing task ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20080920', '$': '2008-09-20'}}}}"
10.1016/j.cognition.2008.08.003,"Interference by process, not content, determines semantic auditory distraction ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081210', '$': '2008-12-10'}}}}"
10.1016/j.cognition.2008.08.004,Frequency trajectory effects in Chinese character recognition: Evidence for the arbitrary mapping hypothesis ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081216', '$': '2008-12-16'}}}}"
10.1016/j.cognition.2008.08.005,Differences in preschoolers’ and adults’ use of generics about novel animals and artifacts: A window onto a conceptual divide ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081128', '$': '2008-11-28'}}}}"
10.1016/j.cognition.2008.08.006,Semantically induced distortions of visual awareness in a patient with Balint’s syndrome ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081117', '$': '2008-11-17'}}}}"
10.1016/j.cognition.2008.08.007,Mental imagery and synaesthesia: Is synaesthesia from internally-generated stimuli possible? ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081001', '$': '2008-10-01'}}}}"
10.1016/j.cognition.2008.08.008,Can an agent’s false belief be corrected by an appropriate communication? Psychological reasoning in 18-month-old infants ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081030', '$': '2008-10-30'}}}}"
10.1016/j.cognition.2008.08.009,The cross-linguistic categorization of everyday events: A study of cutting and breaking ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081022', '$': '2008-10-22'}}}}"
10.1016/j.cognition.2008.08.010,"Chimpanzees know what others know, but not what they believe ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081011', '$': '2008-10-11'}}}}"
10.1016/j.cognition.2008.08.011,Hierarchically organized behavior and its neural foundations: A reinforcement learning perspective ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081015', '$': '2008-10-15'}}}}"
10.1016/j.cognition.2008.09.001,The shape of human navigation: How environmental geometry is used in maintenance of spatial orientation ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081025', '$': '2008-10-25'}}}}"
10.1016/j.cognition.2008.09.002,Judgments of discrete and continuous quantity: An illusory Stroop effect ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081029', '$': '2008-10-29'}}}}"
10.1016/j.cognition.2008.09.003,Mental movements without magnitude? A study of spatial biases in symbolic arithmetic ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081031', '$': '2008-10-31'}}}}"
10.1016/j.cognition.2008.09.004,Sensory load incurs conceptual processing costs ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081108', '$': '2008-11-08'}}}}"
10.1016/j.cognition.2008.09.005,Towards a cognitive model of distraction by auditory novelty: The role of involuntary attention capture and semantic processing ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081112', '$': '2008-11-12'}}}}"
10.1016/j.cognition.2008.09.006,A probabilistic corpus-based model of syntactic parallelism ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081117', '$': '2008-11-17'}}}}"
10.1016/j.cognition.2008.09.007,The smart potential behind probability matching ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081118', '$': '2008-11-18'}}}}"
10.1016/j.cognition.2008.09.008,Sensitivity to syntax in visual cortex ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090103', '$': '2009-01-03'}}}}"
10.1016/j.cognition.2008.10.001,Action goal selection and motor planning can be dissociated by tool use ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081113', '$': '2008-11-13'}}}}"
10.1016/j.cognition.2008.10.002,Attentional loads associated with interlimb interactions underlying rhythmic bimanual coordination ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081117', '$': '2008-11-17'}}}}"
10.1016/j.cognition.2008.10.003,"A note on DeCaro, Thomas, and Beilock (2008): Further data demonstrate complexities in the assessment of information–integration category learning ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081121', '$': '2008-11-21'}}}}"
10.1016/j.cognition.2008.10.004,"Learn locally, act globally: Learning language from variation set cues ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081118', '$': '2008-11-18'}}}}"
10.1016/j.cognition.2008.10.005,Elucidating the component processes involved in dyslexic and non-dyslexic reading fluency: An eye-tracking study ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081118', '$': '2008-11-18'}}}}"
10.1016/j.cognition.2008.10.006,Estimating the probability of negative events ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081125', '$': '2008-11-25'}}}}"
10.1016/j.cognition.2008.10.007,Explanation and categorization: How “why?” informs “what?” ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081217', '$': '2008-12-17'}}}}"
10.1016/j.cognition.2008.10.008,Embodied and disembodied cognition: Spatial perspective-taking ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081203', '$': '2008-12-03'}}}}"
10.1016/j.cognition.2008.10.009,On the signals underlying conscious awareness of action ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081206', '$': '2008-12-06'}}}}"
10.1016/j.cognition.2008.10.010,Development of perceptual expertise in emotion recognition ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081206', '$': '2008-12-06'}}}}"
10.1016/j.cognition.2008.10.011,Both motor prediction and conceptual congruency between preview and action-effect contribute to explicit judgment of agency ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081126', '$': '2008-11-26'}}}}"
10.1016/j.cognition.2008.10.012,Great apes’ capacities to recognize relational similarity ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081225', '$': '2008-12-25'}}}}"
10.1016/j.cognition.2008.10.013,Role of inhibition in language switching: Evidence from event-related brain potentials in overt picture naming ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081212', '$': '2008-12-12'}}}}"
10.1016/j.cognition.2008.10.014,A developmental dissociation between category and function judgments about novel artifacts ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081220', '$': '2008-12-20'}}}}"
10.1016/j.cognition.2008.10.015,Phonetic recalibration only occurs in speech mode ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081206', '$': '2008-12-06'}}}}"
10.1016/j.cognition.2008.10.016,Reference production in young speakers with and without autism: Effects of discourse status and processing constraints ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081225', '$': '2008-12-25'}}}}"
10.1016/j.cognition.2008.10.017,The dynamic nature of knowledge: Insights from a dynamic field model of children’s novel noun generalization ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090107', '$': '2009-01-07'}}}}"
10.1016/j.cognition.2008.10.018,"Categorizing moving objects into film genres: The effect of animacy attribution, emotional response, and the deviation from non-fiction ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081231', '$': '2008-12-31'}}}}"
10.1016/j.cognition.2008.11.001,God’s categories: The effect of religiosity on children’s teleological and essentialist beliefs about categories ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081205', '$': '2008-12-05'}}}}"
10.1016/j.cognition.2008.11.002,Bilingualism and conversational understanding in young children ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081212', '$': '2008-12-12'}}}}"
10.1016/j.cognition.2008.11.003,Spontaneous mapping of number and space in adults and young children ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081217', '$': '2008-12-17'}}}}"
10.1016/j.cognition.2008.11.004,Beginning readers activate semantics from sub-word orthography ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081223', '$': '2008-12-23'}}}}"
10.1016/j.cognition.2008.11.005,The effect of visual signals on spatial decision making ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090103', '$': '2009-01-03'}}}}"
10.1016/j.cognition.2008.11.006,Feelings of control: Contingency determines experience of action ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081224', '$': '2008-12-24'}}}}"
10.1016/j.cognition.2008.11.007,Categorical perception of affective and linguistic facial expressions ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081225', '$': '2008-12-25'}}}}"
10.1016/j.cognition.2008.11.008,Tasty non-words and neighbours: The cognitive roots of lexical-gustatory synaesthesia ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081220', '$': '2008-12-20'}}}}"
10.1016/j.cognition.2008.11.009,Neural computation as a tool to differentiate perceptual from emotional processes: The case of anger superiority effect ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090106', '$': '2009-01-06'}}}}"
10.1016/j.cognition.2008.11.010,Development of infants’ attention to faces during the first year ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081227', '$': '2008-12-27'}}}}"
10.1016/j.cognition.2008.11.011,Articulatory mediation of speech perception: A causal analysis of multi-modal imaging data ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081224', '$': '2008-12-24'}}}}"
10.1016/j.cognition.2008.11.012,Qualitative differences in the representation of abstract versus concrete words: Evidence from the visual-world paradigm ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20081224', '$': '2008-12-24'}}}}"
10.1016/j.cognition.2008.11.013,Connectionist semantic systematicity ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090109', '$': '2009-01-09'}}}}"
10.1016/j.cognition.2008.11.014,Flexible shaping: How learning in small steps helps ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090101', '$': '2009-01-01'}}}}"
10.1016/j.cognition.2008.11.015,When knowing can replace seeing in audiovisual integration of actions ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090101', '$': '2009-01-01'}}}}"
10.1016/j.cognition.2008.11.016,Beyond perceptual symbols: A call for representational pluralism ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090109', '$': '2009-01-09'}}}}"
10.1016/j.cognition.2008.11.017,A connectionist model of a continuous developmental transition in the balance scale task ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090126', '$': '2009-01-26'}}}}"
10.1016/j.cognition.2008.12.001,Orthographic vs. phonologic syllables in handwriting production ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090117', '$': '2009-01-17'}}}}"
10.1016/j.cognition.2008.12.002,Short-term action intentions overrule long-term semantic knowledge ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090223', '$': '2009-02-23'}}}}"
10.1016/j.cognition.2008.12.003,Retraction notice,"serial JL 271061 291210 291723 291726 291738 291743 291782 31 Cognition COGNITION 2009-01-03 2009-01-03 2010-04-18T13:36:08 1-s2.0-S001002770800293X S0010-0277(08)00293-X S001002770800293X 10.1016/j.cognition.2008.12.003 S300 S300.1 HEAD-AND-TAIL 1-s2.0-S0010027708X00125 2015-05-14T00:00:22.981292-04:00 0 0 20090101 20090131 2009 2009-01-03T00:00:00Z rawtext articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype volfirst volissue webpdf webpdfpagecount articletitle alllist content subj ssids 0010-0277 00100277 110 110 1 1 Volume 110, Issue 1 11 123 123 200901 January 2009 2009-01-01 2009-01-31 2009 Retraction simple-article ret Copyright © 2008 Published by Elsevier B.V. All rights reserved. RETRACTIONNOTICE item S0010-0277(08)00293-X S001002770800293X 1-s2.0-S001002770800293X 10.1016/j.cognition.2008.12.003 271061 2010-09-21T04:38:49.351934-04:00 2009-01-01 2009-01-31 1-s2.0-S001002770800293X-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800293X/MAIN/application/pdf/e00cd68e396c5d4953188647c4dfbaf8/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800293X/MAIN/application/pdf/e00cd68e396c5d4953188647c4dfbaf8/main.pdf main.pdf pdf true 98620 MAIN 1 1-s2.0-S001002770800293X-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S001002770800293X/PREVIEW/image/png/7b0ad0992f7fc61e96cf958a865f7816/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S001002770800293X/PREVIEW/image/png/7b0ad0992f7fc61e96cf958a865f7816/main_1.png main_1.png png 16448 849 656 IMAGE-WEB-PDF 1 Retraction notice Lozano, S. C., Hard, B. M., & Tversky, B. (2007). Putting action in perspective. Cognition, 103, 480–490. Lozano,S.C.,Hard,B.M.,&Tversky,B.(2008).Puttingmotor resonance in perspective. Cognition, 106, 1195–1220. All authors retract these two articles. Bridgette Martin Hard and Barbara Tversky believe that the research results cannot be relied upon; Sandra C. Lozano takes full respon- sibility for the need to retract these articles. Cognition 110 (2009) 123 Contents lists available at ScienceDirect Cognition journal homepage: www.elsevier.com/locate/COGNIT doi:10.1016/j.cognition.2008.12.003 COGNIT 1920 S0010-0277(08)00293-X 10.1016/j.cognition.2008.12.003 Retraction notice"
10.1016/j.cognition.2008.12.004,Recipient design in tacit communication ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090207', '$': '2009-02-07'}}}}"
10.1016/j.cognition.2008.12.005,Discourse-mediation of the mapping between language and the visual world: Eye movements and mental representation,"serial JL 271061 291210 291723 291726 291738 291743 291782 31 90 Cognition COGNITION 2009-02-03 2009-02-03 2014-11-18T16:43:20 1-s2.0-S0010027708002904 S0010-0277(08)00290-4 S0010027708002904 10.1016/j.cognition.2008.12.005 S300 S300.3 FULL-TEXT 1-s2.0-S0010027709X00041 2015-05-14T00:00:22.981292-04:00 0 0 20090401 20090430 2009 2009-02-03T00:00:00Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast footnotes primabst ref 0010-0277 00100277 UNLIMITED WT false 111 111 1 1 Volume 111, Issue 1 5 55 71 55 71 200904 April 2009 2009-04-01 2009-04-30 2009 Regular Papers article fla Copyright © 2008 Elsevier B.V. DISCOURSEMEDIATIONMAPPINGBETWEENLANGUAGEVISUALWORLDEYEMOVEMENTSMENTALREPRESENTATION ALTMANN G 1 Introduction 2 Experiment 1 2.1 Method 2.1.1 Subjects 2.1.2 Stimuli 2.1.3 Procedure 2.2 Results 2.3 Discussion 3 Experiment 2 3.1 Method 3.1.1 Subjects 3.1.2 Stimuli 3.1.3 Procedure 3.2 Results 3.3 Discussion 4 General discussion Acknowledgments Appendix 1 References ALLOPENNA 1998 419 439 P ALTMANN 2004 79 87 G ALTMANN 1999 247 264 G ALTMANN 2004 347 386 G INTEGRATIONLANGUAGEVISIONACTIONEYEMOVEMENTSVISUALWORLD NOWSEENOWDONTMEDIATINGMAPPINGBETWEENLANGUAGEVISUALWORLD ALTMANN 2007 502 518 G BALLARD 1997 723 767 D BARSALOU 2003 84 91 L CHAMBERS 2004 687 696 C CLEMENTS 1994 377 395 W COOPER 1974 84 107 R DAHAN 2001 507 534 D DOWTY 1979 D WORDMEANINGMONTAGUEGRAMMAR FERREIRA 2002 11 15 F GIBSON 1977 J PERCEIVINGACTINGKNOWING THEORYAFFORDANCES HENDERSON 2004 1 58 J INTERFACELANGUAGEVISIONACTION SCENEPERCEPTIONFORPSYCHOLINGUISTS HOMMEL 2001 849 937 B HOOVER 2008 533 542 M HUETTIG 2005 23 32 F JOHNSONLAIRD 1983 P MENTALMODELSTOWARDSACOGNITIVESCIENCELANGUAGEINFERENCECONSCIOUSNESS KAMIDE 2003 133 159 Y KNOEFERLE 2006 481 529 P KNOEFERLE 2007 519 543 P KNOEFERLE 2005 95 127 P MANDLER 1986 309 320 J MCRAE 1997 137 176 K OREGAN 1992 461 488 J RICHARDSON 2000 269 295 D SCHEEPERS 2003 179 205 C SPIVEY 2004 M INTERFACELANGUAGEVISIONACTIONEYEMOVEMENTSVISUALWORLD THINKINGOUTSIDEBRAINSPATIALINDICESVISUALLINGUISTICINFORMATION STEEDMAN 2002 723 753 M TANENHAUS 1995 1632 1634 M VANDIJK 1983 T STRATEGIESINDISCOURSECOMPREHENSION WIMMER 1983 103 128 H ZAITCHIK 1990 41 68 D ZWAAN 1995 292 297 R ZWAAN 1998 162 185 R ALTMANNX2009X55 ALTMANNX2009X55X71 ALTMANNX2009X55XG ALTMANNX2009X55X71XG Full 2013-07-16T19:12:22Z http://creativecommons.org/licenses/by/3.0/ item S0010-0277(08)00290-4 S0010027708002904 1-s2.0-S0010027708002904 10.1016/j.cognition.2008.12.005 271061 2014-11-19T13:02:25.473578-05:00 2009-04-01 2009-04-30 UNLIMITED WT 1-s2.0-S0010027708002904-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/MAIN/application/pdf/d89c18631b872eec732211ae9217c4d9/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/MAIN/application/pdf/d89c18631b872eec732211ae9217c4d9/main.pdf main.pdf pdf true 1067274 MAIN 17 1-s2.0-S0010027708002904-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/PREVIEW/image/png/2e03e826a42b0ff76d77695eab88d765/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/PREVIEW/image/png/2e03e826a42b0ff76d77695eab88d765/main_1.png main_1.png png 53447 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0010027708002904-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/STRIPIN/image/gif/4e54eaa671143e68dc9e0beda8405af9/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/STRIPIN/image/gif/4e54eaa671143e68dc9e0beda8405af9/si2.gif si4 si4.gif gif 183 11 11 ALTIMG 1-s2.0-S0010027708002904-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/STRIPIN/image/gif/4e54eaa671143e68dc9e0beda8405af9/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/STRIPIN/image/gif/4e54eaa671143e68dc9e0beda8405af9/si2.gif si3 si3.gif gif 183 11 11 ALTIMG 1-s2.0-S0010027708002904-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/STRIPIN/image/gif/4e54eaa671143e68dc9e0beda8405af9/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/STRIPIN/image/gif/4e54eaa671143e68dc9e0beda8405af9/si2.gif si2 si2.gif gif 183 11 11 ALTIMG 1-s2.0-S0010027708002904-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/STRIPIN/image/gif/4e54eaa671143e68dc9e0beda8405af9/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/STRIPIN/image/gif/4e54eaa671143e68dc9e0beda8405af9/si2.gif si1 si1.gif gif 183 11 11 ALTIMG 1-s2.0-S0010027708002904-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/gr4/DOWNSAMPLED/image/jpeg/83d9bdf7fb2ba3a3d2366e0f11370bde/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/gr4/DOWNSAMPLED/image/jpeg/83d9bdf7fb2ba3a3d2366e0f11370bde/gr4.jpg gr4 gr4.jpg jpg 104337 680 689 IMAGE-DOWNSAMPLED 1-s2.0-S0010027708002904-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/gr3/DOWNSAMPLED/image/jpeg/5cebe004b5c574f9d6fa6d0cfce93dfa/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/gr3/DOWNSAMPLED/image/jpeg/5cebe004b5c574f9d6fa6d0cfce93dfa/gr3.jpg gr3 gr3.jpg jpg 99333 383 512 IMAGE-DOWNSAMPLED 1-s2.0-S0010027708002904-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/gr2/DOWNSAMPLED/image/jpeg/4d448b736f78e4fd9488e495536fdb4e/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/gr2/DOWNSAMPLED/image/jpeg/4d448b736f78e4fd9488e495536fdb4e/gr2.jpg gr2 gr2.jpg jpg 63712 329 690 IMAGE-DOWNSAMPLED 1-s2.0-S0010027708002904-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/gr1/DOWNSAMPLED/image/jpeg/0b14cd7a3bd80d2ad65e9b7971bf259d/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/gr1/DOWNSAMPLED/image/jpeg/0b14cd7a3bd80d2ad65e9b7971bf259d/gr1.jpg gr1 gr1.jpg jpg 108650 384 511 IMAGE-DOWNSAMPLED 1-s2.0-S0010027708002904-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/gr4/THUMBNAIL/image/gif/47e7d5826638d88f6c475e39c74b9a38/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/gr4/THUMBNAIL/image/gif/47e7d5826638d88f6c475e39c74b9a38/gr4.sml gr4 gr4.sml sml 6570 164 166 IMAGE-THUMBNAIL 1-s2.0-S0010027708002904-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/gr3/THUMBNAIL/image/gif/a3ba84a6576da73420486a24f4462a7d/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/gr3/THUMBNAIL/image/gif/a3ba84a6576da73420486a24f4462a7d/gr3.sml gr3 gr3.sml sml 14629 164 219 IMAGE-THUMBNAIL 1-s2.0-S0010027708002904-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/gr2/THUMBNAIL/image/gif/b555778778b55ab6e0d6274f602ce68c/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/gr2/THUMBNAIL/image/gif/b555778778b55ab6e0d6274f602ce68c/gr2.sml gr2 gr2.sml sml 6093 104 219 IMAGE-THUMBNAIL 1-s2.0-S0010027708002904-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027708002904/gr1/THUMBNAIL/image/gif/629c52573c0f067c8724523c4286839c/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027708002904/gr1/THUMBNAIL/image/gif/629c52573c0f067c8724523c4286839c/gr1.sml gr1 gr1.sml sml 16424 164 218 IMAGE-THUMBNAIL COGNIT 1917 S0010-0277(08)00290-4 10.1016/j.cognition.2008.12.005 Elsevier B.V. Fig. 1 Example scene from Experiments 1 and 2. See the main text for the accompanying sentential stimuli. Fig. 2 Percentage of trials in Experiment 1 with fixations on the regions of interest corresponding to the table and the glass in the ‘moved’ and ‘unmoved’ conditions during ‘she will pick up the bottle and pour the wine carefully into the glass’ or its equivalent across trials. The percentages reflect the proportion of trials on which each of the regions of interest was fixated at each moment in time, and were calculated at each successive 25ms from the synchronization point. See the main text for a description of the resynchronization process. The region of the graph corresponding to the target noun phrase ‘the glass’ is highlighted. Fig. 3 Example regions of interest, shown in black, for Experiment 2 superimposed over an example scene. Fig. 4 Percentage of trials in Experiment 2 with fixations on the regions of interest corresponding to where the table, glass, or distractor had been during ‘she will pick up the bottle and pour the wine carefully into the glass’ or its equivalent across trials. The percentages were calculated as for Experiment 1. Panel A shows the data from the ‘moved’ condition; Panel B shows the ‘unmoved’ data. Table 1 Probabilities in Experiment 1 of fixating on, or launching saccades towards, the spatial regions occupied by the table or by the glass, calculated at the onset of the postverbal region (fixation analysis), during the postverbal region (saccadic analysis), during the sentence-final noun phrase (saccadic analysis), and at the offset of that noun phrase (fixation analysis). Numbers in parentheses indicate absolute number of trials on which a fixation on, or saccade to, each region was observed. For the saccadic analyses, the probabilities can sum to more than one because the eyes could saccade to more than one region in the available time. Equally, they can sum to less than one if no saccade was made during the interval of interest. Where the fixation probabilities sum to less than one, trials were lost through blinks, looks beyond the screen, or other failures to track the eye. Analysis point/window …pour ∧ the wine carefully into the glass …pour the wine carefully into the glass (1246ms) …pour the wine carefully into the glass (541ms) …pour the wine carefully into the glass ∧ Analysis type p(fixation) p(saccade) p(saccade) p(fixation) Condition Unmoved Moved Unmoved Moved Unmoved Moved Unmoved Moved Table .04 (11) .08 (21) .13 (34) .29 (73) .06 (15) .16 (40) .04 (10) .13 (32) Glass .11(29) .11 (28) .48 (123) .44 (112) .29 (74) .25 (65) .34 (88) .27 (70) Elsewhere .74 (190) .69 (176) .79 (201) .78 (200) .50 (127) .49 (125) .47 (121) .48 (122) Table 2 Probabilities in Experiment 2 of fixating on, or launching saccades towards, the spatial regions corresponding to where the table, the glass, or the distractor had been, calculated at the onset of the postverbal region (fixation analysis), during the postverbal region (saccadic analysis), during the sentence-final noun phrase (saccadic analysis), and at the offset of that noun phrase (fixation analysis). Numbers in parentheses indicate absolute number of trials on which a fixation on, or saccade to, each region was observed. For each scene, the regions of interest corresponding to where the table, glass, or distractor had been were identically sized. Analysis point/window …pour ∧ the wine carefully into the glass …pour the wine carefully into the glass (1246ms) …pour the wine carefully into the glass (541ms) …pour the wine carefully into the glass ∧ Analysis type p(fixation) p(saccade) p(saccade) p(fixation) Condition Unmoved Moved Unmoved Moved Unmoved Moved Unmoved Moved Table .06 (17) .06 (15) .07 (19) .13 (36) .02 (6) .12 (32) .07 (19) .17 (46) Glass .08 (22) .06 (15) .14 (39) .07 (20) .10 (28) .03 (8) .14 (37) .04 (11) Distractor .06 (15) .04 (11) .05 (14) .03 (9) .02 (6) .02 (6) .06 (16) .04 (10) Elsewhere .61 (166) .68 (185) .27 (73) .24 (64) .13 (34) .15 (40) .56 (153) .58 (157) Discourse-mediation of the mapping between language and the visual world: Eye movements and mental representation Gerry T.M. Altmann a ⁎ g.altmann@psych.york.ac.uk Yuki Kamide b a Department of Psychology, University of York, Heslington, York YO10 5DD, UK b School of Psychology, University of Dundee, UK ⁎ Corresponding author. Tel.: +44 (0)1904 434362; fax: +44 (0)1904 433181. Abstract Two experiments explored the mapping between language and mental representations of visual scenes. In both experiments, participants viewed, for example, a scene depicting a woman, a wine glass and bottle on the floor, an empty table, and various other objects. In Experiment 1, participants concurrently heard either ‘The woman will put the glass on the table’ or ‘The woman is too lazy to put the glass on the table’. Subsequently, with the scene unchanged, participants heard that the woman ‘will pick up the bottle, and pour the wine carefully into the glass.’ Experiment 2 was identical except that the scene was removed before the onset of the spoken language. In both cases, eye movements after ‘pour’ (anticipating the glass) and at ‘glass’ reflected the language-determined position of the glass, as either on the floor, or moved onto the table, even though the concurrent (Experiment 1) or prior (Experiment 2) scene showed the glass in its unmoved position on the floor. Language-mediated eye movements thus reflect the real-time mapping of language onto dynamically updateable event-based representations of concurrently or previously seen objects (and their locations). Keywords Sentence comprehension Eye movements Visual scene interpretation Situation models 1 Introduction Increasing attention has focused in recent years on language-mediated eye movements and the ‘visual world’ paradigm (Cooper, 1974; Tanenhaus, Spivey-Knowlton, Eberhard, & Sedivy, 1995). Language-mediated eye movements are commonly taken to reflect the cognitive processes that underpin the real-time processing of language, and the mapping of that language onto a concurrent visual world. Various studies have now shown the sensitivity of language-mediated eye movements to factors implicated in a wide range of phenomena associated with language comprehension (for reviews, see Henderson & Ferreira, 2004, and Journal of Memory and Language, Vol. 57). Typically, such studies measure eye movements around static scenes; for example, monitoring the likelihood with which certain objects depicted within the scene are fixated as a word or sentence unfolds. Recently, Hoover and Richardson (2008) and Knoeferle and Crocker (2007) explored the mapping of eye movements onto events depicted across either dynamically changing animations or multiple frames. In these studies, the eye movements of interest were towards a static, unchanging, scene that followed the animation or the multiple frames. Both studies showed that language-mediated eye movements reflect the mapping from language onto dynamically updateable mental representations of the visual ‘situation’, as distinct from the mapping of language onto static representations of the concurrent visual scene. But whereas these two studies were based on updating of the situation on the basis of spatiotemporal information afforded by the animations or multiple frames, the studies we report below show such updating on the basis of linguistic information alone. Moreover, we show (in Experiment 2) that such updating can occur, and more significantly, can drive eye movements, even when the visual scene has been removed prior to the onset of that linguistic information. These data will allow us to make a distinction between the representations of objects as depicted within a (concurrent or previous) visual scene and the representations of objects (and their locations) as maintained within the unfolding conceptual correlates of the event which the unfolding language describes. Events have internal complexity, entailing, at a minimum, an initial state and an end state (with one or more participants in the event undergoing some change between the initial and end states); cf. Dowty (1979). Sentence comprehension in the context of a concurrent (but static) visual scene requires the comprehender to determine whether the scene corresponds to the initial state, the end state, or some intermediate state in the event described by the unfolding language (cf. Altmann & Kamide, 2007); thus, and notwithstanding the static nature of the concurrent visual depiction of the participants, it also requires the comprehender to keep track of changes to the participants in the event as the event, as described by the language, unfolds. Our interest here is in respect of the consequences for the cognitive mechanisms that might instantiate event representations, and the manifestation of these consequences on language-mediated eye movements, of the need to keep track of multiple representations of the same participant, albeit at different stages of the event. We shall argue below that these dynamically changing mental representations of the participants can, in certain circumstances, compete with their visually depicted counterparts. The goal of much work within the visual world paradigm has been to investigate how (and when) the language that we hear makes contact with the world that we see. The evidence to date suggests that certain aspects of the language make contact with the visual world at the theoretically earliest opportunity. Work by Allopenna, Magnuson, and Tanenhaus (1998) and by Dahan and colleagues (e.g. Dahan, Magnuson, Tanenhaus, & Hogan, 2001) has shown how acoustic mismatch mediates looks towards potential referents at the earliest moments. Kamide, Altmann, and Haywood (2003) showed in addition how multiple information sources conspire to drive the eyes towards particular objects as soon as that information becomes available to the comprehender. They presented participants with a visual scene depicting a man, a child (a girl), a motorbike, a fairground carousel and various other objects. Concurrently, participants heard either ‘The man will ride the motorbike’ or ‘The girl will ride the carousel’. It was more plausible for the man to ride the motorbike than the carousel, and for the child to ride the carousel than the motorbike. During the acoustic lifetime of ‘ride’, more anticipatory looks were directed towards the motorbike when the subject was ‘the man’ than when it was ‘the child’. Conversely, more looks were directed towards the carousel during ‘ride’ after ‘the child’ than after ‘the man’. This result demonstrates that the eyes were directed towards distinct objects in the scene, during the acoustic lifetime of the verb, on the basis of the rapid integration of the meaning of the verb ‘ride’, the meaning of its grammatical subject (‘the man’ or ‘the child’), and the plausibility of the denoted event given the objects in the concurrent visual scene (that is, who, given the scene, would do the riding, and what, given that same scene, would most plausibly be ridden). Kamide et al. (2003) suggested that their data are the hallmark of an incremental language processor that attempts at each moment in time to construct the fullest possible interpretation of the linguistic input (a claim that needs to be moderated to take account of goal-related factors that may lead to less than the fullest possible interpretation – cf. Ferreira, Ferraro, & Bailey, 2002). Importantly, language-mediated eye movements do not reflect only the workings of the language system. They reflect also the workings of whichever parts of the cognitive system interpret the external world. Indeed, Kamide et al. (2003) pointed out that their data were compatible with a hypothesis in which the assignment of thematic roles to objects in the visual world was as much driven by processes operating in the linguistic domain as by processes operating in the visual domain (see also Altmann & Kamide, 2004). They proposed that processes that are not language-specific, but which draw on experiential knowledge of objects and their interactions (i.e. affordances), establish thematic relations between objects in the scene, both in relation to each other and in relation to the thematic roles which the unfolding language may make available (cf. Chambers, Tanenhaus, & Magnuson, 2004; Knoeferle & Crocker, 2006; Knoeferle, Crocker, Scheepers, & Pickering, 2005). This view, that ‘situated’ sentence interpretation draws on domain-independent processes operating over experiential and situational knowledge, is little different to that expressed by Zwaan and Radvansky (1998), who review a range of studies suggesting that modality-independent processes are used to construct situation models during reading, listening, and viewing. In the studies we report below, we consider how the construction and dynamic modification of such situation models impacts on language-mediated eye movements; we show how discourse context can, by dynamically changing the situation, change aspects of the mental representations of the objects depicted within a concurrent but unchanging scene (in fact, those aspects to do with the distinct locations that an object moves through as the situation/event unfolds); we show that such changes mediate subsequent eye movements towards the scene as the language unfolds. Thus, we shall demonstrate how language is mapped not onto static representations of the (static) scene, but rather onto dynamically changing (and changeable) representations of that scene. Our starting point for this work can be exemplified by the following: ‘Paul will take the watch off his wrist, and place it around Jeanne’s wrist’. Our mental representation of the events denoted by this sentence include the initial state (the watch on the wrist), intermediate states (entailed by the action associated with taking off the watch), and the end state (the watch on Jeanne’s wrist). Each of these states must be encoded with respect to some internalized time line (without which the causal relationships between these states and the events denoted by the sentence would not be apparent). If this sentence were to be followed by ‘She will admire the watch for a moment, before removing it’ we would interpret ‘the watch’ to mean the watch after it has been taken off Paul’s wrist and placed on her own wrist. On the other hand, the first mention of the watch in ‘Paul will take the watch off his wrist’ is taken to refer to the watch on his wrist. So what are the consequences, for our interpretation of the final token of ‘the watch’, if Paul is standing before us with his wristwatch plainly in view, on his wrist, and as yet unmoved? How, if at all, does the cognitive system keep apart the representation of the concurrent watch (on Paul’s wrist) and the representation of this same watch at some distinct time (in the future) and location (on Jeanne’s wrist)? Presumably, the processing system uses information about, in this case, the tense of the sentence to indicate a future timeframe, and on this basis the representations can be referred to with little confusion. We have elsewhere established that tense information is indeed used, as a sentence unfolds in real-time, to constrain which representations are being referred to (Altmann & Kamide, 2007; cf. Knoeferle & Crocker, 2007). The experiments below attempt instead to establish the attentional consequences of referring to something that is co-present in the visual world but which is referred to in the context of some future change in location of that object. In effect, we ask here what happens when people see Paul and the watch upon his wrist, and Jeanne (watchless), and hear the sequence above (about Paul taking off his watch and placing it around Jeanne’s wrist) and hear mention of the watch – if hearing mention of the watch when it refers to the watch on his wrist causes the eyes to move towards his wrist as the word ‘watch’ unfolds (cf. Allopenna et al., 1998; Cooper, 1974), where will the eyes move when ‘the watch’ refers to that ‘version’ of the same watch when it is on Jeanne’s wrist? Will they look towards the ‘original’ (and co-present) watch, or to the location of this future version of the watch (i.e. her wrist)? On the assumption that the representation of the watch as encoded from the language (i.e. the watch that is no longer on Paul’s wrist) contains information pertaining to the watch’s new location (i.e. as being on Jeanne’s wrist), can this information mediate visual attention during subsequent reference to the watch? 2 Experiment 1 The purpose of this study was to determine whether eye movements are mediated by the content of a concurrent visual scene, or by the content of mental representations that have an existence that is, at least in part, dissociable from the perceptual correlates of the objects in that scene. We manipulated the mental representations by presenting a contextualizing sentence which described how one of the objects in the concurrent scene was going to be moved by a protagonist (also depicted in the scene) to a new location. For example, the scene shown in Fig. 1 depicts, amongst other things, a woman, an empty wine glass, and a table. Immediately prior to a target sentence that referred to the woman pouring the wine into the glass, we presented first either ‘The woman will put the glass on the table’ or ‘The woman is too lazy to put the glass onto the table’. Both the context sentence and the subsequent target sentence were presented concurrently with the visual scene, but the first of the two alternative context sentences changed the mental location of the glass from the floor to the table. The second of the two alternatives left the location unchanged. In this study, we shall ask two questions of the data: First, where do participants’ eyes move as they anticipate the most plausible location of the pouring? Kamide et al. (2003); Experiment 1 observed anticipatory eye movements towards the most plausible goal object following a ditransitive verb such as ‘pour’ (i.e. towards the receptacle) during the post verbal region of the sentence. We shall take advantage of this phenomenon to establish where the interpretive systems assumes that goal object to be – will the eyes move more towards the table in the ‘moved’ condition than in the ‘unmoved’ (‘too lazy’) condition? Or will they move towards the glass irrespective of the prior context? Second, we shall ask where will participants’ eyes be looking after they have heard ‘glass’ in the target fragment ‘she will pick up the bottle and pour the wine carefully into the glass’ – will looks at the physical location of the glass be unaffected by the prior context? Or might its ‘mental location’, as determined by the prior context, determine the likelihood of looking at the glass or table? 2.1 Method 2.1.1 Subjects Thirty-two participants from the University of York student community took part in this study. They participated either for course credit or for £2.00. All were native speakers of English and either had uncorrected vision or wore soft contact lenses or spectacles. 2.1.2 Stimuli Sixteen experimental pictures (see Fig. 1) were paired with two sentential conditions corresponding to (1) and (2) below. (1) The woman will put the glass onto the table. Then, she will pick up the bottle, and pour the wine carefully into the glass. (2) The woman is too lazy to put the glass onto the table. Instead, she will pick up the bottle, and pour the wine carefully into the glass. The first sentence in each condition always referred to the agent, the theme, and the goal; the two conditions were designed to be minimally different. See Appendix 1. The visual scenes were created using commercially available ClipArt packages, and were constructed using a 16-colour palette. The scenes corresponding to each experimental item are described in Appendix 1. They were presented on a 17” viewing monitor at a resolution of 640×480pixels. The same target sentence was used across both context conditions. A further 32 sentence/scene pairs were added as fillers. These employed similar pictures to the experimental items but included a range of other sentence types. The materials were arranged in a fixed-random order so that no successive items belonged to the same condition. Two lists of stimuli were created containing each of the 16 experimental pictures but just one version of each sentence pair. The sentences were recorded by a male native speaker of British English (GTMA), and sampled at 44.1KHz. The sound files were presented to participants via a mono channel split to two loudspeakers positioned either side of the viewing monitor. The onsets and/or offsets of critical words in the stimulus sentences were marked using a sound editing package for later analysis. 2.1.3 Procedure Participants were seated in front of a 17” display with their eyes approximately 60cm. from the display. They wore an SMI EyeLink head-mounted eye-tracker, sampling at 250Hz from the right eye (viewing was binocular). Participants were told that they would be shown some pictures that would be accompanied by a short sentence spoken over loudspeakers. In respect of their task, participants were simply told that ‘we are interested in what happens when people look at these pictures while listening to sentences that describe something that might happen in the picture’ (see Altmann, 2004 for discussion of the task). Between each trial, participants were shown a single centrally-located dot to allow for any drift in the eye-track calibration to be corrected. This dot was then replaced by a fixation cross and participants would press a response button for the next trial. The onset of the visual stimulus preceded the onset of the spoken stimulus by 1000ms. The trial was automatically terminated after 10 or 12s, depending on the length of the auditory stimulus. After every fourth trial, the eye-tracker was recalibrated using a 9-point fixation stimulus. Calibration took approximately 20s. There were four practice trials before the main experimental block. The entire experiment lasted approximately 25m. 2.2 Results Eye movements that landed more than one or two pixels beyond the boundaries of the target object were not counted as fixations on that object. As in previous studies (e.g. Altmann & Kamide, 2007) we make no claims here regarding either the resolution of the eye tracker or the accuracy of eye movements. We adopt this criterion simply to avoid having to make a potentially arbitrary decision regarding how far a fixation can land from an object but still be deemed to have been directed towards that object. We report in Table 1 four eye movement measures synchronized on a trial-by-trial basis with the target sentence. For the sake of exposition, we shall refer to the target with the example ‘she will pick up the bottle, and pour the wine carefully into the glass’. The first measure we report is the probability of fixating the glass or the table at the onset of ‘the wine’ (i.e. at the onset of the determiner). At this point in the sentence, we do not anticipate any bias to look towards one or other object (participants at this stage are most likely anticipating the theme, not the goal – Kamide et al., 2003, observed anticipatory eye movements in equivalent ditransitive constructions towards the glass during ‘the wine’, but not before). The second measure is the probability of launching at least one eye movement towards the glass or table during the underlined portion of ‘she will pick up the bottle, and pour the wine carefully into the glass’ (i.e. in the region between the onset of the postverbal determiner and the onset of the final determiner). We report also the probability of launching at least one eye movement towards the glass or table during the final noun phrase ‘the glass’ and, finally, the probability of fixating the glass or table at the offset of ‘glass’. We include these last three measures in order to establish, first, where participants looked when anticipating the goal location of the pouring (cf. Altmann & Kamide, 1999; Kamide et al., 2003), and second, where participants were looking once they knew, on the basis of the acoustic input, that the glass was indeed the intended goal of the pouring. Probabilities were calculated by summing, for saccades, the number of trials in which at least one saccadic eye movement was directed towards the target during the critical region, or for fixations, the number of trials in which the target was fixated at the onset of the critical word. In each case, we took into account on a trial-by-trial basis the actual onsets/offsets of the critical words in the auditory stimulus. Statistical analyses were performed using hierarchical log-linear models. Log-linear models are appropriate in the analysis of frequency or probability data, which are necessarily bounded. The equivalent of planned comparisons were computed by establishing an interaction (or lack thereof) between condition (‘moved’ vs. ‘unmoved’) and object (e.g. the table vs. all other objects, or the glass vs. all other objects). This analysis allows us to take into account the necessary dependency on each trial between looks to one object and looks to all others. If an effect of context is found on both the table and the glass, we need then to establish whether these effects are carried solely by the table and the glass (i.e. looks towards the table being at the expense of looks towards the glass, and vice versa), or whether they might be carried by (unexplained) looks elsewhere in the scene. To do this, we contrast looks towards the table and the glass (taken together) with looks elsewhere. Failing to find an interaction between condition (‘moved’ vs. ‘unmoved’) and object (the table and the glass vs. the rest of the scene) would establish that the number of looks towards the table and the glass, taken together, were constant across condition, meaning in turn that the effects of context on the glass were complementary to the effects of context on the table (see Altmann & Kamide, 2007, for discussion of this logic). Participants and items were entered, separately, as factors in the computation of partial association Likelihood Ratio Chi-Squares (LRCS1 and LRCS2, respectively) in order to assess the generalizability of the effects across participants and items. 1 A significant 2-way interaction between condition and object in the LRCS1 and LRCS2 analyses would indicate generalizability across participants and items respectively. In addition, the lack of a 3-way interaction (condition×object×participants/items) would indicate consistency in the magnitude of the effect of condition across participants or items. For ease of exposition, we describe an effect as ‘more looks towards A in condition X than in condition Y’ when we are in fact referring to the interaction between condition (X vs. Y) and object (A vs. B), and we describe an effect as ‘consistent’ by participants or items when we are in fact referring to the 3-way interaction with either participants or items. We used SPSS Version 16 to analyse these data; within SPSS non-interaction effects (e.g. the absolute difference in looks towards A vs. looks towards B) do not yield different values of LRCS by participant or by item, although higher-order interactions with such effects (as would be tested in order to determine consistency in the magnitude of the difference) do yield different values. The same is not true of other statistical packages (e.g. Statistica), which produce partial association main effect values of LRCS that may differ between participant and item analyses. The difference appears to be due to the ways in which these packages derive expected frequencies for main effects (Christoph Scheepers, pers. comm.) 1 For further discussion of the use of log-linear models in this experimental paradigm, see Altmann and Kamide (2007), Huettig and Altmann (2005), and Scheepers (2003). (i). At the onset of ‘the wine’: The probability of fixating the table was marginally greater in the ‘moved’ condition than in the ‘unmoved’ condition (LRCS1 =3.9, df=1, p =.049; LRCS2 =3.5, df=1, p =.062), consistent by participants and by items (LRCS1 =22.9, df=31, p >.8; LRCS2 =19.6, df=15, p >.1). The probability of fixating the glass did not vary by condition (LRCS1 =0, df=1, p =1; LRCS2 =0.02, df=1, p >.8), consistent by participants and by items (LRCS1 =35.6, df=31, p >.2; LRCS2 =16.7, df=15, p >.3). Overall, the glass was fixated significantly more often than the table (LRCS = 7.1, df = 1, p < .01), consistent by participants and by items (LRCS1 = 23.1, df = 31, p > .8; LRCS2 = 14.4, df = 15, p > .4). (ii). During ‘the wine carefully into’: The probability of launching an anticipatory eye movement towards the table was significantly higher in the ‘moved’ condition than in the ‘unmoved’ condition (LRCS1 =15.9, df=1, p <.001; LRCS2 =13.5, df=1, p <.001), consistent by participants and by items (LRCS1 =30.9, df=31, p >.4; LRCS2 =14.7, df=15, p >.4). The probability of launching an eye movement towards the glass did not differ, statistically, between the two conditions (LRCS1 =1.8, df=1, p >.1; LRCS2 =2.2, df=1, p >.1), consistent by participants and by items (LRCS1 =17.9, df=31, p >.9; LRCS2 =14.6, df=15, p >.4). Saccades were launched more often towards the glass than towards the table (LRCS=49.1, df=1, p <.001), consistent by participants and by items (LRCS1 =31.6, df=31, p >.4; LRCS2 =14.3, df=15, p >.5). (iii). During ‘the glass’: The probability of launching an eye movement towards the table was significantly higher in the ‘moved’ condition than in the ‘unmoved’ condition (LRCS1 =12.2, df=1, p <.001; LRCS2 =13.0, df=1, p <.001), consistent by participants and by items (LRCS1 =31.6, df=31, p >.4; LRCS2 =21.8, df=15, p >.1). The probability of launching an eye movement towards the glass did not differ, statistically, between the two conditions (LRCS1 =1.6, df=1, p >.2; LRCS2 =1.7, df=1, p >.1), consistent by participants and by items (LRCS1 =26.5, df=31, p >.6; LRCS2 =12.0, df=15, p >.6). Saccades were again launched more often towards the glass than towards the table (LRCS=37.6, df=1, p <.001), consistent by participants and by items (LRCS1 =23.3, df=31, p >.8; LRCS2 =23.4, df=15, p >.07). (iv). At the offset of ‘the glass’: the table was fixated more at this point in time in the ‘moved’ condition than in the ‘unmoved’ condition (LRCS1 =14.3, df=1, p <.001; LRCS2 =13.0, df=1, p <.001), consistent by participants and by items (LRCS1 =33.8, df=31, p >.3; LRCS2 =17.4, df=15, p >.2). And conversely, the glass was fixated more in the ‘unmoved’ condition than in the ‘moved’ condition, although the effect just failed to meet statistical significance in the by-items analysis (LRCS1 =4.8, df=1, p <.03; LRCS2 =3.8, df=1, p =.051), consistent by participants and by items (LRCS1 =31.8, df=31, p >.4; LRCS2 =19.6, df=15, p >.1). To the extent that there were effects of context on both fixations on the table and fixations on the glass, these effects were complementary – that is, increased fixations on the table were at the expense of decreased fixations on the glass, and vice versa (there was no effect of context on proportions of looks to non-critical regions (see above for the rationale for this analysis): LRCS1 =0.03, df=1, p >.8; LRCS2 =0.08, df=1, p >.7). This was consistent by items (LRCS2 =20.3, df=15, p >.1), but was not consistent by participants (LRCS1 =51.4, df=31, p <.02), meaning that the magnitude of the context×object (glass/table vs. distractors) interaction varied across participants (most likely, this should be interpreted as meaning that for some participants, the increased fixations on the table in the ‘moved’ condition were accompanied not only by decreased fixations on the glass, but also by decreased fixations on other regions of the scene; this increase in fixations on the table was overall slightly larger than the corresponding decrease in fixations on the glass and could not therefore be entirely accounted for by decreased fixations on the glass). There were, overall, more fixations on the glass than on the table (LRCS=71.7, df=1, p <.001), Saccades were launched more often towards the glass than towards the table (LRCS=37.6, df=1, p <.001), consistent by participants and by items (LRCS1 =27.7, df=31, p >.6; LRCS2 =17.6, df=15, p >.2). In Fig. 2 , we plot the percentage of trials with fixations on each of the two regions of interest (the table and the glass), in 25ms. increments from the onset of, and during, ‘the wine carefully into the glass’. As noted in Altmann and Kamide (2004), there is an inherent problem in interpreting such plots; for example, ‘zeroing’ time at the onset of ‘the wine carefully into the glass’ results in a mean onset of ‘the glass’ at 1246ms. However, this is just the average across stimuli (and hence, across trials), with a minimum onset at 1014ms. and a maximum onset at 1510ms. This renders the interpretation of such plots problematic; the further into the sentence fragment, the greater this degree of desynchronization between the unfolding speech and the unfolding eye movement plot. In order to avoid this cumulative desynchronization, the curves in Fig. 2 (and Fig. 4 , below) are resynchronized at each of the points shown by the vertical lines (in effect, separate curves are calculated for each interval of interest, and ‘stitched’ together). Thus, instead of just one synchronization point at the onset of the sentence fragment, there are seven synchronization points (including fragment onset and fragment offset). This guarantees that the intersection between each curve and each vertical synchronization line accurately reflects the probability of fixation at the corresponding moments in time across all trials. Hence multiple zeros on the x-axis of each plot. A further problem with such plots, also described in Altmann and Kamide (2004), is that fixation plots do not accurately reflect the moment-by-moment shifts in overt attention that are accompanied by saccadic eye movements. Fixations and saccades can dissociate; a period of time in which the likelihood of fixation on a region is constant may also be a period of time in which the likelihood of a saccadic movement to that region rises (and conversely, saccadic movements out of that region also rise). This dissociation is task-dependent, and is less apparent for example in reaching tasks where the eye will tend to maintain fixation on the to-be-reached target. In the ‘look and listen’ task we employ here, the dissociation between fixations and saccades is more apparent; hence our reporting, and statistical analyses, across both fixational and saccadic measures. The graph in Fig. 2 (and Fig. 4 below) is thus provided for illustrative purposes only, with the data in Table 1 (and 2 below) reflecting more directly the statistical analyses of these two measures, and indeed, reflecting more directly shifts in overt attention towards the glass or the table. 2.3 Discussion Participants were more likely to look, postverbally, towards the table in the ‘moved’ condition than in the ‘unmoved’ condition. Indeed, at the one point in the sentence when participants could be absolutely certain that the glass was the object under consideration, namely at the offset of the sentence-final ‘glass’, they ended up looking at the table or the glass as a function of the context; that is, as a function of where the glass was located in the contextually determined mental representation of the scene and the objects it contained. It would appear, therefore, that language-mediated eye movements can be driven by the mapping of a sentence onto the contents of a dynamically updateable situational model in which the locations of the objects can be dynamically updated; eye movements were driven by the encoded locations of those objects, rather than just their actual locations as determined by the concurrent image. This conclusion is subject to two caveats, however. First, there was no effect of context on looks towards the glass until the final point in the sentence; thus, increased looks towards the table before this point were not at the expense of fewer looks towards the glass (and moreover, even at the final point in the sentence, some caution should be exercised in respect of the effect of context on fixations on the glass, given that this effect was not entirely reliable, statistically, in the by-items analysis; p =.051). Second (but possibly related – see below), notwithstanding the effect of context on looks towards the table, there was always a preference to look towards the glass (see Table 1 – this preference could not be an artefact of differences in size, across trials, between the region corresponding to the glass and that corresponding to the table: the former was generally smaller than the latter). Thus, although (some) eye movements were driven by the encoded location of the glass, as either on the floor or on the table, this is not the whole story: they were only partly driven by the encoded locations, and were driven more by the actual location of the glass in the image. So how, then, can we reconcile the reliable effects of context on looks towards the table, when anticipating the glass or hearing ‘the glass’, with the overall preference to look towards the depicted glass? One possibility is to take into account that participants had to keep track of multiple representational instantiations of the glass – the glass as depicted in the scene, and the glass as described by the unfolding language and which, at some future time, would be located on the table. 2 A version of Experiment 1 was run separately in which we contrasted, for the ‘moved’ condition alone, the tense of each sentence: In the ‘future’ condition, the sentences were as in Experiment 1, and in the ‘past’ condition they were changed to the past tense (e.g. ‘The woman put the glass onto the table. Then, she picked up the bottle, and poured the wine carefully into the glass.’) There was no effect of tense on looks towards either the glass or the table. As will become clear in the main text, the critical issue is not tense in these cases, but the requirement to maintain distinct representations of the state of the glass at different moments in event-time. Nonetheless, other studies have demonstrated that tense does have an important role with respect to interpreting the scene as depicting the initial or final state in the described event (Altmann & Kamide, 2007). 2 Evidently, we do keep track of such multiple representational instantiations; otherwise, how else could we say to someone how sober (or not) they looked the night before without confusing the person in the here-and-now with the person as they were in the there-and-then? Given this need to maintain multiple representations of the same object, indexed to different events and locations, it follows that in the two conditions of Experiment 1, there are multiple instantiations of the glass that must be kept apart: the glass depicted on the floor in the here-and-now, the glass filled at some later time with wine, and in the ‘moved’ condition, the glass located on the table at the time of the pouring of the wine. These distinct representations must be kept apart, and as such, may in fact compete. Thus, on hearing ‘the glass’ at the end of the final sentence in Experiment 1, the two different instantiations of the glass – one depicted concurrently in the scene, and the other referred to by the language – may each compete for attention. Given the salience of the currently depicted glass (given its concurrent physical/sensory correlates), we might suppose that it ‘wins out’ in respect of this competition, and hence the bias to look towards the concurrently depicted glass when anticipating the glass (even in the ‘moved’ condition). The fact that looks to the table were modulated by the context, and looks to the glass also (albeit manifesting only in fixations on the glass at the end of the sentence) suggests that the representational instantiation of the glass on the table did ‘attract’, or guide, looks to some extent, notwithstanding the preference for looks to be guided primarily by the depiction of the glass on the floor. In Experiment 2 we test this hypothesis by eliminating the concurrent glass from the scene, and thereby eliminating the competition between the stimulus-driven representation of that glass and the event-based representation of the glass as described by the unfolding language. We predict that by eliminating this competition, the overall bias to look towards the physical location of the glass will itself be eliminated. 3 Experiment 2 Experiment 2 is identical to Experiment 1 except that the scenes were removed before the onset of the spoken sentences. Altmann (2004) showed participants scenes depicting, for example, a man, a woman, a cake, and a newspaper. The scenes were removed after a few seconds, and shortly after, participants heard sentences such as ‘The man will eat the cake’ while the screen remained blank. It was found that the eyes nonetheless moved, during ‘eat’ in this example, towards where the cake had been (cf. Altmann & Kamide, 1999, who showed the equivalent effect when the scene and accompanying sentence were concurrent). The rationale for using this blank screen paradigm for Experiment 2 is as follows: once the scene has been removed, information about where the glass is located can be based on only two sources of information – the memory of where the glass had actually been located in the prior scene, and the event-representations constructed as the spoken sentences unfold. Both of these are internal representations that do not have any concurrent physical correlates (unlike the actually depicted glass in the scene; in that case, the internal representation corresponding to that glass does have concurrent physical correlates). Conceivably, the visual memory of where the glass had actually been located is a more salient representation of the location of the glass than the event-representations constructed through the language (it is grounded, after all, in prior physical correlates). However, if this visual memory constitutes a temporary record of the experience of the glass, including its location (cf. an ‘episodic trace’), then this memory (like the representations constructed by the unfolding language) is also event-based (cf. Hommel, Müsseler, Aschersleben, & Prinz, 2001; and affordance-based accounts of object representation; e.g. Gibson, 1977; see Steedman, 2002, for a formal treatment of affordances as event representations). If the representation corresponding to the visual memory of the glass is itself an event-based representation, then perhaps it is no more salient a representation than the event-based representations constructed through the language. Indeed, the latter must presumably act upon versions of the former (they cannot directly modify the episodic memory of the object or it would not be possible to keep apart the episodic memory from the language-cued event-representation that refers to the glass in an alternative location). Thus, the visual memory of where the glass had actually been located may be no more salient (i.e. may attract no more attention) than the language-induced representation of where it will be located (after the event described by the language has unfolded). Whether this is in fact the case is an empirical issue which Experiment 2 addresses, and we postpone further discussion of the relative saliency of these different representations until the discussion section below. Critically, our intention is to establish whether it was indeed the concurrent physical representation of the glass in Experiment 1 that caused the overall preference to look towards this glass even in the ‘moved’ condition. 3.1 Method 3.1.1 Subjects Thirty-four participants from the University of York student community took part in this study. They participated either for course credit or for £2.00. All were native speakers of English and either had uncorrected vision or wore soft contact lenses or spectacles. 3.1.2 Stimuli The visual and auditory stimuli were identical to those used in Experiment 1 except for the 24 fillers used in this study. These included stimuli for an unrelated blank screen study, but all the filler stimuli were similar in respect of the complexity of the scenes and associated sentence types). 3.1.3 Procedure The same procedure was employed as for Experiment 1 except that a 22” monitor was used and the scenes were presented for 5s before being replaced by a light grey screen. The onset of the auditory stimulus (corresponding to the context and target sentences) occurred 1s after the scene had been removed. Eye movements were monitored throughout using an EyeLink II head-mounted eye-tracker sampling at 250Hz, and the trial terminated 11s after the onset of the auditory stimulus. Thus, each trial lasted for 17s in total. 3.2 Results Whereas in Experiment 1 a fixation was deemed to have landed on an object if it fell on the pixels occupied by that object, we adopted a different scheme for defining regions of interest in this experiment. A rectangular box was drawn around either the location previously occupied by the glass or around the location to which it was ‘moved’ (in this case, a region encompassing the table top). The two rectangles, corresponding to where the glass or table top had been, were of identical size (although the size of these regions of interest varied on a trial-by-trial basis depending on the visual objects whose locations they indicated, but within each trial, the two regions of interest were identically sized). A third identically sized rectangle was placed at the location previously occupied by one of the distractor objects (e.g. the lower part of the bookshelf shown in Fig. 1). We included this region for the purpose of comparison with the other two regions (corresponding to where the glass or the table top had been), given that within the blank screen paradigm, comparison between different equally-sized regions can be made without the possibility that differences in looks might be due to differences in low-level visual salience (each region of interest is, after all, identical). Thus, any differences across condition can only be due to biases introduced by the mental representations constructed through the interplay between the unfolding language and the memory of what had previously occupied the scene. An example of these regions of interest, superimposed over the original image, is shown in Fig. 3 . We report in Table 2 and Fig. 4 the same eye movement measures as were reported for Experiment 1, although in the present experiment, eye movements during the unfolding sentence were directed towards empty space. Of interest is which empty space the eyes were directed towards. (i). At the onset of ‘the wine’: The probability of fixating where the table had been in the ‘moved’ condition was the same as that in the ‘unmoved’ condition (LRCS1 =0.34, df=1, p >.5; LRCS2 =0.28, df=1, p >.5), consistent by participants and by items (LRCS1 =24.14, df=33, p >.8; LRCS2 =11.88, df=15, p >.6). The probability of fixating where the glass had been also did not vary by condition (LRCS1 =2.39, df=1, p >.1; LRCS2 =1.73, df=1, p >.1), consistent by participants and by items (LRCS1 =24.87, df=33, p >.8; LRCS2 =21.31, df=15, p >.1). There were, overall, no more fixations on where the glass had been than on where the table had been (LRCS=0.36, df=1, p >.5), consistent by participants and by items (LRCS1 =19.84, df=33, p >.9; LRCS2 =19.66, df=15, p >.1). (ii). During ‘the wine carefully into’: The probability of launching an anticipatory eye movement towards where the table had been was significantly higher in the ‘moved’ condition than in the ‘unmoved’ condition (LRCS1 =10.0, df=1, p <.002; LRCS2 =7.37, df=1, p <.008), consistent by participants and by items (LRCS1 =34.14, df=33, p >.4; LRCS2 =14.37, df=15, p >.4). The probability of launching an eye movement towards where the glass had been was significantly higher in the ‘unmoved’ condition than in the ‘moved’ condition (LRCS1 =7.39, df=1, p <.008; LRCS2 =4.40, df=1, p <.04), consistent by participants and by items (LRCS1 =25.30, df=33, p >.8; LRCS2 =11.26, df=15, p >.7). Eye movements towards where the table had been were at the expense of eye movements towards where the glass had been, and vice versa (i.e. there was no effect of context on looks to non-critical regions: LRCS1 =0.07, df=1, p >.7; LRCS2 =0.20, df=1, p >.6), consistent by participants and by items (LRCS1 =26.56, df=33, p >.7; LRCS2 =7.37, df=15, p >.9). There were no more looks, collapsed across condition, to where the glass had been than towards where the table had been (LRCS=0.14, df=1, p >.7), consistent by participants and by items (LRCS1 =31.29, df=33, p >.5; LRCS2 =12.69, df=15, p >.6). That is, there was no residual bias towards one region or the other. To explore whether there was a residual tendency to move the eyes towards where the glass had actually been even in the ‘moved’ condition, we conducted further analyses which revealed that in this condition there were indeed slightly more saccades towards where the glass had been than towards the distractor region (LRCS=4.28, df=1, p =.04), consistent by participants and by items (both p >.2). Finally, looks to where the table had been in the ‘moved’ condition were as frequent as looks towards where the glass had been in the ‘unmoved’ condition (LRCS=0.12, df=1, p >.7; consistent by participants and by items – both p >.1). (iii). During ‘the glass’: The probability of launching an eye movement towards the table region was significantly higher in the ‘moved’ condition than in the ‘unmoved’ condition (LRCS1 =22.36, df=1, p <.001; LRCS2 =21.31, df=1, p <.001), consistent by participants and by items (LRCS1 =22.13, df=33, p >.9; LRCS2 =8.38, df=15, p >.9). The probability of launching an eye movement towards the glass region was significantly higher in the ‘unmoved’ condition than in the ‘moved’ condition (LRCS1 =25.09, df=1, p <.001; LRCS2 =15.82, df=1, p <.001), consistent by participants and by items (LRCS1 =21.43, df=33, p >.9; LRCS2 =13.03, df=15, p >.6). Eye movements towards where the glass had been were at the expense of eye movements towards where the table had been, and vice versa (LRCS1 =0.001, df=1, p >.9; LRCS2 =0.27, df=1, p >.6), consistent by participants and items (LRCS1 =24.37, df=33, p >.8; LRCS2 =8.33, df=15, p >.9). There was no overall bias to look more towards where the glass had been than towards where the table had been (LRCS=0.05, df=1, p >.8), consistent by participants and items (LRCS1 =15.27, df=33, p >.9; LRCS2 =8.78, df=15, p >.8). The probability of making an eye movement in the ‘moved’ condition to where the glass had been did not differ from the probability of moving to the distractor region (LRCS=0.29, df=1, p >.5; consistent by participants and by items, both p >.4). Looks to where the table had been in the ‘moved’ condition were as frequent as looks towards where the glass had been in the ‘unmoved’ condition (LRCS=0.27, df=1, p >.6; consistent by participants and by items, both p >.5). (iv). At the offset of ‘the glass’: the table region was fixated more at this point in time in the ‘moved’ condition than in the ‘unmoved’ condition (LRCS1 =14.05, df=1, p <.001; LRCS2 =15.06, df=1, p <.001), consistent by participants and by items (LRCS1 =41.49, df=33, p >.1; LRCS2 =16.06, df=15, p >.3). And conversely, the glass region was fixated more in the ‘unmoved’ condition than in the ‘moved’ condition (LRCS1 =17.54, df=1, p <.001; LRCS2 =15.52, df=1, p <.001), consistent by participants and by items (LRCS1 =40.94, df=33, p >.1; LRCS2 =18.76, df=15, p >.2). Increased fixations on where the table had been were at the expense of decreased fixations on where the glass had been and vice versa (LRCS1 =0.01, df=1, p >.9; LRCS2 =0.04, df=1, p >.8). This was consistent by participants and by items (LRCS1 =31.83, df=33, p >.5; LRCS2 =10.77, df=15, p >.7). There were no more fixations where the glass had been than where the table had been (LRCS=2.57, df=1, p >.1) consistent by participants and by items (LRCS1 =42.85, df=33, p >.1; LRCS2 =21.43, df=15, p >.1). In the ‘moved’ condition, the probability of fixating where the glass had been did not differ from the probability of fixating the distractor region (LRCS=0.05, df=1, p >.8; consistent by participants and by items, both p >.08). Fixations on the region where the table had been in the ‘moved’ condition were as frequent as fixations on the region where the glass had been in the ‘unmoved’ condition (LRCS=0.98, df=1, p >.3; consistent by participants and by items, both p >.2). 3.3 Discussion The results from Experiment 2 are clear: there were statistically reliable effects of context on eye movements towards both where the table had been and where the glass had been, whether in respect of anticipatory saccades, concurrent saccades (i.e. during ‘the glass’) or fixations at the offset of the sentence-final ‘glass’. Moreover, these effects were symmetrical – the eyes were directed towards where the table had been in the ‘moved’ condition as often as they were directed towards where the glass had been in the ‘unmoved’ condition (and vice versa). Thus, the visual record of where the glass had been in the ‘unmoved’ condition was no more salient (in respect of attracting eye movements towards the corresponding location) than the linguistically induced event-based record of where the glass would be in the ‘moved’ condition. Moreover, in the ‘moved’ condition, the eyes were no more attracted during ‘the glass’ to where the glass had actually been than they were towards where the distractor had been. In other words, there was no residual bias in this condition to look towards the remembered location of the glass. 3 Further inspection of the data revealed that the slight tendency to look towards the original location of the glass in the ‘moved’ condition during the underlined interval ‘pour the wine carefully into the glass’ (see Table 2) was due to a small increase in saccades towards this location during ‘carefully into’ (there was no such increase during ‘the wine’). Hence, there was some small residual attraction of the location originally occupied by the glass that did influence anticipatory eye movements. Crucially, the location originally occupied by the table was significantly more attractive, nonetheless. 3 Thus, the data from the ‘moved’ conditions indicate that the spatial representations that drove the eye movements in these studies were not reliant on objects actually having occupied particular locations within the scene. This is distinct from the situation described in Altmann (2004), in which anticipatory eye movements were observed towards a cake during ‘eat’ in ‘The man will eat the cake’ even though the corresponding scene had been removed prior to the onset of the spoken sentence. In Experiments 1 and 2, the glass had never occupied a position on or near the table, and yet its representation must have ‘inherited’, by means of the linguistic context, the spatial location associated with the table. We discuss below, in the general discussion, how this process might proceed. After Experiment 1, we suggested that the stimulus-driven representation of the concurrent glass in the scene competed with the representation of that glass as instantiated in the event-representation constructed through the unfolding language. Our motivation for Experiment 2 was to eliminate this competition. This appears to have been accomplished, with no more looks towards where the actual glass had been located, in the ‘unmoved’ condition, than towards where the glass would be moved in the ‘moved’ condition; by eliminating the concurrent perceptual correlates of one of these representations (the glass that was on the floor), neither representation (the glass on the floor or on the table) was more salient than the other. Moreover, we would maintain that both representations were available to the cognitive system. We collected no evidence in this regard, but we do not believe that participants believed mistakenly, in the ‘moved’ condition, that the glass had originally been located on the table; participants more probably tracked the initial and end states of the glass, maintaining both representations as components of the moving event (indeed, the representation of that event entails the representation of both states). The likely availability of both representations is apparent in the following examples (which should be interpreted within the context of the visual scene depicted in Fig. 1): (3) The woman will put the glass onto the table. Then, she will pick up the bottle, and pour the wine carefully into the glass. (4) The woman will put the glass onto the table. But first, she will pick up the bottle, and pour the wine carefully into the glass. Depending on the temporal connective ‘then’ or ‘first’, the glass into which the wine is poured is either located on the table (cf. 3) or on the floor (cf. 4). Further research is currently being undertaken to establish that participants’ eyes would return at the sentence-final ‘glass’ to the original location of the glass in (4) but to the new location on the table in (3); only two items in the current set of 16 used the ‘but first’ construction – too few to analyse separately. Nonetheless, the ease with which (4) can be comprehended (notwithstanding the difficulty induced by the mismatch between narrative and chronological order; cf. Mandler, 1986), including accommodation of the entailment that the glass is still on the floor, suggests that comprehenders can keep track of the distinct event-based representations of the glass and its locations. In Experiment 2, neither of the event-based representations of the glass was accompanied, during the unfolding language, by the concurrent perceptual correlates of a glass. The representation of the glass on the floor was accompanied by past correlates (i.e. the visual memory of the glass), but equally, the representation of the glass on the table (as instantiated by the unfolding language) was accompanied by these same past perceptual correlates, to the extent that it was the same glass that had previously been seen (it was not some new glass). All that changed across the representations was that one representation included information about the floor-as-location, and the other included information about the table-as-location – and the fact that neither was accompanied by concurrent sensory stimulation resulted in each being equally salient (at least as defined operationally, in respect of both attracting eye movements in equal measure in the corresponding conditions). Thus, whereas in Experiment 2 these two representations competed on a level playing field, in Experiment 1 they did not. 4 General discussion In the two studies reported above, linguistic contexts were used to manipulate the event-related locations of the objects that were portrayed in the concurrent scene. For example, participants fixated the table more often at the offset of ‘glass’ in ‘she will pick up the bottle, and pour the wine carefully into the glass’ when the preceding sentence had been ‘The woman will put the glass onto the table’ than when it had been ‘The woman is too lazy to put the glass onto the table’. Indeed, from ‘pour’ onwards, more saccadic eye movements were directed towards the table, or towards where the table had been, in the ‘moved’ condition than in the ‘unmoved’ condition. At first glance, these data suggest that overt visual attention is directed to particular locations that are, at least in part, determined by a dynamically modifiable representation of the objects’ locations, even when, as in Experiment 1, that representation is at odds with the location of the corresponding object in the concurrent visual scene. Elsewhere, we and others (e.g. Altmann & Kamide, 2007; Chambers et al., 2004; Kamide et al., 2003) have stressed the importance of experientially-based knowledge in respect of the mapping between an unfolding sentence and the current visual world context. But the experientially-based knowledge we have of how an object interacts with its environment is just one source of information we access when interacting with an object. Crucially, it is the episodic, or situation-specific, knowledge associated with the individual experience of an object, in combination with knowledge abstracted over multiple previous experiences of such objects, that determines the mode of that interaction (i.e. how we might orient towards that object, how that object may impact on other specific objects in our immediate environment, and so on; see Chambers et al., 2004 for a demonstration of how possible modes of interaction with objects in the environment modulate language-mediated eye movements). The location of an object, such as the glass in the experiments reported here, is one aspect of the episodic experience associated with that object. So how is that represented, and how can the unfolding language influence the content of that representation? One view of visual cognition – situated vision – proposes that the encoding of the location of an object has an important function in respect of enabling the cognitive system to use the concurrent visual world as an aid to memory (cf. Ballard, Hayhoe, Pook, & Rao, 1997; O’Regan, 1992; Richardson & Spivey, 2000); activating an object’s ‘spatial pointer’ – an oculomotor coordinate defined relative to the configuration of cues within the scene – causes the eyes to move to the object’s location, enabling the retrieval of information about it that had perhaps not been encoded within the mental representation of that object. Depending on the task, it may be advantageous to store only minimal information about the object in that mental representation, thereby minimising memory load; if anything more needs to be recalled about that object, the spatial pointer can direct the eyes towards the object itself, at which time further information can be accessed directly from the visual percept. However, if the spatial pointer is simply a memory of some physical configuration of perceptual cues associated with the location of an object, that object must, at some time, have occupied a particular location. And yet, when the eyes fixated the ‘moved’ location of the glass in Experiments 1 and 2, the glass had not previously occupied that position. Does this mean that the spatial pointer associated with the representation of the glass need not have a sensory basis? In order to permit direct comparison between Experiments 1 and 2, the same stimuli (both visual and auditory) were used. In principle, however, the glass (and its equivalent across different stimuli) could have been removed from the scenes, and the auditory stimulus for the ‘moved’ condition changed to ‘The woman will put a glass onto the table. Then, she will pick up the bottle, and pour the wine carefully into the glass’. We would conjecture that the precise same pattern of eye movements would be found as in the ‘moved’ condition of Experiment 2. In this respect, the component of the mental representation of the glass that encoded its spatial location would not have a sensory (visual) basis. According to Barsalou, Simmons, Barbey, and Wilson (2003), a sentence such as ‘The woman will put the glass on the table’ will engender a mental ‘simulation’ of the described event (a mental enactment of the experience of the event), in which case the spatial pointer corresponding to the eventual location of the glass in the ‘moved’ conditions of Experiments 1 and 2 might be considered a part of one such simulation. Although consideration of the relationship between ‘simulations’, ‘mental models’ (e.g. Johnson-Laird, 1983), and ‘situation models’ (e.g. van Dijk & Kintsch, 1983) is beyond the remit of this article, all three theoretical positions agree on the central role played by event representations – a role that is articulated most explicitly in versions of the event-indexing model (e.g. Zwaan, Langston, & Graesser, 1995; Zwaan & Radvansky, 1998). Within this general framework, the location to which the glass will move must be represented as part of the event structure constructed in response to the sentence that describes where, and when, the glass will be moved. And thus the representation of the glass’s future location is representationally (and situationally) distinct from its location within the concurrent or previous scene – the two representations have different experiential bases, with the actually experienced location based on perceptual properties of the configuration of objects within the scene, and the language-induced event-related location based on conceptual properties of the objects and their configuration within the scene. But given that both representations encode the configuration of objects within the scene, and that such configurational information, as distinct from absolute location, can form the basis for target-directed eye movements (cf. Spivey, Richardson, & Fitneva, 2004), both kinds of representation can support the targeting of saccadic eye movements. There is an alternative account of why the eyes moved towards the table, when anticipating or hearing ‘the glass’ in the ‘moved’ conditions of Experiments 1 and 2. This alternative is not concerned with the spatial pointers associated with the representation of the glass, but rather with how the unfolding language might modify knowledge of the table. Our knowledge of a glass – its affordances – includes the fact that it can be drunk from, and that liquid can be poured into one. Our knowledge of a table is that it can, amongst other things, support objects. We might even suppose that this knowledge is probabilistic, with our knowledge of a table encoding the greater probability with which it may support a plate or a glass than a motorcycle (to this end, we would contend, for example, that a wine glass with a few drops of wine at the bottom would more likely be interpreted as having been fuller and subsequently drunk out of than as having been empty and subsequently filled with just those few drops – the latter is possible, albeit unlikely). In the experiments reported here, the linguistic context changed a number of things, including the future location of the glass, and the future situation-specific affordances of the table – namely, that it would afford a glass with some more definite probability (tables can always afford glasses or any other myriad number of objects, but which objects they afford at which times is situationally-determined). The notion here that the table could ‘afford’ a glass is no different from the notion that an empty wine glass could have afforded, in the past, some wine, or could afford, in the future, some wine. We have previously found (Altmann & Kamide, 2007) that such affordances mediate eye movements towards an empty wine glass or a full glass of beer as a function of whether participants hear ‘the man will drink the…’ or ‘the man has drunk the…’, with significantly more fixations on the empty wine glass at the onset of the postverbal determiner in the ‘has drunk’ condition than in the ‘will drink’ condition. Perhaps, in Experiments 1 and 2, participants fixated the table after ‘glass’, or indeed after ‘pour’ when anticipating an object into which something could be poured, because the knowledge they had of this table included the fact that, in the future, it would more definitely support a glass. In other words, the eyes moved towards the table because its affordances – knowledge of what it would hold in the future – matched the conceptual specification associated with the future tensed verb (see Altmann & Kamide, 2007, for an account of language-mediated eye movement control, based on such conceptual matching, which can be applied to both concurrent and ‘blank screen’ situations). Thus, we distinguish (as we did above) between affordances as knowledge abstracted across multiple experiences, and affordances as situation-specific knowledge that reflects the interaction between experience and the current situation. One corollary of our approach is that, in the context of the ‘move the glass’ example, it matters that the woman moved the glass to a plausible location (that is, to a location that could plausibly afford the placement of a glass). But language is not limited to describing the plausible, or even the possible. Our claim that experientially-based event representations mediate our effects would predict that the eyes would not so readily move to the future location of the glass following a sentence such as ‘The woman will put the glass on her head’. A more perceptually-bound account, in which spatial location is encoded, and accessed, regardless of experientially-based event representations, would predict that the eyes would move to the new location as effortlessly when the glass was moved to the woman’s head as when it was moved to the table. Future research is required to rule out such an outcome. Our data do not determine whether looks towards the table in the ‘moved’ conditions were due to location-specific knowledge associated with the future-event-based representation of the glass or were due to the future-situation-specific affordances of the table (and indeed, the two are not mutually exclusive; looks could have been due to a combination of both these sources of knowledge). Our data do reveal nonetheless that both the experiential and situationally-defined meaning of language interact with visual representations in determining where visual attention is directed as people understand language that refers to a visual scene. This is not particularly noteworthy, as it is unclear (from everyday experience) how cognition could function in any other way. What is noteworthy, we believe, is that our data reveal a dissociation that is possible between our representation of the currently experienced, or previously experienced, state of the (visual) world and other possible states, at other times, of that same world. In so doing, they reveal the manner in which eye movements reflect those same dissociations; the eye movements we have observed in these studies reflect a mental world whose contents appear, at least in part, to be dissociable from the concurrent, remembered, or imagined visual world, and it is this facet of our data that is novel. This dissociation, between the mental representations of objects and the perceptual correlates of those objects as depicted in a concurrent or prior scene, is due to the distinction between the sensory/perceptual experience of an object and the knowledge we have of that object. As suggested earlier, experientially-based encodings of the ways in which we interact with objects (and in which they interact with one another) require a representational substrate that encodes information that goes beyond that conveyed by the visual correlates of those objects. This experiential knowledge is critical in respect of causing attention to be attracted, in different circumstances, to certain objects more than to others. The nature of this knowledge speaks to the relationship between mental representations constructed on the basis of linguistic input on the one hand, and on the basis of visual scene processing on the other. We take the concept associated with an object in the real world to reflect, amongst other things (such as its physical form) the accumulated experience of the ways in which that object interacts with others in its real world environment — an idea that is mirrored in the language literature as the view that thematic roles reflect the accumulated experience of the events, and the entities that participate in those events, to which each verb in the language refers (McRae, Ferretti, & Amyote, 1997). In each case, the concept (whether associated with the object or with the verb-specific thematic role) is the accumulated experience of the interaction between one object and another. On this view, the same knowledge base underpins both the interpretation of the visual scene (in the absence of any language) and the interpretation of a sentence with reference to the verb’s thematic roles and the entities filling those roles (in the absence of a concurrent visual scene). In this respect, the visual scenes we have employed in our studies are simply a means to an end – they enable us to control the content of the mental representations within the context of which a particular sentence will be interpreted; the patterns of eye movements that accompany that interpretation enable us to probe the content of the representation that is being attended to as that interpretation develops in time. Finally, our data suggest that theories of cognition (i.e. theories pertaining to the internal representation of external events) need to take account of the need for multiple representational instantiations of the same objects – instantiated with different event-specific properties. More specifically, they need to take account of the consequences of such multiple instantiations if, as we have suggested, they in fact compete with one another. Ellen Markman (personal communication) has suggested that the competition we have observed amongst multiple representational instantiations of the same object may even explain children’s poor performance on certain tasks such as the False Belief Task (Wimmer & Perner, 1983). In such tasks, the child must keep in mind multiple representations of the same object – the object starts off in one location, but is then moved to another, and this change in location is unseen by a protagonist whom the child is observing (or whom the child is being told about if the task is via story-telling). The child’s task is to say where the (deceived) protagonist thinks the object is (the correct answer corresponds to the original location, as the protagonist could not know that it had moved). The problem for the child is not so much that the object was in different locations before and after the movement, but rather that the child must represent both her own knowledge of the object’s location and the protagonist’s. Children aged 3-years will typically say that the protagonist thinks the object is in the new location. We conjecture that poor performance on such tasks may not reflect impoverished representation of beliefs per se, but may instead reflect competitive processes that favour one representation (the child’s actual knowledge) more than another (the protagonist’s presumed knowledge). Clements and Perner (1994) used evidence from children’s eye movements to argue that these distinct representations corresponding to the object at different locations do in fact co-exist in the traditional version of this task. A similar interpretation of the False Belief Task is given by Zaitchik (1990). She modified the task to show that performance in this task is unrelated to the child having to maintain a representation of the belief state of the protagonist. In her version of the task, a photograph was taken of the object before it was moved, and children were asked to say where, in the photograph, the object was located (the photograph was removed prior to the question). Children responded as if they had been asked where the protagonist thought the object was located – that is, they mistakenly reported the new location. Zaitchik argued that this behaviour arose because of the conflict between the child’s perceptual representation of the world as it really was and the child’s representation of the alternative state as represented in the photograph or the beliefs ascribed to the deceived protagonist. Our own proposal with respect to multiple representational instantiations of the same object is similar, although we place the burden of competition not at a propositional or situational level, but at the level of object representation. With respect to the transition from child to adult, it is conceivable that this involves a gradual shift in the weight given to the different features (perceptual, conceptual, temporal, and so on) which constitute the representational instantiations of each object. Our own data (Experiment 2) suggest that this shift results in an adult system which favours the perceptual correlates of the object-representations constructed through past perceptual experience no more than it does the conceptual correlates of the event-representations constructed through language. The data reported here demonstrate how language can mediate the dynamic updating of a mental representation of a visual scene, and how this updated mental representation can form the basis for the subsequent direction of attention, irrespective of whether the scene is still present. These and other data lead us to believe that both anticipatory and concurrent eye movements reflect, in real-time, the unfolding interpretation of language with respect to a dynamically changing mental representation of a ‘real’ world to which that language may refer. It is this mental representation that guides behaviour. The challenge now is to understand how multiple instantiations of the same event-participants, reflecting the changes they undergo as the event unfolds, are distinguished within this medium. Acknowledgments The research was supported by awards from The Medical Research Council (G0000224) and The Wellcome Trust (076702/Z/05/Z) to the first author. The work benefited from many useful discussions with Silvia Gennari and with Jelena Mirkovic, who also helped prepare and run Experiment 2 as part of an undergraduate project conducted by Jenna Hughes. We thank Christoph Scheepers and two anonymous reviewers for their constructive comments on an earlier version of this article. A preliminary report of an earlier version of Experiment 1, with slightly different items, appears in Altmann and Kamide (2004). Appendix 1 The sentential stimuli used in Experiments 1 and 2. There were two versions of each item, corresponding to the ‘moved’ and ‘unmoved’ conditions. Also shown is a list of the objects in the corresponding scene; the final object in the list corresponds to the distractor in Experiment 2. The woman will put the glass onto the table. Then, she will pick up the bottle, and pour the wine carefully into the glass. [‘moved’ condition]. The woman is too lazy to put the glass onto the table. Instead, she will pick up the bottle, and pour the wine carefully into the glass. [‘unmoved’ condition]. [woman, table, bottle of wine, empty wine glass, bookcase]. The woman will put the bread onto the plate. Then, she will take some butter, and spread it sluggishly onto the bread. The woman decided not to put the bread onto the plate. She will take some butter, and spread it sluggishly onto the bread. [woman, worktop, empty plate, butter dish with butter, slice of bread on board, coffee cup]. The office worker will drag the dustbin right next to the fan. Then, he will grab the can, and chuck it violently into the dustbin. The office worker has just dragged the dustbin away from the fan. Now, he will grab the can, and chuck it violently into the dustbin. [man at desk, floor fan, drinks can, wastebin, swivel chair. The fan was on the far left of the scene, to ensure that the region of interest corresponding to ‘next to the fan’ was a constrained region to just one side]. The woman will lift the pet carrier onto the table. Then, she will take hold of the cat, and put it carefully into the pet carrier. The woman has just lifted the pet carrier down from the table. Now, she will take hold of the cat, and put it carefully into the pet carrier. [woman, table, cat, pet carrier, picture]. The businessman will put the computer onto the desk. Then, he will pick up the disk, and insert it gently into the computer. The businessman was unable to put the computer onto the desk. But, he will pick up the disk, and insert it gently into the computer. [man, desk, computer disk on floor, computer, briefcase]. The secretary will move the folder right next to the lamp. Then, she will look at the documents, and file them efficiently in the folder. The secretary has moved the folder away from the lamp. She will look at the documents, and file them efficiently in the folder. [woman, desktop, desk lamp, pile of documents, document folder, ink stamp. The lamp was on the far right of the scene, to ensure that the region of interest corresponding to ‘next to the lamp’ was a constrained region to just one side]. The woman will place the pan onto the cooker. Then, she will reach for the bowl, and transfer the eggs swiftly into the pan. The woman will soon place the pan onto the cooker. But first, she will reach for the bowl, and transfer the eggs swiftly into the pan. [woman, worktop, cooker, bowl with eggs, frying pan, pepper mill]. The housewife will move the vase onto the sideboard. Then, she will pick up the flowers, and arrange them delicately in the vase. The housewife is too tired to move the vase onto the sideboard. But, she will pick up the flowers, and arrange them delicately in the vase. [woman, sideboard, flowers on floor, vase, books] The chef will take the pan to the cooker. Then, he will notice the lid, and place it quickly onto the pan. The chef will check the pan and the cooker. Then, he will notice the lid, and place it quickly onto the pan. [chef, worktop, cooker, pan lid, pan with vegetables, knife]. The woman will slide the jewellery box right next to the coffee. Then, she will admire the necklace, and hide it quickly inside the jewellery box. The woman will examine the jewellery box as she drinks the coffee. Then, she will admire the necklace, and hide it quickly inside the jewellery box. [woman at table, coffee cup, necklace, jewellery box, door. The smaller objects were arranged on the table top so that a constrained region could be defined corresponding to ‘next to the coffee’]. The man will shift the box onto the worktop. Then, he will lift up the pizza, and put it carefully into the box. The man has just shifted the box off the worktop. Now, he will lift up the pizza, and put it carefully into the box. [man, worktop, napkin, fork, pizza, empty pizza box, fridge]. The man will put the gramophone onto the sideboard. Then, he will clean the record, and place it carefully on the gramophone. The man will soon put the gramophone onto the sideboard. But first, he will clean the record, and place it carefully on the gramophone. [man in chair, sideboard, record, gramophone player, bongos]. The girl will suspend the hanger on the rail. Then, she will reach for the shirt and hang it cheerfully onto the hanger. The girl has taken the hanger off the rail. Now, she will reach for the shirt and hang it cheerfully onto the hanger. [girl, clothes rail, shirt on chair, coat hanger, plant]. The man will move the cup onto the table. Then, he will reach for the tea pot, and pour the tea slowly into the cup. The man has taken the cup off the table. Now, he will reach for the tea pot, and pour the tea slowly into the cup. [man, table, teapot, tea cup, chair]. The man will drag the chair over to the girl. Then, he will lift up the teddy bear, and sit it affectionately on the chair. The man will look at the chair and then at the girl. Then, he will lift up the teddy bear, and sit it affectionately on the chair. [man, girl, teddy bear, chair, Christmas tree. The girl was on the far left of the scene, to ensure that the region of interest corresponding to ‘over to the girl’ was a constrained region to just one side]. The woman will move the mug onto the trolley. Then, she will reach for the bottle, and tip the water quickly into the mug. The woman has taken the mug off the trolley. Now, she will reach for the bottle, and tip the water quickly into the mug. [woman, trolley, bottle of water, mug on table, dustbin]. References Allopenna et al., 1998 P.D. Allopenna J.S. Magnuson M.K. Tanenhaus Tracking the time course of spoken word recognition using eye movements: Evidence for continuous mapping models Journal of Memory and Language 38 4 1998 419 439 Altmann, 2004 G.T.M. Altmann Language-mediated eye movements in the absence of a visual world: The ‘blank screen’ paradigm Cognition 93 2004 79 87 Altmann and Kamide, 1999 G.T.M. Altmann Y. Kamide Incremental interpretation at verbs: Restricting the domain of subsequent reference Cognition 73 3 1999 247 264 Altmann and Kamide, 2004 G.T.M. Altmann Y. Kamide Now you see it, now you don’t: Mediating the mapping between language and the visual world F. Ferreira The integration of language, vision, and action: Eye movements and the visual world 2004 Psychology Press New York 347 386 Altmann and Kamide, 2007 G.T.M. Altmann Y. Kamide The real-time mediation of visual attention by language and world knowledge: Linking anticipatory (and other) eye movements to linguistic processing Journal of Memory and Language 57 2007 502 518 Ballard et al., 1997 D.H. Ballard M.M. Hayhoe P.K. Pook R.P.N. Rao Deictic codes for the embodiment of cognition Behavioural and Brain Sciences 20 4 1997 723 767 Barsalou et al., 2003 L.W. Barsalou W.K. Simmons A.K. Barbey C.D. Wilson Grounding conceptual knowledge in modality-specific systems Trends in Cognitive Sciences 7 2 2003 84 91 Chambers et al., 2004 C.G. Chambers M.K. Tanenhaus J.S. Magnuson Actions and affordances in syntactic ambiguity resolution Journal of Experimental Psychology: Learning, Memory and Cognition 30 2004 687 696 Clements and Perner, 1994 W.A. Clements J. Perner Implicit understanding of belief Cognitive Development 9 1994 377 395 Cooper, 1974 R.M. Cooper The control of eye fixation by the meaning of spoken language: A new methodology for the real-time investigation of speech perception, memory, and language processing Cognitive Psychology 6 1 1974 84 107 Dahan et al., 2001 D. Dahan J.S. Magnuson M.K. Tanenhaus E.M. Hogan Subcategorical mismatches and the time course of lexical access: Evidence for lexical competition Language and Cognitive Processes 16 2001 507 534 Dowty, 1979 D. Dowty Word meaning and Montague grammar 1979 Kluwer Academic Dordrecht, The Netherlands Ferreira et al., 2002 F. Ferreira V. Ferraro K.G.D. Bailey Good-enough representations in language comprehension Current Directions in Psychological Science 11 2002 11 15 Gibson, 1977 J.J. Gibson The theory of affordances R.E. Shaw J. Bransford Perceiving, acting, and knowing 1977 Lawrence Erlbaum Associates Hillsdale, NJ Henderson and Ferreira, 2004 J.M. Henderson F. Ferreira Scene perception for psycholinguists J.M. Henderson F. Ferreira The interface of language, vision and action 2004 Psychology Press Hove 1 58 Hommel et al., 2001 B. Hommel J. Müsseler G. Aschersleben W. Prinz The theory of event coding (TEC): A framework for perception and action planning Behavioral and Brain Sciences 24 2001 849 937 Hoover and Richardson, 2008 M.A. Hoover D.C. Richardson When facts go down the rabbit hole: Contrasting features and objecthood as indexes to memory Cognition 108 2008 533 542 Huettig and Altmann, 2005 F. Huettig G.T.M. Altmann Word meaning and the control of eye fixation: Semantic competitor effects and the visual world paradigm Cognition 96 2005 23 32 Johnson-Laird, 1983 P.N. Johnson-Laird Mental models: Towards a cognitive science of language, inference, and consciousness 1983 Harvard University Press Cambridge, MA Kamide et al., 2003 Y. Kamide G.T.M. Altmann S.L. Haywood The time-course of prediction in incremental sentence processing: Evidence from anticipatory eye movements Journal of Memory and Language 49 2003 133 159 Knoeferle and Crocker, 2006 P. Knoeferle M.W. Crocker The coordinated interplay of scene, utterance, and world knowledge: Evidence from eye tracking Cognitive Science 30 2006 481 529 Knoeferle and Crocker, 2007 P. Knoeferle M.W. Crocker The influence of recent scene events on spoken comprehension: Evidence from eye movements Journal of Memory and Language 57 2007 519 543 Knoeferle et al., 2005 P. Knoeferle M.W. Crocker C. Scheepers M.J. Pickering The influence of the immediate visual context on incremental thematic role-assignment: Evidence from eye-movements in depicted events Cognition 95 2005 95 127 Mandler, 1986 J.M. Mandler On the comprehension of temporal order Language and Cognitive Processes 1 1986 309 320 McRae et al., 1997 K. McRae T.R. Ferretti L. Amyote Thematic roles as verb-specific concepts Language and Cognitive Processes 12 2/3 1997 137 176 O’Regan, 1992 J.K. O’Regan Solving the ‘real’ mysteries of visual perception: The world as an outside memory Canadian Journal of Psychology 46 1992 461 488 Richardson and Spivey, 2000 D.C. Richardson M.J. Spivey Representation, space and Hollywood squares: Looking at things that aren’t there anymore Cognition 76 2000 269 295 Scheepers, 2003 C. Scheepers Syntactic priming of relative clause attachments: Persistence of structural configuration in sentence production Cognition 89 2003 179 205 Spivey et al., 2004 M.J. Spivey D.C. Richardson S.A. Fitneva Thinking outside the brain: Spatial indices to visual and linguistic information J.M. Henderson F. Ferreira The interface of language, vision, and action: Eye movements and the visual world 2004 Psychology Press New York Steedman, 2002 M.J. Steedman Plans, affordances, and combinatory grammar Linguistics and Philosophy 25 2002 723 753 Tanenhaus et al., 1995 M.K. Tanenhaus M.J. Spivey-Knowlton K.M. Eberhard J.C. Sedivy Integration of visual and linguistic information in spoken language comprehension Science 268 5217 1995 1632 1634 van Dijk and Kintsch, 1983 T.A. van Dijk W. Kintsch Strategies in discourse comprehension 1983 Academic Press New York Wimmer and Perner, 1983 H. Wimmer J. Perner Beliefs about beliefs: Representation and constraining function of wrong beliefs in Young children’s understanding of deception Cognition 13 1983 103 128 Zaitchik, 1990 D. Zaitchik When representations conflict with reality: The preschooler’s problem with false beliefs and “false” photographs Cognition 35 1990 41 68 Zwaan et al., 1995 R.A. Zwaan M.C. Langston A.C. Graesser The construction of situation models in narrative comprehension: An event-in-dexing model Psychological Science 6 1995 292 297 Zwaan and Radvansky, 1998 R.A. Zwaan G.A. Radvansky Situation models in language comprehension and memory Psychological Bulletin 123 2 1998 162 185"
10.1016/j.cognition.2008.12.006,Linking production and comprehension processes: The case of relative clauses ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090211', '$': '2009-02-11'}}}}"
10.1016/j.cognition.2008.12.007,The KEY to the ROCK: Near-homophony in nonnative visual word recognition ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090223', '$': '2009-02-23'}}}}"
10.1016/j.cognition.2008.12.008,"The logical syntax of number words: Theory, acquisition and processing ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090213', '$': '2009-02-13'}}}}"
10.1016/j.cognition.2008.12.009,Anatomy of an error: A bidirectional state model of task engagement/disengagement and attention-related errors ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090211', '$': '2009-02-11'}}}}"
10.1016/j.cognition.2008.12.010,Sources of information for discriminating dynamic human actions ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090130', '$': '2009-01-30'}}}}"
10.1016/j.cognition.2008.12.011,Investigating the causes of wrap-up effects: Evidence from eye movements and E–Z Reader ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20090211', '$': '2009-02-11'}}}}"
