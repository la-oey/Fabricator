doi,title,text
10.1016/j.cognition.2005.01.001,Gesture is at the cutting edge of early language development ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050323', '$': '2005-03-23'}}}}"
10.1016/j.cognition.2005.01.002,Phoneme isolation ability is not simply a consequence of letter-sound knowledge ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050408', '$': '2005-04-08'}}}}"
10.1016/j.cognition.2005.01.003,Principled and statistical connections in common sense conception ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050419', '$': '2005-04-19'}}}}"
10.1016/j.cognition.2005.01.004,Spatial representation of pitch height: the SMARC effect ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050531', '$': '2005-05-31'}}}}"
10.1016/j.cognition.2005.01.005,What does an intermediate success rate mean? An analysis of a Piagetian liquid conservation task in the great apes ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050414', '$': '2005-04-14'}}}}"
10.1016/j.cognition.2005.01.006,Speech segmentation by statistical learning depends on attention ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050418', '$': '2005-04-18'}}}}"
10.1016/j.cognition.2005.01.007,Young infants' expectations about hidden objects ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050427', '$': '2005-04-27'}}}}"
10.1016/j.cognition.2005.01.008,The role of inferences about referential intent in word learning: Evidence from autism ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050531', '$': '2005-05-31'}}}}"
10.1016/j.cognition.2005.01.009,Effects of syllable frequency in speech production ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050606', '$': '2005-06-06'}}}}"
10.1016/j.cognition.2005.01.010,Décalage in infants' knowledge about occlusion and containment events: Converging evidence from action tasks ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050606', '$': '2005-06-06'}}}}"
10.1016/j.cognition.2005.01.011,Chimpanzees deceive a human competitor by hiding ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060117', '$': '2006-01-17'}}}}"
10.1016/j.cognition.2005.02.001,Lexically-driven syntactic priming ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050531', '$': '2005-05-31'}}}}"
10.1016/j.cognition.2005.02.002,Interfering neighbours: The impact of novel word learning on the identification of visually similar words ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050531', '$': '2005-05-31'}}}}"
10.1016/j.cognition.2005.02.003,Is inhibition of return a reflexive effect? ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050531', '$': '2005-05-31'}}}}"
10.1016/j.cognition.2005.02.004,The role of phonological activation in the visual semantic retrieval of Chinese characters ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050701', '$': '2005-07-01'}}}}"
10.1016/j.cognition.2005.02.005,The evolution of the language faculty: Clarifications and implications ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050819', '$': '2005-08-19'}}}}"
10.1016/j.cognition.2005.02.006,Cumulative semantic inhibition in picture naming: experimental and computational studies ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060117', '$': '2006-01-17'}}}}"
10.1016/j.cognition.2005.03.002,Categorical perception of speech sounds in illiterate adults ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050701', '$': '2005-07-01'}}}}"
10.1016/j.cognition.2005.03.003,"Decisions, decisions: infant language learning when multiple generalizations are possible ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050629', '$': '2005-06-29'}}}}"
10.1016/j.cognition.2005.03.004,Segmentation of object outlines into parts: A large-scale integrative study ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050725', '$': '2005-07-25'}}}}"
10.1016/j.cognition.2005.03.005,"On the masking and disclosure of unconscious elaborate processing. A reply to Van Opstal, Reynvoet, and Verguts (2005) ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050701', '$': '2005-07-01'}}}}"
10.1016/j.cognition.2005.04.001,Processing controlled PROs in Spanish ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051128', '$': '2005-11-28'}}}}"
10.1016/j.cognition.2005.04.002,On the fate of distractor stimuli in rapid serial visual presentation ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050701', '$': '2005-07-01'}}}}"
10.1016/j.cognition.2005.04.003,Measuring individual differences in sensitivities to basic emotions in faces ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050701', '$': '2005-07-01'}}}}"
10.1016/j.cognition.2005.04.004,Can infants attribute to an agent a disposition to perform a particular action? ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050701', '$': '2005-07-01'}}}}"
10.1016/j.cognition.2005.04.005,Unconscious semantic categorization and mask interactions: An elaborate response to Kunde et al. (2005) ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050629', '$': '2005-06-29'}}}}"
10.1016/j.cognition.2005.04.006,"The nature of the language faculty and its implications for evolution of language (Reply to Fitch, Hauser, and Chomsky) ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050919', '$': '2005-09-19'}}}}"
10.1016/j.cognition.2005.04.007,"Language-experience facilitates discrimination of /d-
                  
               / in monolingual and bilingual acquisition of English ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050822', '$': '2005-08-22'}}}}"
10.1016/j.cognition.2005.04.008,Multi-stage mental process for economic choice in capuchins ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050725', '$': '2005-07-25'}}}}"
10.1016/j.cognition.2005.04.009,Knowing what a novel word is not: Two-year-olds ‘listen through’ ambiguous adjectives in fluent speech ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050825', '$': '2005-08-25'}}}}"
10.1016/j.cognition.2005.04.010,Infants' ability to use luminance information to individuate objects ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050822', '$': '2005-08-22'}}}}"
10.1016/j.cognition.2005.05.001,Erratum to ‘Horizontal and vertical Simon effect: different underlying mechanisms?’ [Cognition 96 (2005) B33–43]☆,"serial JL 271061 291210 291723 291726 291738 291743 291782 31 Cognition COGNITION 2005-06-20 2005-06-20 2010-03-28T22:52:45 1-s2.0-S0010027705000739 S0010-0277(05)00073-9 S0010027705000739 10.1016/j.cognition.2005.05.001 S300 S300.1 FULL-TEXT 1-s2.0-S0010027705X02670 2015-05-14T00:00:22.981292-04:00 0 0 20050701 20050731 2005 2005-06-20T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype volfirst volissue webpdf webpdfpagecount body mmlmath affil articletitle auth authfirstini authfull authlast pubtype alllist content subj ssids 0010-0277 00100277 96 96 3 3 Volume 96, Issue 3 9 b115 b115 200507 July 2005 2005-07-01 2005-07-31 2005 Erratum simple-article err Copyright © 2005 Elsevier B.V. All rights reserved. ERRATUMHORIZONTALVERTICALSIMONEFFECTDIFFERENTUNDERLYINGMECHANISMSCOGNITION962005B3343 VALLESI A 10.1016/j.cognition.2004.11.009 S0010027704002227 VALLESIX2005Xb115 VALLESIX2005Xb115XA item S0010-0277(05)00073-9 S0010027705000739 1-s2.0-S0010027705000739 10.1016/j.cognition.2005.05.001 271061 2010-09-17T05:54:17.121625-04:00 2005-07-01 2005-07-31 1-s2.0-S0010027705000739-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705000739/MAIN/application/pdf/94be983f5507e07412ca457af4f2b038/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705000739/MAIN/application/pdf/94be983f5507e07412ca457af4f2b038/main.pdf main.pdf pdf true 39658 MAIN 1 1-s2.0-S0010027705000739-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705000739/PREVIEW/image/png/a3250eef5f2adaae04ded7b78efa8aa3/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705000739/PREVIEW/image/png/a3250eef5f2adaae04ded7b78efa8aa3/main_1.png main_1.png png 26411 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0010027705000739-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705000739/STRIPIN/image/gif/2f2af0e6984cbab2143aab5a8c684ff4/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705000739/STRIPIN/image/gif/2f2af0e6984cbab2143aab5a8c684ff4/si2.gif si2 si2.gif gif 957 15 300 ALTIMG 1-s2.0-S0010027705000739-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705000739/STRIPIN/image/gif/11b2554511f77487e85e4884a526053e/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705000739/STRIPIN/image/gif/11b2554511f77487e85e4884a526053e/si1.gif si1 si1.gif gif 974 15 300 ALTIMG COGNIT 1438 S0010-0277(05)00073-9 10.1016/j.cognition.2005.05.001 S0010-0277(04)00222-7 10.1016/j.cognition.2004.11.009 Elsevier B.V. Erratum Erratum to ‘Horizontal and vertical Simon effect: different underlying mechanisms?’ [Cognition 96 (2005) B33–43]☆ Antonino Vallesi Daniela Mapelli Sami Schiff Piero Amodio Carlo Umilta ⁎ carlo.umilta@unipd.it Dipartimento di Piscologia Generale, Universita di Padova, via Venezia 8, 35131 Padova, Italy ⁎ Corresponding author. Tel.: +39 49 827 6610; fax: +39 49 827 6600. The publisher regrets that in the publishing of the above article, the formula for calculating the Lateralized Readiness Potential contained a mistake (p. B37, line 2). The formula should read as follows: [ ( C 3 − C 4 ) right hand − ( C 3 − C 4 ) left hand ] / 2 To be coherent with the text and the figures, the formula should be: [ ( C 3 − C 4 ) left hand − ( C 3 − C 4 ) right hand ] / 2 We apologise for any embarassement caused to the authors due to the above error."
10.1016/j.cognition.2005.05.002,"Identification, situational constraint, and social cognition: Studies in the attribution of moral responsibility ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050808', '$': '2005-08-08'}}}}"
10.1016/j.cognition.2005.05.003,The relative importance of spatial versus temporal structure in the perception of biological motion: An event-related potential study ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050726', '$': '2005-07-26'}}}}"
10.1016/j.cognition.2005.05.004,"Competence and performance in belief-desire reasoning across two cultures: The truth, the whole truth and nothing but the truth about false belief? ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050808', '$': '2005-08-08'}}}}"
10.1016/j.cognition.2005.05.005,When English proposes what Greek presupposes: The cross-linguistic encoding of motion events ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050725', '$': '2005-07-25'}}}}"
10.1016/j.cognition.2005.05.006,The influence of visual experience on the ability to form spatial mental models based on route and survey descriptions ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050725', '$': '2005-07-25'}}}}"
10.1016/j.cognition.2005.05.007,Representational and executive selection resources in ‘theory of mind’: Evidence from compromised belief-desire reasoning in old age ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051108', '$': '2005-11-08'}}}}"
10.1016/j.cognition.2005.06.001,A challenge to current models of past tense inflection: The impact of phonotactics ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050801', '$': '2005-08-01'}}}}"
10.1016/j.cognition.2005.06.002,Guest reviewers ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050722', '$': '2005-07-22'}}}}"
10.1016/j.cognition.2005.06.003,Books Received 2004 ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050725', '$': '2005-07-25'}}}}"
10.1016/j.cognition.2005.06.004,Semantic evaluation of syntactic structure: Evidence from eye movements ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050822', '$': '2005-08-22'}}}}"
10.1016/j.cognition.2005.06.005,Object recognition with severe spatial deficits in Williams syndrome: sparing and breakdown ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050926', '$': '2005-09-26'}}}}"
10.1016/j.cognition.2005.06.006,Unconscious inhibition and facilitation at the objective detection threshold: Replicable and qualitatively different unconscious perceptual effects ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051108', '$': '2005-11-08'}}}}"
10.1016/j.cognition.2005.07.001,The role of prosody in the interpretation of structural ambiguities: A study of anticipatory eye movements ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050912', '$': '2005-09-12'}}}}"
10.1016/j.cognition.2005.07.002,Recent experience affects the strength of structural priming ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050822', '$': '2005-08-22'}}}}"
10.1016/j.cognition.2005.07.003,Are generalised scalar implicatures generated by default? An on-line investigation into the role of context in generating pragmatic inferences ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050822', '$': '2005-08-22'}}}}"
10.1016/j.cognition.2005.07.004,How do young children determine location? Evidence from disorientation tasks ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050926', '$': '2005-09-26'}}}}"
10.1016/j.cognition.2005.07.005,Moral dilemmas and moral rules ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050912', '$': '2005-09-12'}}}}"
10.1016/j.cognition.2005.07.006,Preschoolers favor the creator's label when reasoning about an artifact's function ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050926', '$': '2005-09-26'}}}}"
10.1016/j.cognition.2005.08.001,Calendrical savants: Exceptionality and Practice ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20050912', '$': '2005-09-12'}}}}"
10.1016/j.cognition.2005.08.002,Thematic role properties of subjects and objects ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051109', '$': '2005-11-09'}}}}"
10.1016/j.cognition.2005.08.003,From semantics to syntax and back again: Argument structure in the third year of life ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051109', '$': '2005-11-09'}}}}"
10.1016/j.cognition.2005.09.001,Specific phonological impairments in dyslexia revealed by eyetracking ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051108', '$': '2005-11-08'}}}}"
10.1016/j.cognition.2005.09.002,Audio-visual speech perception off the top of the head ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051108', '$': '2005-11-08'}}}}"
10.1016/j.cognition.2005.09.003,Cross-modal interactions in the perception of musical performance ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051109', '$': '2005-11-09'}}}}"
10.1016/j.cognition.2005.09.004,What is the relationship between synaesthesia and visuo-spatial number forms? ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051108', '$': '2005-11-08'}}}}"
10.1016/j.cognition.2005.09.005,"Differential developmental trajectories for egocentric, environmental and intrinsic frames of reference in spatial memory ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051215', '$': '2005-12-15'}}}}"
10.1016/j.cognition.2005.09.006,Comparison of confirmation measures ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060505', '$': '2006-05-05'}}}}"
10.1016/j.cognition.2005.10.001,What does Batman think about SpongeBob? Children's understanding of the fantasy/fantasy distinction ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051121', '$': '2005-11-21'}}}}"
10.1016/j.cognition.2005.10.002,What does syntax say about space? 2-year-olds use sentence structure to learn new prepositions ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051220', '$': '2005-12-20'}}}}"
10.1016/j.cognition.2005.10.003,Agreement and movement: A syntactic analysis of attraction ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051215', '$': '2005-12-15'}}}}"
10.1016/j.cognition.2005.10.004,Enumeration versus multiple object tracking: the case of action video game players ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051215', '$': '2005-12-15'}}}}"
10.1016/j.cognition.2005.10.005,"Five-month-old infants know humans are solid, like inanimate objects ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051219', '$': '2005-12-19'}}}}"
10.1016/j.cognition.2005.10.006,The acquisition of allophonic rules: Statistical learning with linguistic constraints ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051220', '$': '2005-12-20'}}}}"
10.1016/j.cognition.2005.11.001,Information leakage from logically equivalent frames ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051220', '$': '2005-12-20'}}}}"
10.1016/j.cognition.2005.11.002,The role of attention in the facilitation effect and another “inhibition of return” ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051227', '$': '2005-12-27'}}}}"
10.1016/j.cognition.2005.11.003,Implicit action encoding influences personal-trait judgments,"serial JL 271061 291210 291723 291726 291738 291743 291782 31 90 Cognition COGNITION 2006-02-02 2006-02-02 2014-10-19T21:51:32 1-s2.0-S0010027705002192 S0010-0277(05)00219-2 S0010027705002192 10.1016/j.cognition.2005.11.003 S300 S300.2 FULL-TEXT 1-s2.0-S0010027706X02846 2015-05-14T00:00:22.981292-04:00 0 0 20070201 20070228 2007 2006-02-02T00:00:00Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body acknowledge affil articletitle auth authfirstini authfull authkeywords authlast primabst ref 0010-0277 00100277 UNLIMITED WT false 102 102 2 2 Volume 102, Issue 2 2 151 178 151 178 200702 February 2007 2007-02-01 2007-02-28 2007 Regular articles article fla Copyright © 2005 Elsevier B.V. IMPLICITACTIONENCODINGINFLUENCESPERSONALTRAITJUDGMENTS BACH P 1 Introduction 2 Experiment 1: Action movies 2.1 Method 2.1.1 Participants 2.1.2 Material and apparatus 2.1.3 Procedure and design 2.2 Results 2.2.1 Vision–action fluency 2.2.2 Personal-trait judgments 2.3 Discussion 3 Experiment 2: Static images without action 3.1 Method 3.1.1 Participants 3.1.2 Material and apparatus 3.1.3 Procedure and design 3.2 Results 3.2.1 Vision–action fluency 3.2.2 Personal-trait judgments 3.3 Discussion 4 Experiment 3: Action movies, implicit personality assessment 4.1 Method 4.1.1 Participants 4.1.2 Material and apparatus 4.1.3 Procedure and design 4.2 Results 4.2.1 Vision–action fluency 4.2.2 Personal-trait judgments 4.3 Discussion 5 Interindividual differences 5.1 Method and results 5.1.1 Vision–action fluency 5.1.2 Personal-trait judgments 5.2 Discussion 6 General discussion 7 Conclusions Acknowledgments References ADOLPHS 2000 2683 2690 R AUSTIN 2004 451 460 E BARGH 1996 230 244 J BARONCOHEN 1985 37 46 S BARONCOHEN 2001 5 17 S BARSALOU 1999 560 577 L BARSALOU 2003 L SITUATEDSIMULATIONINHUMANCONCEPTUALSYSTEM BARSALOU 2003 43 92 L PSYCHOLOGYLEARNINGMOTIVATION SOCIALEMBODIMENT BAYLISS 2005 95 114 A BAYLISS 2005 631 650 A BLAKEMORE 2001 561 567 S BRASS 2000 124 143 M BUCCINO 2001 400 404 G CASTIELLO 2003 416 430 U CHARTRAND 1999 893 910 T DIPELLEGRINO 1992 176 189 G ELSNER 2003 732 751 B FADIGA 1996 2608 2611 L FRITH 2001 969 979 U GALLESE 2001 33 50 V GALLESE 2003 517 528 V GALLESE 2003 365 388 V GALLESE 1996 593 609 V GLENBERG 1997 1 55 A GREZES 2003 928 937 J HAMILTON 2004 493 498 A HEBERLEIN 2004 1143 1158 A HOMMEL 2001 849 878 B IACOBONI 2005 M PERSPECTIVESIMITATIONCOGNITIVENEUROSCIENCESOCIALSCIENCE UNDERSTANDINGOTHERSIMITATIONLANGUAGEEMPATHY JACOB 2005 21 25 P JACOBS 2005 157 169 A KANNER 1943 217 250 L KANNER 1946 242 246 L KILNER 2003 522 525 J LIBERMAN 1985 1 36 A MANDLER 1987 646 648 G MORRISON 2004 270 278 I NISHITANI 2004 558 562 N OBERMAN 2005 190 198 L PETERSON 2000 391 405 D PRESTON 2001 1 71 S REBER 1998 45 48 R REED 1995 334 343 C RIZZOLATTI 1996 131 141 G RIZZOLATTI 2000 539 552 G NEWCOGNITIVENEUROSCIENCES CORTICALMECHANISMSSUBSERVINGOBJECTGRASPINGACTIONRECOGNITIONANEWVIEWCORTICALMOTORFUNCTIONS ROGERS 1991 137 162 S RUSSELL 1999 303 331 J SEBANZ 2005 433 454 N SONNBYBORGSTROM 2003 3 23 M STEFAN 2005 9339 9346 K STRACK 1988 768 777 F STURMER 2000 1746 1759 B TAGERFLUSBERG 2000 H METHODSFORSTUDYINGLANGUAGEPRODUCTION CHALLENGESTUDYINGLANGUAGEDEVELOPMENTINCHILDRENAUTISM TAI 2004 120 177 Y THEORET 2005 84 85 H TUCKER 1998 830 846 M TUCKER 2001 769 800 M VANBAAREN 2004 71 74 R VANBAAREN 2003 393 398 R WILLIAMS 2001 287 295 J WOHLSCHLAGER 2000 925 930 A ZWAAN 2002 168 171 R BACHX2007X151 BACHX2007X151X178 BACHX2007X151XP BACHX2007X151X178XP Full 2013-07-16T19:12:22Z ElsevierWaived Wellcome Trust http://creativecommons.org/licenses/by/3.0/ item S0010-0277(05)00219-2 S0010027705002192 1-s2.0-S0010027705002192 10.1016/j.cognition.2005.11.003 271061 2014-10-19T21:39:32.768834-04:00 2007-02-01 2007-02-28 UNLIMITED WT 1-s2.0-S0010027705002192-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/MAIN/application/pdf/87aaee15c88bd57450fb459ea4835f62/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/MAIN/application/pdf/87aaee15c88bd57450fb459ea4835f62/main.pdf main.pdf pdf true 857368 MAIN 28 1-s2.0-S0010027705002192-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/PREVIEW/image/png/5cb2029cb145ce6aad2ba9b1167d38b2/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/PREVIEW/image/png/5cb2029cb145ce6aad2ba9b1167d38b2/main_1.png main_1.png png 44052 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0010027705002192-gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/gr5/DOWNSAMPLED/image/jpeg/a4658f69e2ab11e886d8191caf380afd/gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/gr5/DOWNSAMPLED/image/jpeg/a4658f69e2ab11e886d8191caf380afd/gr5.jpg gr5 gr5.jpg jpg 41780 259 558 IMAGE-DOWNSAMPLED 1-s2.0-S0010027705002192-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/gr3/DOWNSAMPLED/image/jpeg/6f44b3a16510c8a82790f24892716010/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/gr3/DOWNSAMPLED/image/jpeg/6f44b3a16510c8a82790f24892716010/gr3.jpg gr3 gr3.jpg jpg 22286 98 556 IMAGE-DOWNSAMPLED 1-s2.0-S0010027705002192-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/gr1/DOWNSAMPLED/image/jpeg/9727a368dbb0dad094f90b1dfa4d88c0/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/gr1/DOWNSAMPLED/image/jpeg/9727a368dbb0dad094f90b1dfa4d88c0/gr1.jpg gr1 gr1.jpg jpg 101917 604 556 IMAGE-DOWNSAMPLED 1-s2.0-S0010027705002192-gr6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/gr6/DOWNSAMPLED/image/gif/219e355cd5e9e2f41a36943ea4a1a1e2/gr6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/gr6/DOWNSAMPLED/image/gif/219e355cd5e9e2f41a36943ea4a1a1e2/gr6.gif gr6 gr6.gif gif 14780 370 556 IMAGE-DOWNSAMPLED 1-s2.0-S0010027705002192-gr4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/gr4/DOWNSAMPLED/image/gif/fe5deb8f1f2be2b67c1c635ecee2abf4/gr4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/gr4/DOWNSAMPLED/image/gif/fe5deb8f1f2be2b67c1c635ecee2abf4/gr4.gif gr4 gr4.gif gif 13738 363 556 IMAGE-DOWNSAMPLED 1-s2.0-S0010027705002192-gr2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/gr2/DOWNSAMPLED/image/gif/d3309d287503f4faebff5a892d8303f1/gr2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/gr2/DOWNSAMPLED/image/gif/d3309d287503f4faebff5a892d8303f1/gr2.gif gr2 gr2.gif gif 13087 366 556 IMAGE-DOWNSAMPLED 1-s2.0-S0010027705002192-gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/gr6/THUMBNAIL/image/gif/7ce480f497e1f7ee6c359b430035085a/gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/gr6/THUMBNAIL/image/gif/7ce480f497e1f7ee6c359b430035085a/gr6.sml gr6 gr6.sml sml 3726 146 219 IMAGE-THUMBNAIL 1-s2.0-S0010027705002192-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/gr4/THUMBNAIL/image/gif/a3d6ce815f2a9e89c6162ff3c8d37d3d/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/gr4/THUMBNAIL/image/gif/a3d6ce815f2a9e89c6162ff3c8d37d3d/gr4.sml gr4 gr4.sml sml 3553 143 219 IMAGE-THUMBNAIL 1-s2.0-S0010027705002192-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/gr2/THUMBNAIL/image/gif/fd6d7b614fdc8da83042d4ba132b4db2/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/gr2/THUMBNAIL/image/gif/fd6d7b614fdc8da83042d4ba132b4db2/gr2.sml gr2 gr2.sml sml 3481 144 219 IMAGE-THUMBNAIL 1-s2.0-S0010027705002192-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/gr5/THUMBNAIL/image/gif/cc551a0bc64e6747c74e826e10905b8a/gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/gr5/THUMBNAIL/image/gif/cc551a0bc64e6747c74e826e10905b8a/gr5.sml gr5 gr5.sml sml 7888 101 219 IMAGE-THUMBNAIL 1-s2.0-S0010027705002192-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/gr3/THUMBNAIL/image/gif/e8de610a795036edd03d54a1d952051b/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/gr3/THUMBNAIL/image/gif/e8de610a795036edd03d54a1d952051b/gr3.sml gr3 gr3.sml sml 5643 39 219 IMAGE-THUMBNAIL 1-s2.0-S0010027705002192-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0010027705002192/gr1/THUMBNAIL/image/gif/48fec77c4c8894457a3ac1afbf314498/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0010027705002192/gr1/THUMBNAIL/image/gif/48fec77c4c8894457a3ac1afbf314498/gr1.sml gr1 gr1.sml sml 11818 164 151 IMAGE-THUMBNAIL COGNIT 1486 S0010-0277(05)00219-2 10.1016/j.cognition.2005.11.003 Elsevier B.V. Fig. 1 Examples for the movies used in Experiment 1 (action movies). The upper two rows show the ‘sporty’ kicking actions carried out by the two individuals. The lower two rows show the ‘academic’ typing actions carried out by the two individuals. Fig. 2 The upper two panels show the vision–action compatibility effects obtained in Experiment 1 (action movies) for RTs (upper left panel) and Error rates (upper right panel). The bars on the left show the data when an individual had to be identified with a finger response and the bars on the right show the data when an individual had to be identified with a foot response. The white bars show the data when the person was presented typing on a keyboard. The black bars show the data for when the person was kicking a football. The lower two panels show the person-trait judgment effects obtained for John (lower left panel) and George (lower right panel). The bars on the left show the ratings of how sporty a person appeared. The bars on the right show how academic a person appeared. The white bars show the data for when the person was identified by a finger response. The black bars show the data for when the person was identified by a foot response. Fig. 3 Stimuli used in Experiment 2 (static images without action). From left to right: George sitting next to a keyboard, George standing next to the football, John sitting next to a keyboard, and John standing next to a football. Fig. 4 The upper two panels show the vision–action compatibility effects obtained in Experiment 2 (static images without action) for RTs (upper left panel) and Error rates (upper right panel). The bars on the left show the data when an individual had to be identified with a finger response and the bars on the right show the data when an individual had to be identified with a foot response. The white bars show the data when the person was presented typing on a keyboard. The black bars show the data for when the person was kicking a football. The lower two panels show the person-trait judgment effects obtained for John (lower left panel) and George (lower right panel). The bars on the left show the ratings of how sporty a person appeared. The bars on the right show how academic a person appeared. The white bars show the data for when the person was identified by a finger response. The black bars show the data for when the person was identified by a foot response. Fig. 5 The upper four panels show examples of the stimuli used in the implicit person priming task (Experiment 3, action Movies, implicit personality assessment). From left to right: two academic scenes and two sporty scenes. The lower half shows the time course of the trials in the implicit personal-trait judgment task of Experiment 3. Fig. 6 The two upper panels show the vision–action fluency effects obtained in Experiment 3 (action Movies, implicit personality assessment) for RTs (upper left panel) and Error rates (upper right panel). The bars on the left show the data when an individual had to be identified with a finger response and the bars on the right show the data when the individual had to be identified with a foot response. The white bars show the data when the individuals were presented typing. The black bars show the data when the individuals were presented kicking a ball. The lower two panels show the RTs (left panel) and Error rates (right panel) in the implicit personality-priming task (Experiment 3). The bars on the left show the data for the identification of sporty scenes and the bars on the right show the data for the identification of the academic scenes. The white bars show the data for scenes preceded by a photograph of the person that had to be identified with a finger response. The black bars show the data for scenes preceded by the image of the person that had to be identified with a foot response. Table 1 The AQ-scores of the participants in the three experiments Range Mean/SD Low Intermediate High Experiment 1 8–27 16.3/4.8 23 9 — Experiment 2 9–28 17.4/5.5 21 11 — Experiment 3 7–36 15.8/6.2 24 7 1 Baron-Cohen 5–37 16.4/6.5 119 51 4 The second column shows the range of the scores in each experiment, and the third column shows the mean AQ-scores and standard deviations. The third, fourth, and fifth columns show how many of the participants in each experiment fell into the ranges in which few autistic traits were present (low), the range in which some autistic traits are present (intermediate, AQ-scores of 20+), and in the range that indicates autistic traits in a similar extent as in individuals with clinical diagnoses of autism (high, AQ-scores of 32+). Ranges were defined according to Baron-Cohen and colleagues (2001). The last row shows the corresponding data for the non-clinical control group tested in the original publication (Baron-Cohen et al., 2001). Table 2 The bivariate correlations of the vision–action fluency effects in RTs (middle column) and Errors (right column) with the participants’ AQ-score (∗ p <.10; ∗∗ p <.05; ∗∗∗ p <.005) RTs Errors Experiment 1 −.186 −.185 Experiment 2 −.121 −.003 Experiment 3 −.202 .154 Table 3 Result of the regression analysis Predictors Correlations Coefficients Experiment 1 Fluency RTs −.046 Fluency errors .243∗ .404∗∗ AQ-score .483∗∗∗ .533∗∗∗ Experiment 2 Fluency RTs −.087 Fluency errors −.207 AQ-score −.031 Experiment 3 Fluency RTs .261 Fluency errors .352∗∗ .352∗∗ AQ-score .228 The third row shows the bivariate correlations of the personal-trait judgment effects with the respective predictor variables. The right row shows the standardized beta values of the coefficients that were significant predictors of the personality effect (∗ p <.10; ∗∗ p <.05; ∗∗∗ p <.005). ☆ This manuscript was accepted under the editorship of Jacques Mehler. Implicit action encoding influences personal-trait judgments Patric Bach ⁎ p.bach@bangor.ac.uk Steven P. Tipper Centre for Clinical and Cognitive Neuroscience, University of Wales, Bangor, Gwynedd LL57 2AS, UK ⁎ Corresponding author. Tel.: +44 1248 388330. Abstract When an observed action (e.g., kicking) is compatible to a to be produced action (e.g., a foot-key response as compared to a finger-key response), then the self-produced action is more fluent, that is, it is more accurate and faster. A series of experiments explore the notion that vision–action compatibility effects can influence personal-trait judgments. It is demonstrated that when an observed individual carries out an action that is compatible with the participants’ response, (1) this individual is identified more fluently, and (2) the observed individual’s personality is attributed with the properties of the observed action. For example, if it is easier to identify one individual with a foot-response when he is seen kicking a ball, as compared to typing, he is perceived to be more ‘sporty’. In contrast, if it is easier to identify one individual with a finger response when he is seen typing as compared to kicking a ball, he is associated with the ‘academic’ trait. These personal-trait judgment effects can be observed with explicit measures, where participants are asked to rate the sporty/academic nature of the person on a scale. They are also obtained when implicit measures are taken in a priming task, where participants are never explicitly asked to rate the personalities of the individuals. A control experiment rules out that these personal-trait effects are merely due to an association of motor responses (foot, finger) to individuals while identifying them, but that these effects depend on a prior manipulation of vision–action fluency. Keywords Vision–action compatibility Mirror neurons Personal-trait judgments Autism 1 Introduction There is mounting evidence that human cognition – social and other – does not rely on amodal representations, but is ‘grounded’ in the perceptual and motor systems. Accordingly, the representations of an entity or an event consist of the relevant perceptual and motor states that were present when these things were experienced (e.g., Barsalou, 1999, 2003; Glenberg, 1997; Zwaan, Stanfield, & Yaxley, 2002). Perceived actions, in particular, seem to activate the representations an observer would use to produce the same actions (e.g., Hommel, Müsseler, Aschersleben, & Prinz, 2001; Iacoboni, 2005). It has been found that actions are more fluent – faster and more accurate – when the actor concurrently perceives another person carry out the same action (e.g., Brass, Bekkering, Wohlschläger, & Prinz, 2000; Castiello, 2003; Fadiga, Fogassi, Pavesi, & Rizzolatti, 1996; Kilner, Paulignan, & Blakemore, 2003; Stürmer, Aschersleben, & Prinz, 2000). Neurophysiological findings provided a neuronal substrate for these processes. DiPellegrino and colleagues have discovered neurons in the macaque premotor cortex that fire if the monkey produces a particular action, but also if it observes another individual produce the same action (DiPellegrino, Fadiga, Fogassi, Gallese, & Rizzolatti, 1992). Evidence for this so-called ‘mirror system’ is now well established in monkey (Gallese, Fadiga, Fogassi, & Rizzolatti, 1996) and human (e.g., Buccino et al., 2001; Grèzes, Armony, Rowe, & Passingham, 2003; Rizzolatti, Fadiga, Gallese, & Fogassi, 1996). The notion that perceived actions were ‘matched directly’ (Rizzolatti, Fogassi, & Gallese, 2000) to the corresponding action representations of the observer had a significant impact on research in social cognition. Perception–action matching processes may form the basis of observational learning (e.g., Elsner & Aschersleben, 2003; Liberman & Mattingly, 1985; Stefan et al., 2005) and are also critical for smooth and coherent social intercourse. Humans mimic the gestures, body postures, and facial expression of the persons they interact with. Although completely unconscious and non-strategic, this mimicking behavior facilitates social interactions and bonding between people (e.g., Chartrand & Bargh, 1999). For instance, when Van Baaren, Holland, Steenaert, and van Knippenberg (2003) required a waitress to either mimic (repeat back) or not mimic a food order made by a customer, the level of tips received was significantly higher in the mimicking case (see Van Baaren, Holland, Kawakami, & van Knippenberg, 2004 for other examples of pro-social behavior evoked by action mimicking). According to embodied and motor accounts of social cognition (e.g., Barsalou, Niedenthal, Barbey, & Ruppert, 2003; Blakemore & Decety, 2001; Preston & de Waal, 2002; for a critique, see Jacob & Jeannerod, 2005) these findings imply that observers ‘simulate’ the bodily states of other persons on the basis of their own sensorimotor systems. By putting themselves into the shoes of others, they gain empathic insights into these persons’ personalities, goals, and emotional states (e.g., Gallese, 2001, 2003; Preston & de Waal, 2002; for a neuronal mechanism that could drive such inferences, see Barsalou et al., 2003). Perception–action matching mechanisms might therefore also form the basis of higher social cognitive functions, such as intention reading, Theory Of Mind, or the attribution of emotional states and personal traits to other persons (e.g., Blakemore & Decety, 2001; Gallese & Metzinger, 2003; Iacoboni, 2005). A malfunctioning mirror system might also underlie the social deficits of the autistic disorder (e.g., Nishitani, Avikainen, & Hari, 2004; Williams, Whiten, Suddendorf, & Perrett, 2001). Consistent with such simulation accounts of social perception, it has been found that empathic people exhibit more mimicking behavior than non-empathic people (e.g., Sonnby-Borgström, Jönsson, & Svensson, 2003). Similarly, lesion and imaging studies show that partially overlapping brain areas process facial expressions and painful experiences of self and other (e.g., Adolphs, Damasio, Tranel, Cooper, & Damasio, 2000; Morrison, Lloyd, DiPellegrino, & Roberts, 2004), and there is evidence that an intact premotor cortex (i.e., mirror system) is required to attribute personality traits via observation of a person’s actions (Heberlein, Adolphs, Tranel, & Damasio, 2004). The notion that the mirror system was impaired in autism has also been supported by recent studies. In contrast to healthy subjects, autistic individuals do not always exhibit motor facilitation during action observation (Théoret et al., 2005). The aim of the present work was to provide direct evidence for vision–action matching accounts of social perception by demonstrating that the attribution of personal traits relies on processes in the observer’s action system. Our experimental paradigm rests on the following notion: if the observer’s action system is involved in social perception, then manipulations that affect the action system of the observer should also influence how other persons are viewed. Similar research strategies have been applied before to show that the state of the observer’s action system affects, for instance, the perceived movement direction of illusory revolving figures (Wohlschläger, 2000), the perceived weight of a box lifted by another person (Hamilton, Wolpert, & Frith, 2004), or the perceived movement speed of point light walkers (Jacobs & Shiffrar, 2005). Similar techniques have also been applied in research on embodied (social) cognition. For instance, Strack, Martin, and Stepper (1988) have shown that manipulations that induce smiles or frowns also affect how funny the participants rated cartoons they perceived at the same time (for a review of related findings, see Barsalou et al., 2003). Here, we extend this logic to investigate whether the fluency states of the observer’s action system becomes associated with the actions other people carry out at the same time, and hence influence how the personality of these people is perceived. Consider the following experimental situation. The participant’s task is to identify two individuals: if it is George, press a key with the right index finger, if John, press a foot key with the right foot. The individuals are presented carrying out either a sporty action (kicking a ball) or an academic action (typing on a keyboard). It is predicted that the depicted actions should influence the fluency with which the foot- and finger-key responses are executed, even though they are irrelevant to the task of person identification. Thus, the right finger-key press response to identify George will be faster and more accurate when he is carrying out the academic action (typing) than when he is carrying out the sporty action (kicking a ball); the opposite pattern will be observed for the right foot-key response to identify John. Such vision–action compatibility effects would confirm prior studies showing that observed actions and to be executed responses rely on overlapping representations in the observer’s action system (cf. Brass et al., 2000; Stürmer et al., 2000). What is novel about our approach is the idea that the manipulation of vision–action compatibility might also influence what kind of people ‘George’ and ‘John’ are perceived to be. That is, because the finger-key press to identify ‘George’ is more fluent when he is carrying out the academic action than when carrying out the sporty action, it is predicted that participants will report that he is a more academic than sporty person. In contrast, because the foot response to identify ‘John’ will be more fluent when he is carrying out the sporty action of kicking a ball than when carrying out the academic action of typing, the participants will rate him as more sporty than academic. To briefly preview our findings: it is indeed the case that the fluency of the participants’ responses affected the attribution of personal traits to the individuals. These personality-trait judgment effects can be observed with both explicit measures where participants are asked to rate the sporty/academic nature of George and John on a scale, and when implicit measures are taken in a priming task where participants are never explicitly asked to rate the personalities of the individuals. A control experiment rules out that these effects are merely due to an association of motor responses to individuals, and shows that a prior manipulation of vision–action fluency is critical to affect personal-trait judgments. 2 Experiment 1: Action movies In Experiment 1, the participants were presented with movies of two individuals (‘George’ or ‘John’) carrying out either an academic action (typing on a keyboard) or a sporty action (kicking a ball). In a speeded response task, the participants had to identify the two persons by pressing either a finger or a foot key. Thus, the participant’s responses to identify a particular individual were either compatible with the sporty action carried out by this individual and incompatible with the academic action, or vice versa. We predicted that the compatibility between observed action and executed response should influence, first, the fluency with which the identification responses are executed; and second, the personality traits attributed to the two individuals. 2.1 Method 2.1.1 Participants Thirty-two students (27 females) ranging in age from 18 to 42 years participated in the study. All participants had normal or corrected-to-normal vision. The key assignment of actors (George/John) to response keys (foot/finger) was counterbalanced across participants. All participants filled out the Autism-Spectrum Quotient (Baron-Cohen, Wheelwright, Skinner, Martin, & Clubley, 2001) before taking part in the experiment (see Table 1 , row 1, for the mean AQ and the distribution in the current sample). 2.1.2 Material and apparatus The experiment was controlled by Presentation run on a 3.0GHz PC running Windows XP. Eight movies made up the stimulus set (see Fig. 1 for examples). The movies lasted 1100ms each and subtended 5° visual angle vertically and 8° horizontally, given an average viewing distance of 60cm. Two of these movies showed John or George kicking a football, and two movies showed John or George hitting a key on a computer keyboard. In these four movies, the movement direction was always from left to right. To exclude possible confounds arising from compatibility of movement direction and response, for each of these four movies a mirror-inverted version was created, in which the movement direction was from right to left. 2.1.3 Procedure and design The participants were seated in a dimly lit room facing a color monitor at a distance of 60cm. After the computer-driven instruction and a short training phase of 16 trials the experiment properly started. It lasted for about 15min and consisted of 320 trials. The eight different movies were presented at equal rates in a randomized order. Thus, there were 160 trials in which the actor had to be identified by a finger response. In these trials, he was equally often typing on a computer keyboard (compatible) or kicking a football (incompatible). In the remaining 160 trials, the actor had to be identified with a foot response. In these trials, he was again either kicking a ball (compatible) or typing on the computer keyboard (incompatible). The course of each trial was as follows: After the participants initiated the trial by pressing the space bar with their left hand, the movie was presented after 500ms. They identified John or George by either pressing the foot pedal with their right foot or the enter button on the computer keyboard with their right index finger. Participants were instructed to give their judgment in the interval in which the movie was on the screen (1100ms). If their judgment was correct, the next trial started. If they committed an error or did not react in the given response interval of 1100ms, an error message was displayed. After the experiment was finished, a short questionnaire was presented on the computer screen. The participants had to indicate on a scale from −4 (‘not at all’) to 4 (‘very much’) how sporty they imagined the two actors to be (presented by name and an image of their face). They answered the same question with regard to whether they imagined the two individuals to be academic persons or not. The order in which these questions were presented was counterbalanced across participants (i.e., whether they rated George or John first and whether they gave ratings of sporty-ness before academic-ness). 2.2 Results 2.2.1 Vision–action fluency For the analysis of RTs (Fig. 2 , upper left panel), trials in which the participants pressed the wrong button or did not react in the given reaction time interval were excluded (8%). The remaining RTs were entered into a repeated measurements ANOVA with the within-subjects factors Response (foot/finger) and Observed Action (kicking/typing). A main effect of Response was obtained (F [1,31]=175.2, p <.0001, partial eta squared =.85). Participants were faster in responding with the finger than with the foot. There was no main effect of Observed Action (F [1,31]<1). Individuals were identified equally quickly when they were presented typing or kicking. Finally, the predicted two-way interaction of Response and Observed Action was marginally significant (F [1,31]=3.0, p =.093, partial eta squared =.09). When identifying an individual with a foot response, RTs were faster when the person was seen kicking a ball than when typing. When identifying an individual with a finger key-press, RTs were faster when viewing a typing action than when viewing a kicking action. The analysis of the Error Rates (Fig. 2, upper right panel) did not reveal main effects for Response (F [1,30]<1) or Observed Action (F [1,31]<1). Therefore, foot and hand responses were equally accurate and the individuals were identified equally reliably when they were presented typing or kicking. However, the interaction of Response and Observed Action was highly significant (F [1,31]=9.2, p =.005 partial eta squared =.23). Hand responses were more accurate when typing actions were observed than when kicking actions were observed. Conversely, foot responses were more accurate when kicking actions were observed than when typing actions were observed. 2.2.2 Personal-trait judgments Before analyzing the data of the personal-trait judgment task (Fig. 2, lower panels), we checked whether the two persons were rated differently on the two traits. To this end, the data were entered into a repeated measures ANOVA with the factors Person (John, George) and Trait (academic, sporty). There was a main effect of Trait (F [1,31]=16.0, p <.0001, partial eta squared =.34) and a main effect of Person (F [1,31]=7.0, p =.012, partial eta squared =.19). Overall, the two individuals were rated to be more academic than sporty, and John generally received higher ratings than George. However, there also was an interaction of Person and Trait (F [1,31]=22.2, p <.0001, partial eta squared =.42). Thus, the two persons were rated differently on the two traits. John was judged sportier than George, but less academic than George. Note that these differences had to be eliminated in order to obtain a pure measure of the effect of Response on the personal-trait judgments. That is, for each participant, the difference between the person identified with a foot response and the person identified with a finger response also reflects differences that are intrinsic to the two individuals, which had to be identified with these responses. Therefore, from each participant’s rating of the two people on each trait, the mean rating of this person on this trait across all participants was subtracted. This procedure eliminated all differences between the two individuals on the two traits but preserved the effects of Response on the personal-trait judgments. The data were then entered into a two-way ANOVA with the within-subjects factors Trait (academic/sporty) and Response (person identified with a finger response/foot response). There was no main effect of Response (F <1), showing that the two persons were rated equally irrespective of whether they were identified with a foot or a finger response. Due to the normalization procedure described above, the effect of Trait was eliminated (F =0). However, the predicted interaction of Trait and Response was significant (F [1,31]=7.4, p =.011, partial eta squared =.19). Thus, a person was judged more academic when he was identified with a finger response compared to when he was identified with a foot response. A person appeared sportier when he was identified with a foot response compared to when he was identified with a finger response. 2.3 Discussion The present experiment demonstrated for the first time that the compatibility between observed actions with to be produced responses affects not only the fluency of the participants’ responses, but also the attribution of personal traits to the observed individuals. Foot-key responses were more fluent when the identified person was carrying out the sporty action (kicking a ball) compared to when he was carrying out the academic action (typing). This person was later judged to be sportier. Finger-key responses were more fluent when the identified person was carrying out the academic action compared to when the person was carrying out the sporty action. This person was perceived to be more academic. These vision–action personal-trait effects were observed for the ratings of both John and George, although the two individuals were rated quite differently (John was rated more sporty than academic; George was rated more academic than sporty). It is essential to confirm in further experiments that the present effects on personal-trait judgments were indeed caused by the prior manipulation of vision–action fluency. Participants have been exposed to equal numbers of sporty and academic scenes for each individual. Therefore, the results are not an artifact of stimulus exposure. However, each participant always pressed the same key to identify a particular person. Consequently, one person could have become associated with a foot response, while the other person was associated with a finger response over the course of the first part of the experiment. The bias to sporty or academic would then be due to an association of motor responses with individuals, if one assumes that foot responses are more strongly associated with the sporty trait than finger responses, and vice versa for the academic trait. According to this account, the association of individuals and motor responses is sufficient to bring about changes in person perception; a prior induction of vision–action fluency is not required. Experiment 2 addresses this alternative explanation. 3 Experiment 2: Static images without action The participants had the same task as in Experiment 1 (identify one person with a finger-key response and the other with a foot-key response), but overt action was removed from the stimuli. The two persons (John or George) were presented as static images either standing next to a ball (but not kicking it), or sitting next to a computer keyboard (but not typing). Thus, the sporty and academic contexts of the scenes were comparable to Experiment 1, but because no overt action was presented, the vision–action fluency effects that arose from the compatibility between observed actions and to be executed responses should be eliminated. This modification of the original paradigm allowed us to address the alternative explanation that the effects on personal-trait judgments were due to an association of motor responses with individuals. If this were the case, then the same effects as in Experiment 1 should be observed because the association of individuals to motor responses was also the same as in Experiment 1. If, however, the effects on personal-trait judgments were due to a prior induction of vision–action fluency, then a reduction of the vision–action fluency effects should lead to similar reductions of the effects on personal-trait judgments. 3.1 Method 3.1.1 Participants Thirty-two students (23 female) ranging in age from 20 to 30 years participated in the study. All participants filled out the Autism-Spectrum Quotient (Baron-Cohen et al., 2001) before taking part in the experiment (see Table 1, row 2, for the mean AQ and the distribution in the current sample). All other aspects of the participant selection were as in the previous experiment. 3.1.2 Material and apparatus The apparatus was identical to that of the previous experiment. The material comprised eight static images of the individuals (John or George) standing or sitting next to the objects instead of the action movies of the previous experiment (see Fig. 3 for examples). Again, the people could either be facing to the left or to the right. Visual angles and exposure times were identical to Experiment 1. 3.1.3 Procedure and design The experimental setup and the course of each trial were identical to the previous experiment. 3.2 Results 3.2.1 Vision–action fluency The reaction time (Fig. 4 , upper left panel) and error data (Fig. 4, upper right panel) were analyzed as in Experiment 1. For the analysis of the RTs, trials in which the participants pressed the wrong button or did not react in the given reaction time interval were excluded (7%). The ANOVA revealed a main effect of Response (F [1,31]=247, p <.0001, partial eta squared =.89). Participants were faster in responding with the finger than with the foot. There also was a main effect of Observed Action (F [1,31]=27.0, p <.0001, partial eta squared =.47). Participants identified the individuals more quickly when they were presented next to a keyboard than when they were presented next to a football. Importantly, in contrast to Experiment 1, there was no interaction of Observed Action and Response (F [1,31]=2.6, p =.12, partial eta squared =.08). However, because the p-value was close to significance it is important to note that this trend for an interaction is in the opposite direction to that found in Experiment 1. That is, responses were faster to identify the individuals seen sitting adjacent to a keyboard, and this advantage was larger when making a foot response. This is the opposite pattern to that expected, and observed in Experiment 1, based on vision–action fluency/priming. The analysis of the Error Rates revealed a main effect of Response (F [1,31]=6.2, p <.05, partial eta squared =.17), showing that hand responses were more accurate than foot responses. There was no main effect for Observed Action (F [1,31]=2.0). As in RTs, the critical two-way interaction between Response and Observed Action was not significant (F [1,31]<1, partial eta squared =.02). 3.2.2 Personal-trait judgments The data for the personal-trait judgment task (Fig. 4, lower panels) were analyzed as in Experiment 1. The analysis of the differences between the ratings of John and George replicated the findings of Experiment 1. There was a main effect of Trait (F [1,31]=18.4, p <.0001, partial eta squared =.19) and a main effect of Person (F [1,31]=7.5, p =.01, partial eta squared =.37). Accordingly, the two individuals were rated to be more academic than sporty, and John generally received higher ratings that George. Again, there also was an interaction of Person and Trait (F [1,30]=40.9, p <.0001, partial eta squared =.57) reflecting that John was perceived sportier than George, but less academic. These differences were again eliminated from the data to assess the effects of Response on the sporty and academic ratings. This analysis revealed no main effect of Response (F <1) and Trait (F =0). In contrast to Experiment 1, there also was no interaction of Trait and Response (F [1,31]=2.4, ns, partial eta squared =.04). If anything, the data showed the reverse pattern to Experiment 1. Persons identified with a foot response were judged slightly less sporty than persons identified with a finger response. Persons identified with a finger response were judged slightly less academic than persons identified with a foot response. 3.3 Discussion There were no effects of vision–action fluency in either the RTs or the Error rates. Likewise, the personal-trait judgments were not affected by the motor response (foot, finger) that was required to identify the individuals. This was the case even though the participants were efficiently rating the individuals and reproduced the general bias of John being rated as sportier, and George as more academic. Therefore, the present experiment confirmed that the mere association of motor responses (foot or finger) to individuals when identifying them did not suffice to affect personal-trait judgments, but that a prior manipulation of vision–action fluency is critical. The results of Experiment 2 also supported the idea that the vision–action fluency effects in RTs and error rates in Experiment 1 reflected the compatibility of perceived actions with the responses required to identify the individuals. The mirror system is preferentially activated for actions directed at objects if biological motion is present in the stimuli (Tai, Scherfler, Brooks, Sawamato, & Castiello, 2004). Consistently, when biological motion and all cues for action were eliminated, foot and finger responses were equally fluent irrespective of whether the individuals were presented in the academic or sporty contexts. The presence of objects and effectors that were also present in Experiment 1 did not affect the fluency of the participants’ responses. Please note that the present study did not allow us to rule out that the absence of biological motion by itself was critical to eliminate the vision–action fluency effects. For instance, the motion cues in Experiment 1 could have drawn attention to critical body parts of the individuals (feet, hands) or to the critical objects in the scenes (football, computer keyboard). Thus, the vision–action fluency effects observed in Experiment 1 could also have reflected interactions between the participants’ responses and either the compatible objects (e.g., Tucker & Ellis, 1988, 2001) or compatible body parts (Reed & Farah, 1995). But note that both of these notions imply that the action system of the observers was affected by the stimuli they perceived. Thus, they do not challenge the view that the personal-trait judgment effects depended on the prior fluency states of the participants’ action system while identifying the individuals. 4 Experiment 3: Action movies, implicit personality assessment In Experiment 1, the participants were required to make explicit decisions by rating the personal traits (sporty/academic) of the individuals they had observed earlier in the experiment on a scale. However, many social cognitive processes do not take place in such an explicit way, and many processes may not be available to conscious/explicit access. In addition, it is important to show that the attribution of the personal traits occurs not only when the participants are required to do so, but spontaneously while the participants observed the acting individuals. Therefore, in this experiment we assessed the personal-trait effects with an implicit measure, where the participants were never asked to make personal-trait judgments, and where they had no knowledge that such an issue was investigated. The first part of the experiment was identical to Experiment 1, but afterwards the participants were not given the short questionnaire that explicitly required them to attribute the traits ‘sporty’ and ‘academic’ to the observed individuals. Instead, the personal-trait judgment effects were now assessed with a priming task. The participants were instructed to categorize a variety of scenes as to whether they were sporty or academic. The scenes were preceded by brief presentations of the faces of either John or George, which the participants were instructed to ignore. If the traits ‘sporty’ and ‘academic’ had become associated with the two individuals while the participants were identifying them, then the faces of the two individuals should now act as a prime and affect the identification of the scenes. More specifically, it should be easier to categorize a scene as ‘sporty’, when the face of the person that was identified with a foot response was presented beforehand. In this case the participants’ responses were more fluent whenever this person carried out the sporty action than when carrying out the academic action. Analogously, a scene should be more easily categorized as ‘academic’ when the face of the person that was identified with a finger response was presented beforehand. In contrast, if the effects on personal-trait judgments in Experiment 1 only occurred because the participants were explicitly required to make such judgments, there should now be no effects of the face-primes on the categorization of the scenes. 4.1 Method 4.1.1 Participants Thirty-two students (26 female) ranging in age from 20 to 30 years participated in the study. All participants filled out the Autism-Spectrum Quotient (Baron-Cohen et al., 2001, see Table 1, row 3, for the mean AQ and the distribution in the current sample) before taking part in the experiment. All other aspects of the participant selection were as in the previous experiments. 4.1.2 Material and apparatus The material and apparatus used in the first part of this experiment, where video clips of George and John were identified with finger or foot responses, were identical to experiment one. In the second part of the experiment, 24 new photographs were used. Four images were profile shots of the faces of John and George, facing either to the left or the right (visual angle: 2° horizontally, 2° vertically). The remaining 20 black-and-white photographs were shots of 10 sporty and 10 academic scenes (see Fig. 5 for examples). The horizontal and vertical visual angles of these images varied between 2° and 3°. 4.1.3 Procedure and design The first stage of the experiment, where individuals were identified with finger and foot responses, was identical to that of experiment one. After completion of this stage, the participants carried out another short experiment, lasting about 5min and consisting of 80 trials. In this experiment, the faces of either John or George were presented for 500ms at equal rates and in random order. Immediately afterwards, one of the academic or sporty scenes was presented for 1000ms (see Fig. 5 for the time course of the trials). Participants were instructed that the face images were now irrelevant to their current task and so should be ignored. Rather, their task now was to rapidly classify the subsequent scene as sporty or academic by pressing the ‘1’-key or ‘7’-key on the keyboards numerical block with their left hand. If they pressed the wrong button or failed to react in the interval of 1000ms, a short error message was displayed. Otherwise, the next trial started after the participants had pressed the zero-key on the numerical key-block with their right index finger. 4.2 Results 4.2.1 Vision–action fluency The analysis of the vision–action fluency effects in RTs (Fig. 6 , upper left panel) and Error Rates (Fig. 6, upper right panel) was carried out as in the previous experiments. Trials in which the participants pressed the wrong button or did not react in the given reaction time interval were excluded from the analysis of the RTs (8%). As in Experiment 1, the analysis of RTs revealed no main effect of Observed Action (F [1,31]=1.1, partial eta squared =.03). The individuals were identified equally quickly when they were carrying out typing or kicking actions. There was a main effect of Response (F [1,31]=330.2, p <.0001 partial eta squared =.91). Participants were faster in responding with the hand than with the foot. The two-way interaction of Response and Observed Action was not significant (F [1,31]<1, partial eta squared =.01). The analysis of the Error Rates showed a main effect of Response (F [1,31]=6.9, p =.013, partial eta squared =.22). Finger responses were more accurate than foot responses. There also was an effect of Observed Action (F [1,31]=5.9, p <.021, partial eta squared =.16). The individuals were identified more reliably when they were presented typing than when they were presented kicking a ball. Finally, the critical interaction between Response (finger/hand) and Observed Action (kick/type) was again significant (F [1,31]=5.3, p <.028, partial eta squared =.15). Hand responses were more accurate when typing actions were observed than when kicking actions were observed. Foot responses were performed more accurately when kicking actions were observed than when typing actions were observed. 4.2.2 Personal-trait judgments Fig. 6 shows the RTs (lower left panel) and errors rates (lower right panel) to categorize the pictures as sporty or academic in the priming procedure. Trials in which the participants pressed the wrong button or did not react in the given reaction time interval of 1000ms were excluded (11%) from the analysis of RTs. The remaining data were entered into a repeated measures ANOVA with the within-subjects factors Response (person identified with a finger response/person identified with a foot response) and Scene (academic scene/sporty scene). It revealed a main effect of Scene (F [1,31]=16.9, p <.0001, partial eta squared =.36). In general, the participants were faster in classifying sporty scenes than academic scenes. There was no main effect of Response (F <1), but an interaction of Response and Scene (F [1,31]=4.3, p =.046, partial eta squared =.12). The participants were faster in classifying a scene as academic when the person identified with a finger response was presented beforehand than when the person identified with a foot response was presented beforehand. Conversely, the participants were faster in classifying a sporty scene when the person identified with a foot response was presented beforehand than when the person identified with a finger response was presented beforehand. The Error Rates (Fig. 6, lower right panel) were analyzed with the same ANOVA. However, no significant effects were obtained (for all, F <1.9). It is noteworthy, however, that the Error Rates show exactly the same pattern as the RTs. The participants were more accurate in identifying an academic scene when the person identified with a finger response was presented beforehand than when the person identified with a foot response was presented beforehand. Conversely, the participants identified a sporty scene more reliably when the person identified with a foot response was presented beforehand than when the person identified with a finger response was presented beforehand. We investigated the significant RT priming effects further by examining the effects in the first and second half of the procedure. It is possible that the person-trait priming effects are stronger in the initial trials because: (a) participants habituate to the irrelevant priming faces with repeated exposures; (b) the person-trait effect is transient, only lasting a few minutes after the vision–action matching processes; and (c) as RTs to categorize the scenes get substantially faster with repeated exposure, priming effects might get smaller. Therefore, we analyzed separately the first 40 trials and the second 40 trials of the implicit personal-trait priming task. This analysis showed that the interaction of Person and Scene was highly significant in the first half of the personal-trait priming task (F [1,31]=5.1, p <.032, partial eta squared =.14), but not for the second half (F <1, partial eta squared =.01). The effect on error rates was neither significant in the first or the second half. However, numerically, the effect in the error rates was also stronger in the first than the second half. 4.3 Discussion The vision–action fluency effects generally replicate those of Experiment 1. More importantly, the new priming measure for the vision–action personal-trait effect was also significant. Again, the personality of the observed individuals took on the properties of the action for which the participants’ responses were more fluent. Participants were quicker in judging a scene as ‘academic’ when they were primed with the face of the person that was more fluently identified when carrying out the academic action (typing) than when carrying out the sporty action (kicking a ball). Likewise, participants were quicker in judging a scene as ‘sporty’ when they were primed with the face of the person that was more fluently identified when carrying out the sporty action (kicking a ball). Consequently, the attribution of personal traits to individuals on the basis of vision–action fluency occurred even though the participants had no knowledge that this issue was investigated and the faces of John and George were irrelevant to the task of scene categorization. Moreover, the present findings support the view that the attribution of personal traits on the basis of vision–action fluency occurred spontaneously during the observation of the acting individuals, and not only when the participants were asked to do so at the end of the experiment. It is worth noting that the personal-trait priming effects were much clearer in the first half of the priming procedure. As noted, there are a number of possible reasons for this result. First, it may be the case that with repeated exposures to the faces participants habituate to them, hence less encoding would produce no facilitation effects. Second, it may be the case that the personal-trait associated with an individual via previous vision–action fluency is transient. Hence after a few minutes the effect might dissipate and third, it could simply be the case that participants are able to very rapidly encode and categorize the sport/academic scenes after repeated exposure to them, and such ‘ceiling’ performance reduces the likelihood of detecting any priming effects. Further work will be necessary to decide between these alternatives. 5 Interindividual differences The aim of this final section was twofold. The first aim was to investigate the hypothesis that autism could be characterized by a mirror neuron dysfunction, that is, a deficit in mapping perceived actions to one’s own action representations (e.g., Oberman, Hubbard, McCleery, Ramachandran, & Pineda, 2005; Williams et al., 2001). Importantly, however, other researchers have argued that autistic individuals were ‘far from action blind’ (Sebanz, Knoblich, Stumpf, & Prinz, 2005) and that brain structures interacting with the mirror system were sub-optimal in autism (e.g., Arbib & Yahya, 2002). According to this latter view, autistic individuals might be impaired only in the ‘use’ of information provided by intact vision–action matching systems. To differentiate between these two possibilities, we analyzed the results from Experiments 1 to 3 with regard to the data from the Autism-Spectrum Quotient (Baron-Cohen et al., 2001) filled out by all participants prior to taking part in the experiments. The distribution of the current sample corresponded well to the non-clinical control group assessed by Baron-Cohen and colleagues (see Table 1, for the distribution of the scores in the current samples). The AQ presupposes that autism was an extreme case of typical variations in social-communication disability, and represents healthy and more autistic individuals on a continuous scale, with higher scores for individuals closer to the autism end of the scale. The AQ is derived from 50 different questions that reflect the five ‘traits’ associated with autism (10 questions each: social skill, attention switching, attention to detail, communication, and imagination). The AQ has been shown to be a valid and reliable measure for autistic ‘traits’ and corresponds well to clinical diagnoses of autism (Austin, 2004; Baron-Cohen et al., 2001). It also traces known autistic deficits of social cognition such as eye-gaze cuing in the behavior of normals (Bayliss & Tipper, 2005; Bayliss, DiPellegrino, & Tipper, 2005). Thus, if autism is associated with damage to the mirror system, then persons with more autistic traits should (1) show smaller effects of vision–action fluency in the first part of the experiment and (2) show reduced effects on personal-trait judgments. If, however, more autistic individuals were impaired only in the use of the information provided by the vision–action matching processes, then a participant’s AQ-score should not influence the induction of vision–action fluency in the first part of the experiment, but should influence whether he shows effects in the personal-trait judgments. The second aim was to confirm our interpretation that the effects on personal-trait judgments were due to a prior induction of vision–action fluency. If this were the case, then there should be a positive relationship between the induction of vision–action fluency in the first parts of the experiments and subsequent effects on personal-trait judgments. Those participants that were the most affected by the compatibility of perceived actions and to be produced responses should also exhibit the strongest effects on personal-trait judgments. To investigate both questions, we carried out regression analyses for each of the experiments. For each experiment, the participants’ AQ-scores were entered as predictors in separate regression analyses (stepwise method), (1) for the induction of vision–action fluency in the first part of the experiments, and (2) the effects on personal-trait judgments in the second parts. The participants’ effect on vision–action fluency was entered as a second predictor in the analysis of the personal-trait judgment effects. 5.1 Method and results 5.1.1 Vision–action fluency For each experiment, the average vision–action fluency effect in the first part of the experiment was calculated for each participant, separately for the Error Rates and RTs (i.e., the difference between RTs/Error Rates when responses and irrelevant visual-actions were compatible and when responses and irrelevant visual-actions were incompatible). These values were then entered as dependents into two separate linear regression analyses (stepwise method) for the RTs and Error Rates with the participants’ AQ-scores as single predictors. Table 2 shows the result of this analysis. The participants’ AQ-scores were not a significant predictor for the participants’ vision–action fluency effect in any of the experiments for the RTs or the Error Rates. Thus, autism and vision–action matching (mediated by mirror systems) do not seem to be related in this study. 5.1.2 Personal-trait judgments For the analysis of the effects on personal-trait judgments, the predictors were the participants’ AQ-score and the vision–action fluency effect in RTs and Error rates. The dependent variable that described a participant’s effect on personal-trait judgments was computed in the following way: for Experiments 1 and 2, the average of the sporty judgments for the person identified with the foot-key was subtracted from the academic ratings for this person, and the academic judgments for the person identified with the finger-key were subtracted from the sporty ratings for this person. For Experiment 3, the effect in RTs in the first 40 trials, for which the personal-trait judgment effect was significant, was used as a dependent variable. Here, it was derived by subtracting the responses to the scenes that were preceded by a ‘compatible’ face (academic scenes, person identified with a finger-key; sporty scenes, person identified with a foot-key) from those preceded by an ‘incompatible’ face (academic scenes, person identified with a foot-key; sporty scenes, person identified with a finger-key). Table 3 shows the results of these analyses. This analysis revealed significant models for the personal-trait judgment effects in Experiment 1 (action movies: R =.59; p <.005) and Experiment 3 (implicit personal-trait judgments: R =.352; p <.05), but not in Experiment 2 (no action cues). In both Experiments 1 and 3, the vision–action fluency effects were a significant predictor of the subsequent effect on personal-trait judgments (Experiment 1: r =.404; Experiment 3: r =.352; both p <.05). Thus, the more a participant’s responses (foot/finger key to identify George/John) were affected by the irrelevant actions (kicking/typing), the more his/her personal-trait judgments were affected, irrespective of whether these judgments were measured explicitly or implicitly. In addition, the AQ-score of the participants was a highly significant predictor of the effect on explicit personal-trait judgments in Experiment 1 (r =.533, p <.005). Surprisingly, this relationship was positive. Thus, the personal-trait judgments of participants with features more symptomatic of autism were even more affected by induction of vision–action fluency in the first part of the experiment. A similar relationship was, however, not observed in Experiment 3, in which the personal-trait judgment effects were measured implicitly. 5.2 Discussion The regression analysis confirmed that the effects on personal-trait judgments were induced by the prior manipulation of vision–action fluency. That is, there was a significant positive relationship between the vision–action fluency effects in the first part of the experiment and the subsequent changes in personal-trait judgments in Experiment 1 and 3, but not in Experiment 2. Thus, the more the irrelevant actions influenced the fluency of a participant’s responses, the more personal-trait judgments were subsequently affected. The lack of such a relationship in Experiment 2 also supports the view that the effects on personality judgments were due to prior interactions of perceived actions and to be produced responses, and not due to interactions of perceived objects or effectors and to be produced responses. Even those participants whose responses were affected by either the perceived effectors, objects, or implied future actions in Experiment 2 did not show larger personal-trait judgment effects. Thus, any effect on personal-trait judgment seems to be driven by prior interactions of perceived actions and produced responses. The results of the regression analyses contrasted, however, with the notion that autism was characterized by a mirror neuron dysfunction. If this had been the case, there should have been negative relationships between AQ-score and the induced vision–action fluency on the one hand, and between AQ-score and the effect on personal-trait judgments on the other hand. However, there was no relationship between AQ- score and vision–action fluency, and the relationship between AQ-score and effect on personal-trait judgments was positive. These findings are consistent with the notion that the vision–action matching systems are not absent in autistic individuals, but that these individuals differ from more socially adept individuals in the use of the information provided by these systems. The finding of a positive relationship between the presence of autistic symptoms and the effects on personal-trait judgments suggests that persons with the highest AQ-scores in our (non-clinical) sample had more problems than the AQ-low-scorers with representing the actions of others independently from the actions they carried out at the same time. Of potential importance, the personality-priming task in Experiment 3 appeared to be less sensitive to interindividual differences than the explicit measure in Experiment 1. Thus, when the personal-trait judgments were assessed implicitly in the priming procedure of Experiment 3, there was no relationship with the AQ-scores of the participants. 6 General discussion The mirroring of the behavior of others is fundamental to fluent social intercourse. This capacity seems to rely on the matching of perceived actions to the corresponding action representations of the observer (e.g., Hommel et al., 2001; Rizzolatti et al., 2000). The subtle mimicking behavior that results from these processes might form the basis of observational learning, facilitates social interactions, and generates bonding and rapport between persons (e.g., Chartrand & Bargh, 1999). The present work goes beyond these findings and provided evidence that action mirroring also plays a role in higher social cognitive functions. We have demonstrated that the compatibility between observed actions and to be executed responses can influence the attribution of personal traits to other individuals. In a task in which the participants had to identify two individuals by pressing either a finger-key or a foot-key, we manipulated whether these responses were compatible either with a sporty action (kicking a ball) carried out by an individual, or with an academic action (typing on a keyboard). We found that an individual was identified more fluently when the irrelevant action he was carrying out was compatible with the response required to identify him. Although the compatibility effects were generally more pronounced in the error rates than in the RTs, this result replicated prior reports of perceived actions facilitating compatible responses or interfering with incompatible responses (e.g., Brass et al., 2000; Kilner et al., 2003). Such effects are expected if perceived actions were automatically mapped onto the action representations an observer would rely on to carry out these actions (e.g., Hommel et al., 2001; Rizzolatti et al., 2000). Consistent with this view, there were no vision–action compatibility effects when the to be identified individuals were not carrying out an action (Experiment 2). Importantly, the compatibility between observed actions and responses also affected the subsequent attribution of personal traits to the individuals. The personality of the two individuals took on the properties of the action for which they were identified more fluently. Two findings confirmed that the effects on personal-trait judgments were due to prior interactions of perceived actions and executed responses in the action system of the observer. First, the regression analysis of Experiment 1 revealed a direct relationship between the effects on personal-trait judgments and the vision–action fluency effects in the first part of the experiment. This relationship was replicated in Experiment 3, in which the personal-trait effects were assessed implicitly via a priming task. Therefore, the more a participant’s identification responses were affected by the irrelevant actions, the stronger was the influence on personal-trait judgments at a later point in time, irrespective of whether these personal-trait judgments were measured explicitly or implicitly. Second, the personal-trait judgments were only affected when a prior induction of visuomotor fluency was successful (Experiments 1 and 3). When the observed individuals were not acting (Experiment 2), there was no evidence for vision–action compatibility, and of course, there were no personal-trait judgment effects, either. Note that even the regression analysis failed to reveal a significant relationship between induced vision–action fluency and subsequent personal-trait judgments in Experiment 2. Thus, even those participants who showed compatibility effects (for instance, because they attended to either the implied but not performed actions, the objects, or the effectors present in the scenes) did not show larger personal-trait effects than the participants who did not exhibit compatibility effects. Although preliminary, this finding suggests that the effect on personal-trait judgments depends on actions that are truly perceived, instead of other stimulus aspects that could, in principle, have evoked compatibility effects. These findings support embodied or simulation accounts of social perception (e.g., Barsalou et al., 2003; Gallese, 2001, 2003; Gallese & Metzinger, 2003; Iacoboni, 2005; Preston & de Waal, 2002). Accordingly, observers recreate the bodily states of others on the basis of their own action system to gain information about the goals, emotional states, and personal traits of these persons. Thus, by simulating the observed actions of others, such as frowning or smiling, or vigorous or slow ponderous movements, the emotional state of another person may be better understood. Similarly, our personal-trait effects emerged from a process of vision–action matching, that is, an interaction between observing an incidental action that is irrelevant to the task at hand with the response to be produced when identifying an individual. For example, when George can be identified with a foot response more fluently when he is seen kicking a ball, he is associated with this sporty property. Further studies are required to pinpoint the exact nature of the mechanism that evoked the personal-trait judgment effect. We predicted such effects if observers tended to misattribute the fluency of their own responses to the actions they have perceived at the same time. If this were the case, other manipulations that only affect the action system of the observers while identifying the individuals (e.g., making responses easier or harder in some situations) should lead to similar results on personal-trait judgments. However, there are other possibilities to explain the vision–action personal-trait effect. According to Hommel and colleagues (2001) there is not only an influence from perception on action, but also a reverse influence from action on perception. Thus, the performance of a foot press might have interfered with the perception of the incompatible typing action, and/or facilitated the perception of the compatible kicking action. Theorists of embodied (social) cognition offered a similar explanation for enhancing effects of mimicry on perceptual measures. Accordingly, mimicry provides additional activation to the representation of a compatible stimulus (e.g., Barsalou et al., 2003). These notions suggest a more perceptual origin of the effects. If this were the case, manipulations that affect only the fluency of the perceptual processes while identifying the individuals (e.g., increasing contrast) should lead to similar effects on personal-trait judgments. Indeed, it has been demonstrated that manipulations that facilitated perceptual processing evoked more favorable judgments about the perceived stimuli (e.g., Mandler, Nakamura, & Van Zandt, 1987; Reber, Winkielman, & Schwartz, 1998; for a review of related findings, see Barsalou, 1999, 2003). The present study also provided some preliminary information concerning the interindividual differences mediating the vision–action personal-trait effects. Participants completed the Autism-Spectrum Quotient developed by Baron-Cohen and colleagues (2001). This measures traits associated with autism, with higher scorers being closer to the autism end of the scale. The AQ has been shown to be a valid and reliable measure for autistic symptoms and corresponds well with clinical diagnoses of autism (Austin, 2004; Baron-Cohen et al., 2001). It should be noted, of course, that because only one of our participants had an AQ-score that fell in the range associated with a clinical diagnosis of autism, any conclusions we draw here must subsequently be confirmed with clinical studies. We investigated two issues: first, whether the AQ-scores are related to the vision–action compatibility effects assumed to reflect mirror processing; and second, the new issue of whether the personal-trait effects differ in people with different AQ scores. In the former case, there is some debate as to whether individuals with autism have intact vision–action matching (mirror) systems. On the one hand, Williams and colleagues (2001) suggested that individuals with autism are impaired in representing the actions of others via mirror systems. On the other hand, others (e.g., Sebanz et al., 2005; Théoret et al., 2005) suggest that in some circumstances individuals with autism represent even task irrelevant actions of other people within their action system. Our results support this latter view. In both Experiments 1 and 3, where significant vision–action compatibility effects were observed, these effects were not related to the AQ-score of the participants. In contrast, when examining whether AQ score affected the personal-trait effects, individual differences were detected. The higher a participant’s AQ-score, the stronger were the effects on personal-trait judgments he exhibited. Importantly, this relationship between AQ and personal-trait assessment was only observed in Experiment 1 where explicit/conscious measures were taken. When we measured the personal-trait associations implicitly via a priming technique, such that participants were unaware such information was being assessed (Experiment 3), no AQ differences were detected. Our current working hypothesis is as follows: the initial processes that match perceived actions to the observer’s action system are intact also in the individuals with the highest AQ-scores in our (non-clinical) sample. Thus, the relatively rapid and automatic computations undertaken by mirror systems provide equivalent inputs to later systems. However, it is the ability to utilize this information that might differ in individuals with more autistic traits. In Experiment 1, persons closer to the autistic end of the AQ-scale were more affected by the vision–action fluency effects when they subsequently made conscious decisions about the personal traits of another person. Low AQ scorers, on the other hand, appeared to be able to more effectively discount/inhibit prior vision–action processes when making overt decisions about an individual’s personal traits. As noted, this ability of low AQ participants to discount prior processing is only observed when consciously manipulating information in the explicit personal-trait task of Experiment 1: all individuals responded similarly when implicit/pre-conscious processes were assessed in Experiment 3. Other research would appear to be compatible with this line of thought. For example, individuals with autism tend to mimic the actions (echopraxia) and words (echolalia) of others irrespective of their own goals. Thus, the basic perception–action matching processes that result in the ability to mimic are not absent in autistic individuals, but the subsequent appropriate use of this information is lacking. Furthermore, they also confuse the personal pronouns of “I” and “You” (e.g., Kanner, 1943, 1946; for review see Tager-Flusberg, 2000). It follows that autistic individuals have problems with coordinating separate representations of self and other (Rogers & Pennington, 1991; Russell & Jarrold, 1999; Théoret et al., 2005; for a review, see Williams et al., 2001). Consistently, in false belief tasks, autistic children are more prone than healthy subjects to attribute their own knowledge about a situation to individuals that would not have this information (e.g., Baron-Cohen, Leslie, & Frith, 1985; Peterson & Bowler, 2000; for a review, see Frith, 2001). Even more relevant to our current findings, Russell and Jarrold (1999) demonstrated that in contrast to normally developing children and those with mild learning difficulties, children with autism had significant problems in differentiating their own from another person’s actions. Normal children are clearly aware of whether an action was produced by themselves, or whether they observed someone else produce a similar action. For individuals with autism their own actions and the actions of others they observe are not differentiated. Our findings were consistent with this view. Accordingly, the explicit personal-trait ratings of those with the highest AQ-scores in our sample were most affected by the induction of vision–action fluency, because they had problems with keeping the representations of the actions carried out by the observed individuals separate from the representations of their own actions. That is, their own visual–action fluency when identifying an individual with a foot response while they are observed undertaking a sporty action, for example, is inappropriately assigned to the viewed person. Thus, the observed person is perceived to be a more fluent athlete. Of course, when measured implicitly it is not possible to separate self-action fluency from other person properties, as these are outside strategic control. 7 Conclusions The present work links lower-level processes typically studied within the domains of visual psychophysics and motor control to higher-level cognitive processes in social cognition. Prior work has shown that priming participants with words associated with the elderly (e.g., ‘wrinkle’) can influence them to subsequently walk more slowly (Bargh, Chen, & Burrows, 1996). Our work has now shown the opposite effects of vision–action fluency influencing the attribution of personal traits. Perhaps the most striking aspect of these processes was their automaticity. This was reflected in two ways: first, in all experiments, the actions (kicking/typing) carried out by the two individuals were completely irrelevant to the participant’s task of person identification. Second, the personality-trait judgment effects could be observed with both explicit measures where participants were asked to rate the sporty/academic nature of George and John on a scale, and when implicit measures were taken in a priming task where participants were never explicitly asked to rate the personalities of the individuals. Thus, the attribution of personal traits to individuals occurs spontaneously during the perception and production of actions, and the trait information associated with a person can be accessed rapidly and automatically even when the person’s identity and personality are not relevant to the task. Acknowledgments We thank Stefanie Schuch, Matthew Paul, and Andrew Bayliss for their helpful comments. The work was supported by a Wellcome Trust Programme grant awarded to S.P.T. References Adolphs et al., 2000 R. Adolphs H. Damasio D. Tranel G. Cooper A.R. Damasio A role for somatosensory cortices in the visual recognition of emotions as revealed by threedimensional lesion mapping The Journal of Neuroscience 20 2000 2683 2690 Arbib and Yahya, 2002 Arbib, M. A., & Yahya, J. S. M. (2002). Abstract for the conference on “Perspectives On Imitation: From Cognitive Neuroscience to Social Science”, 23–26 May 2002, Royaumont Abbey, France. Austin, 2004 E.J. Austin Personality correlates of the broader autism phenotype as assessed by the Autism Spectrum Quotient (AQ) Personality and Individual Differences 38 2 2004 451 460 Bargh et al., 1996 J.A. Bargh M. Chen L. Burrows Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action Journal of Personality and Social Psychology 71 1996 230 244 Baron-Cohen et al., 1985 S. Baron-Cohen A.M. Leslie U. Frith Does the autistic child have a “Theory of mind”? Cognition 21 1985 37 46 Baron-Cohen et al., 2001 S. Baron-Cohen S. Wheelwright R. Skinner J. Martin E. Clubley The Autism-Spectrum Quotient (AQ): Evidence from Asperger Syndrome/high-functioning autism, males and females, scientists and mathematicians Journal of Autism and Developmental Disorders 31 1 2001 5 17 Barsalou, 1999 L.W. Barsalou Perceptual symbol systems Behavioral and Brain Sciences 22 1999 560 577 Barsalou, 2003 L.W. Barsalou Situated simulation in the human conceptual system 2003 Elsevier Amsterdam Barsalou et al., 2003 L.W. Barsalou P.M. Niedenthal A. Barbey J. Ruppert Social embodiment B. Ross The psychology of learning and motivation Vol. 43 2003 Academic Press San Diego 43 92 Bayliss and Tipper, 2005 A.P. Bayliss S.P. Tipper Object-based attention varies along the Autism-Spectrum: Evidence from social gaze and arrow cueing in normal adults British Journal of Psychology 96 2005 95 114 Bayliss et al., 2005 A.P. Bayliss G. DiPellegrino S.P. Tipper Sex differences in eye gaze and symbolic cueing of attention The Quarterly Journal of Experimental Psychology 58 4 2005 631 650 Blakemore and Decety, 2001 S.J. Blakemore J. Decety From the perception of action to the understanding of intention Nature Reviews Neuroscience 2 8 2001 561 567 Brass et al., 2000 M. Brass H. Bekkering A. Wohlschläger W. Prinz Compatibility between observed and executed finger movements: Comparing symbolic, spatial and imitative cues Brain and Cognition 44 2000 124 143 Buccino et al., 2001 G. Buccino F. Binkofski G.R. Fink L. Fadiga L. Fogassi V. Gallese Action observation activates premotor and parietal areas in a somatotopic manner: An fMRI study European Journal of Neuroscience 13 2001 400 404 Castiello, 2003 U. Castiello Understanding other people’s actions: Intention and attention Journal of Experimental Psychology: Human Perception and Performance 29 2 2003 416 430 Chartrand and Bargh, 1999 T.L. Chartrand J.A. Bargh The chameleon effect: The perception-behaviour link and social interaction Journal of Personality and Social Psychology 76 1999 893 910 DiPellegrino et al., 1992 G. DiPellegrino L. Fadiga L. Fogassi V. Gallese G. Rizzolatti Understanding motor events: A neurophysiological study Experimental Brain Research 91 1992 176 189 Elsner and Aschersleben, 2003 B. Elsner G. Aschersleben Do I get what you get? Learning about effects of self-performed and observed actions in infants Consciousness and Cognition 12 4 2003 732 751 Fadiga et al., 1996 L. Fadiga L. Fogassi G. Pavesi G. Rizzolatti Motor facilitation during action observation: A magnetic stimulation study Journal of Neurophysiology 73 6 1996 2608 2611 Frith, 2001 U. Frith Mind blindness and the brain in autism Neuron 32 2001 969 979 Gallese, 2001 V. Gallese The ‘shared manifold’ hypothesis. From mirror neurons to empathy Journal of Consciousness Studies 8 5–7 2001 33 50 Gallese, 2003 V. Gallese The manifold nature of interpersonal relations: The quest for a common mechanism Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences 358 2003 517 528 Gallese and Metzinger, 2003 V. Gallese T. Metzinger Motor Ontology: The representational reality of goals, actions and selves Philosophical Psychology 16 9 2003 365 388 Gallese et al., 1996 V. Gallese L. Fadiga L. Fogassi G. Rizzolatti Action recognition in the premotor cortex Brain 119 1996 593 609 Glenberg, 1997 A.M. Glenberg What memory is for Behavioral and Brain Sciences 20 1997 1 55 Grèzes et al., 2003 J. Grèzes L. Armony J. Rowe R.E. Passingham Activations related to “mirror” and “canonical” neurones in the human brain: An fMRI study NeuroImage 18 2003 928 937 Hamilton et al., 2004 A. Hamilton D. Wolpert U. Frith Your own action influences how you perceive another person Current Biology 14 2004 493 498 Heberlein et al., 2004 A.S. Heberlein R. Adolphs D. Tranel H. Damasio Cortical regions for judgments of emotions and personality traits from point-light walkers Journal of Cognitive Neuroscience 16 7 2004 1143 1158 Hommel et al., 2001 B. Hommel J. Müsseler G. Aschersleben W. Prinz The Theory of Event Coding (TEC): A framework for perception and action planning Behavioral and Brain Sciences 24 2001 849 878 Iacoboni, 2005 M. Iacoboni Understanding others. Imitation, language, empathy S. Hurley N. Chater Perspectives on imitation. From cognitive neuroscience to social science 2005 MIT Press Cambridge, MA Jacob and Jeannerod, 2005 P. Jacob M. Jeannerod The motor theory of social cognition: A critique Trends in Cognitive Sciences 9 1 2005 21 25 Jacobs and Shiffrar, 2005 A. Jacobs M. Shiffrar Walking perception by walking observers Journal of Experimental Psychology: Human Perception and Performance 31 1 2005 157 169 Kanner, 1943 L. Kanner Autistic disturbances of affective contact Nervous Child 2 1943 217 250 Kanner, 1946 L. Kanner Irrelevant metaphorical language in early infantile autism American Journal of Psychiatry 103 1946 242 246 Kilner et al., 2003 J.M. Kilner Y. Paulignan S.J. Blakemore An interference effect of observed biological movement on action Current Biology 13 2003 522 525 Liberman and Mattingly, 1985 A.M. Liberman I.G. Mattingly The motor theory of speech perception revised Cognition 21 1985 1 36 Mandler et al., 1987 G. Mandler Y. Nakamura B. Van Zandt Nonspecific effects of exposure on stimuli that cannot be recognized Journal of Experimental Psychology: Learning, Memory, and Cognition 13 4 1987 646 648 Morrison et al., 2004 I. Morrison D. Lloyd G. DiPellegrino N. Roberts Vicarious responses to pain in anterior cingulated cortex: Is empathy a multisensory issue? Cognitive, Affective and Behavioral Neuroscience 4 2 2004 270 278 Nishitani et al., 2004 N. Nishitani S. Avikainen S. Hari Abnormal imitation-related cortical activation sequences in Asperger’s syndrome Annals of Neurology 55 4 2004 558 562 Oberman et al., 2005 L.M. Oberman E.M. Hubbard J.P. McCleery V.S. Ramachandran J.A. Pineda EEG evidence for mirror neuron dysfunction in autism Cognitive Brain Research 24 2 2005 190 198 Peterson and Bowler, 2000 D. Peterson D.M. Bowler Counterfactual reasoning and false belief understanding in autism Autism 4 4 2000 391 405 Preston and de Waal, 2002 S.D. Preston F.B.M. de Waal Empathy: Its ultimate and proximate bases Behavioral and Brain Sciences 25 1 2001 1 71 Reber et al., 1998 R. Reber P. Winkielman N. Schwartz Effects of perceptual fluency on affective judgements Psychological Research 9 1998 45 48 Reed and Farah, 1995 C.L. Reed M.J. Farah The psychological reality of the body schema: A test with normal participants Journal of Experimental Psychology: Human Perception and Performance 21 1995 334 343 Rizzolatti et al., 1996 G. Rizzolatti L. Fadiga V. Gallese L. Fogassi Premotor cortex and the recognition of motor actions Cognitive Brain Research 3/2 1996 131 141 Rizzolatti et al., 2000 G. Rizzolatti L. Fogassi V. Gallese Cortical mechanisms subserving object grasping and action recognition: A new view on the cortical motor functions M.S. Gazzaniga The new cognitive neurosciences 2nd ed. 2000 MIT Press Cambridge, MA 539 552 Rogers and Pennington, 1991 S.J. Rogers B.F. Pennington A theoretical approach to the deficits in infantile autism Development and Psychopathology 3 1991 137 162 Russell and Jarrold, 1999 J. Russell C. Jarrold Memory for actions in children with autism: Self versus other Cognitive Neuropsychiatry 4 1999 303 331 Sebanz et al., 2005 N. Sebanz G. Knoblich L. Stumpf W. Prinz Far from action blind: Representation of others’ actions in individuals with autism Cognitive Neuropsychology 22 3–4 2005 433 454 Sonnby-Borgström et al., 2003 M. Sonnby-Borgström P. Jönsson P. Svensson Emotional empathy as related to mimicry reactions at different levels of information processing Journal of Nonverbal Behavior 27 1 2003 3 23 Stefan et al., 2005 K. Stefan L.G. Cohen J. Duque R. Mazzocchio P. Celnik L. Sawaki Formation of a motor memory by action observation Journal of Neuroscience 25 41 2005 9339 9346 Strack et al., 1988 F. Strack L.L. Martin S. Stepper Inhibiting and facilitating conditions of the human smile Journal of Personality and Social Psychology 54 5 1988 768 777 Stürmer et al., 2000 B. Stürmer G. Aschersleben W. Prinz Correspondence effects with manual gestures and postures: A study of imitation Journal of Experimental Psychology: Human Perception and Performance 26 6 2000 1746 1759 Tager-Flusberg, 2000 H. Tager-Flusberg The challenge of studying language development in children with autism L. Menn N.B. Ratner Methods for studying language production 2000 Earlbaum Mahwah, NJ Tai et al., 2004 Y.F. Tai C. Scherfler D.J. Brooks N. Sawamato U. Castiello The human premotor cortex is ‘mirror’ only for biological movements Current Biology 14 2004 120 177 Théoret et al., 2005 H. Théoret E. Halligan M. Kobayashi F. Fregni H. Tager-Flusberg A. Pascual-Leone Impaired motor facilitation during action observation in individuals with autism spectrum disorder Current Biology 15 3 2005 84 85 Tucker and Ellis, 1988 M. Tucker R. Ellis On the relations between seen objects and components of potential actions Journal of Experimental Psychology: Human Perception and Performance 24 1998 830 846 Tucker and Ellis, 2001 M. Tucker R. Ellis The potentiation of grasp types during visual object recognition Visual Cognition 8 2001 769 800 Van Baaren et al., 2004 R.B. Van Baaren R.W. Holland K. Kawakami A. van Knippenberg Mimicry and prosocial behavior Psychological Science 15 2004 71 74 Van Baaren et al., 2003 R.B. Van Baaren R.W. Holland B. Steenaert A. van Knippenberg Mimicry for money: Behavioural consequences of imitation Journal of Experimental Social Psychology 39 2003 393 398 Williams et al., 2001 J.H.G. Williams A. Whiten T. Suddendorf D.J. Perrett Imitation, mirror neurons and autism Neuroscience and Biobehavioral Reviews 25 2001 287 295 Wohlschläger, 2000 A. Wohlschläger Visual motion priming by invisible actions Vision Research 40 2000 925 930 Zwaan et al., 2002 R.A. Zwaan R.A. Stanfield R.H. Yaxley Language comprehenders mentally represent the shapes of objects Psychological Science 13 2002 168 171"
10.1016/j.cognition.2005.11.004,The nature of music from a biological perspective ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060220', '$': '2006-02-20'}}}}"
10.1016/j.cognition.2005.11.005,"The capacity for music: What is it, and what’s special about it? ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051227', '$': '2005-12-27'}}}}"
10.1016/j.cognition.2005.11.006,Infant music perception: Domain-general or domain-specific mechanisms? ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20051227', '$': '2005-12-27'}}}}"
10.1016/j.cognition.2005.11.007,Are we “experienced listeners”? A review of the musical capacities that do not depend on formal musical training ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060117', '$': '2006-01-17'}}}}"
10.1016/j.cognition.2005.11.008,Varieties of musical experience ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060117', '$': '2006-01-17'}}}}"
10.1016/j.cognition.2005.11.009,The biology and evolution of music: A comparative perspective ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060117', '$': '2006-01-17'}}}}"
10.1016/j.cognition.2005.12.001,Giving the boot to the bootstrap: How not to learn the natural numbers ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060117', '$': '2006-01-17'}}}}"
10.1016/j.cognition.2005.12.002,Determination of visual figure and ground in dynamically deforming shapes ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060131', '$': '2006-01-31'}}}}"
10.1016/j.cognition.2005.12.003,"The development of mental state attributions in women with X-monosomy, and the role of monoamine oxidase B in the sociocognitive phenotype ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060117', '$': '2006-01-17'}}}}"
10.1016/j.cognition.2005.12.004,The integration of figurative language and static depictions: An eye movement study of fictive motion ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060124', '$': '2006-01-24'}}}}"
10.1016/j.cognition.2005.12.005,Feature binding in visual working memory evaluated by type identification paradigm ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060126', '$': '2006-01-26'}}}}"
10.1016/j.cognition.2005.12.006,"Language-specific and universal influences in children’s syntactic packaging of Manner and Path: A comparison of English, Japanese, and Turkish ","{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060126', '$': '2006-01-26'}}}}"
10.1016/j.cognition.2005.12.007,Eye movements of monkey observers viewing vocalizing conspecifics ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060131', '$': '2006-01-31'}}}}"
10.1016/j.cognition.2005.12.008,Color naming universals: The case of Berinmo ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060207', '$': '2006-02-07'}}}}"
10.1016/j.cognition.2005.12.009,Body posture facilitates retrieval of autobiographical memories ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060203', '$': '2006-02-03'}}}}"
10.1016/j.cognition.2005.12.010,Lexical and post-lexical phonological representations in spoken production ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060217', '$': '2006-02-17'}}}}"
10.1016/j.cognition.2005.12.011,Domain-general contributions to social reasoning: Theory of mind and deontic reasoning re-explored ,"{'xocs:doc': {'xocs:meta': {'xocs:open-access': {'xocs:oa-article-status': {'@is-open-access': '0', '@is-open-archive': '0'}}, 'xocs:available-online-date': {'@yyyymmdd': '20060214', '$': '2006-02-14'}}}}"
